{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Data From Yahoo Finance For Stock Build last updated 21/11/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install beautifulsoup4\n",
    "#!pip3 install curl_cffi\n",
    "#!pip3 install frozendict\n",
    "#!pip3 install multitasking\n",
    "#!pip3 install numpy\n",
    "#!pip3 install pandas\n",
    "#!pip3 install peewee\n",
    "#!pip3 install platformdirs\n",
    "#!pip3 install protobuf\n",
    "#!pip3 install pytz\n",
    "#!pip3 install requests\n",
    "#!pip3 install websockets\n",
    "#!pip3 install statsmodels\n",
    "#!pip3 install tkinter\n",
    "#!pip3 install xlwings\n",
    "#!pip3 install webdriver-manager\n",
    "#!pip3 install openpyxl\n",
    "#!pip3 install pyinstaller\n",
    "#!pip3 install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is only for when we require an upgrade to software package\n",
    "#!pip3 install --upgrade pandas\n",
    "#!pip3 install --upgrade openpyxl\n",
    "#!pip3 install --upgrade yfinance\n",
    "#!pip3 install --upgrade webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 1 imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import time\n",
    "import yfinance as yf\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import hashlib\n",
    "import shutil\n",
    "import io\n",
    "import sys, os\n",
    "import json\n",
    "import xlwings as xw\n",
    "import statsmodels.api as sm\n",
    "import re, zipfile\n",
    "import tkinter as _tk\n",
    "import multiprocessing as mp\n",
    "import pptx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import pinv\n",
    "from pathlib import Path\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.enum.text import MSO_AUTO_SIZE\n",
    "from datetime import datetime\n",
    "from tkinter import ttk as _ttk, messagebox as _mb\n",
    "from scipy.optimize import minimize\n",
    "try:\n",
    "    import win32com.client as win32\n",
    "    HAS_WIN32COM = True\n",
    "except Exception:\n",
    "    HAS_WIN32COM = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### BLOCK 2 Global codes and Data Retrieval from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Central base directory\n",
    "# ---------------------------------------------------------------------\n",
    "def _app_dir() -> Path:\n",
    "    \"\"\"\n",
    "    Determine the application directory dynamically:\n",
    "      - When frozen (PyInstaller): use the exe folder\n",
    "      - When run as a script: use the script's folder\n",
    "      - When interactive (Jupyter/IPython): use cwd\n",
    "    \"\"\"\n",
    "    if getattr(sys, \"frozen\", False):\n",
    "        return Path(sys.executable).parent\n",
    "    if \"__file__\" in globals():\n",
    "        return Path(__file__).resolve().parent\n",
    "    return Path(os.getcwd())\n",
    "\n",
    "\n",
    "# Absolute path to your central config root (for dev use)\n",
    "_DEV_BASE = Path.home() / \"Portfolio_Optimiser\"\n",
    "\n",
    "# Use the dev folder if it exists, otherwise fall back to dynamic app dir\n",
    "APP_DIR = _DEV_BASE if _DEV_BASE.exists() else _app_dir()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config file and Excel workbook paths\n",
    "# ---------------------------------------------------------------------\n",
    "def _default_excel_path() -> str:\n",
    "    \"\"\"Return full path to the default Excel workbook.\"\"\"\n",
    "    return str((APP_DIR / \"Stock Analysis.xlsm\").resolve())\n",
    "\n",
    "CONFIG_PATH = APP_DIR / \"config.json\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Export directory (for generated reports)\n",
    "# ---------------------------------------------------------------------\n",
    "EXPORT_DIR = APP_DIR \n",
    "EXPORT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Default configuration values\n",
    "# ---------------------------------------------------------------------\n",
    "_DEFAULTS = {\n",
    "    \"excel_path\": _default_excel_path(),\n",
    "    \"marginal_tax_rate\": 0.37,\n",
    "    \"carry_forward_losses\": 0.0,\n",
    "    \"lot_match_method\": \"HIFO\",\n",
    "    \"open_after_save\": True,\n",
    "    \"use_xlwings\": True,\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config loader\n",
    "# ---------------------------------------------------------------------\n",
    "def load_config() -> dict:\n",
    "    cfg = dict(_DEFAULTS)\n",
    "    try:\n",
    "        if CONFIG_PATH.exists():\n",
    "            with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                user_cfg = json.load(f)\n",
    "            for k, v in user_cfg.items():\n",
    "                if k in cfg:\n",
    "                    cfg[k] = v\n",
    "    except Exception as e:\n",
    "        print(f\"[config] using defaults (error reading config.json): {e}\")\n",
    "\n",
    "    # Ensure workbook directory exists\n",
    "    try:\n",
    "        os.makedirs(Path(cfg[\"excel_path\"]).parent, exist_ok=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return cfg\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Definition for PPTX\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "CFG = load_config()\n",
    "\n",
    "def _os_open(path: str) -> None:\n",
    "    try:\n",
    "        os.startfile(path)  # Windows\n",
    "    except AttributeError:\n",
    "        import subprocess, sys\n",
    "        if sys.platform == \"darwin\":\n",
    "            subprocess.run([\"open\", path])\n",
    "        else:\n",
    "            subprocess.run([\"xdg-open\", path])\n",
    "\n",
    "user_opts = {}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Actual Code\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "TILT_FACTORS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "\n",
    "# Bind config into existing globals you already use\n",
    "filename               = CFG[\"excel_path\"]\n",
    "MARGINAL_TAX_RATE      = float(CFG[\"marginal_tax_rate\"])\n",
    "CAPITAL_LOSS_CARRY_FWD = float(CFG[\"carry_forward_losses\"])\n",
    "LOT_MATCH_METHOD       = str(CFG[\"lot_match_method\"]).upper()\n",
    "OPEN_AFTER_SAVE        = bool(CFG.get(\"open_after_save\", True))\n",
    "USE_XLWINGS            = bool(CFG.get(\"use_xlwings\", True))\n",
    "\n",
    "def evaluate_transaction_costs(trade_df, lots_df, sale_date, tax_rate):\n",
    "    # Temporary placeholder to prevent crash\n",
    "    return {\"brokerage\": 0.0, \"cgt_tax\": 0.0, \"total_cost\": 0.0}\n",
    "\n",
    "def _read_lots_from_path(xl_path, sheet_name=\"Lots\"):\n",
    "    try:\n",
    "        return pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception:\n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "# --- Brokerage & CGT config (edit these to suit) ---\n",
    "BROKERAGE = {\n",
    "    \"ASX\": {\"first_buy_free_threshold\": 1000.0, \"min_fee\": 11.0, \"rate\": 0.001},  # 0.10%\n",
    "    \"US\":  {\"min_fee\": 0.0, \"rate\": 0.0},  # CMC U.S. brokerage $0\n",
    "}\n",
    "MARGINAL_TAX_RATE = 0.37           # your personal marginal rate (decimal)\n",
    "CAPITAL_LOSS_CARRY_FWD = 0.0       # prior year carried-forward capital losses (AUD)\n",
    "LOT_MATCH_METHOD = \"HIFO\"          # or \"FIFO\" (parcel-matching when selling)\n",
    "\n",
    "def ensure_workbook(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    with xw.App(visible=False, add_book=True) as app:\n",
    "        wb = app.books.add()\n",
    "        for nm in [\"Holdings\",\"Tilts\",\"OPT\",\"Input\",\"Cov\",\"FF5F\",\"Lots\"]:\n",
    "            try: wb.sheets[nm]\n",
    "            except: wb.sheets.add(nm)\n",
    "        # Minimal headers\n",
    "        wb.sheets[\"Holdings\"].range(\"A1\").value = [[\"Security\",\"Units\",\"Last Price\",\"FX to AUD\",\"Market Value\",\"Weight\",\"Include?\"]]\n",
    "        wb.sheets[\"Tilts\"].range(\"A1\").value = [[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "        wb.sheets[\"Tilts\"].range(\"A2\").value = [[f, (1.0 if i==0 else 0.0), 0.20, (i==0)] for i,f in enumerate(TILT_FACTORS)]\n",
    "        wb.sheets[\"Lots\"].range(\"A1\").value = [[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"]]\n",
    "        wb.save(path); wb.close()\n",
    "\n",
    "# Call it right before Block 7 seed reads:\n",
    "ensure_workbook(filename)\n",
    "\n",
    "# -------- Risk-free (AU): current RBA cash rate target --------\n",
    "def get_rba_cash_rate_target_current(default=0.04):\n",
    "    \"\"\"\n",
    "    Returns the latest RBA cash rate target as a decimal, scraped from:\n",
    "    https://www.rba.gov.au/statistics/cash-rate/\n",
    "    Falls back to the monthly-average CSV if needed, else `default`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dfs = pd.read_html(\"https://www.rba.gov.au/statistics/cash-rate/\", match=\"Cash rate target %\")\n",
    "        if dfs:\n",
    "            tab = dfs[0]\n",
    "            val = pd.to_numeric(tab.iloc[0][\"Cash rate target %\"], errors=\"coerce\")\n",
    "            if pd.notna(val):\n",
    "                return float(val) / 100.0\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        csv = \"https://www.rba.gov.au/statistics/tables/csv/f1.1-data.csv\"\n",
    "        df = pd.read_csv(csv)\n",
    "        col = next(c for c in df.columns if c.lower().startswith(\"cash rate target\"))\n",
    "        last = pd.to_numeric(df[col], errors=\"coerce\").dropna().iloc[-1]\n",
    "        return float(last) / 100.0\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "# -------- Simple on-disk cache (7-day TTL) for FF5 + MOM --------\n",
    "_CACHE_DIR = pathlib.Path(os.path.expanduser(\"~\")) / \".portfolio_optimiser_cache\"\n",
    "_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _cache_path(url: str) -> pathlib.Path:\n",
    "    key = hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "    return _CACHE_DIR / f\"{key}.csv\"\n",
    "\n",
    "def _cached_read(url: str, build_df_fn, ttl_days: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If we have a cached CSV newer than ttl_days, load it.\n",
    "    Otherwise call build_df_fn() to construct the DataFrame, then store it.\n",
    "    Assumes the DF has a DatetimeIndex.\n",
    "    \"\"\"\n",
    "    p = _cache_path(url)\n",
    "    try:\n",
    "        if p.exists():\n",
    "            age_sec = time.time() - p.stat().st_mtime\n",
    "            if age_sec <= ttl_days * 86400:\n",
    "                df = pd.read_csv(p, index_col=0, parse_dates=[0])\n",
    "                # ensure sorted Date index\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                return df.sort_index()\n",
    "    except Exception as e:\n",
    "        print(f\"[cache] read miss due to: {e}\")\n",
    "\n",
    "    df = build_df_fn()\n",
    "    try:\n",
    "        df.to_csv(p)\n",
    "    except Exception as e:\n",
    "        print(f\"[cache] write skipped due to: {e}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------- FF5F + Momentum loaders (Dartmouth) --------\n",
    "FF5_DAILY_ZIP = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip\"\n",
    "MOM_DAILY_ZIP = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_daily_CSV.zip\"\n",
    "\n",
    "def get_mom_daily():\n",
    "    def _builder():\n",
    "        r = requests.get(MOM_DAILY_ZIP, timeout=60); r.raise_for_status()\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        csv = next(n for n in z.namelist() if n.lower().endswith(\".csv\"))\n",
    "        raw = z.read(csv).decode(\"latin1\", errors=\"ignore\").splitlines()\n",
    "        num_rx = re.compile(r\"^\\s*\\d{6,8}\\s*[,\\s]\")\n",
    "        first = next(i for i, ln in enumerate(raw) if num_rx.match(ln))\n",
    "        header = \"Date,MOM\"\n",
    "        data = [header] + [ln.strip() for ln in raw[first:] if num_rx.match(ln)]\n",
    "        df = pd.read_csv(io.StringIO(\"\\n\".join(data)), engine=\"python\", sep=r\"\\s*,\\s*\")\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "        df[\"MOM\"] = pd.to_numeric(df[\"MOM\"], errors=\"coerce\") / 100.0  # decimal\n",
    "        return df[[\"MOM\"]]\n",
    "    df = _cached_read(MOM_DAILY_ZIP, _builder, ttl_days=7)\n",
    "    # ensure schema exactly as expected\n",
    "    df = df.copy()\n",
    "    if \"MOM\" not in df.columns:\n",
    "        df[\"MOM\"] = pd.to_numeric(df.iloc[:, 0], errors=\"coerce\")\n",
    "        df = df[[\"MOM\"]]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def get_ff5_daily(cache_csv_path=None):\n",
    "    \"\"\"\n",
    "    Fama–French 5 Factors (2x3) [Daily].\n",
    "    Returns columns (decimals): ['Mkt-RF','SMB','HML','RMW','CMA','RF'] indexed by Date.\n",
    "    Uses 7-day cached CSV in %USERPROFILE%\\\\.portfolio_optimiser_cache\n",
    "    \"\"\"\n",
    "    def _builder():\n",
    "        resp = requests.get(FF5_DAILY_ZIP, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "        csv_name = next(n for n in zf.namelist() if n.lower().endswith(\".csv\"))\n",
    "\n",
    "        raw = zf.read(csv_name).decode(\"latin1\", errors=\"ignore\")\n",
    "        lines = raw.splitlines()\n",
    "\n",
    "        num_rx = re.compile(r\"^\\s*\\d{6,8}\\s*[,\\s]\")\n",
    "        first_data_idx = next(i for i, ln in enumerate(lines) if num_rx.match(ln))\n",
    "\n",
    "        header_idx = None\n",
    "        for i in range(max(0, first_data_idx-5), first_data_idx+1):\n",
    "            if re.search(r\"\\bdate\\b\", lines[i], flags=re.I) and (\"mkt\" in lines[i].lower()):\n",
    "                header_idx = i\n",
    "                break\n",
    "\n",
    "        header = lines[header_idx].strip() if header_idx is not None else \"Date,Mkt-RF,SMB,HML,RMW,CMA,RF\"\n",
    "        data_lines = [header]\n",
    "        for ln in lines[first_data_idx:]:\n",
    "            if not num_rx.match(ln):\n",
    "                break\n",
    "            data_lines.append(ln.strip())\n",
    "\n",
    "        df = pd.read_csv(io.StringIO(\"\\n\".join(data_lines)), engine=\"python\", sep=r\"\\s*,\\s*\")\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        col_map = {c.lower().replace(\" \", \"\"): c for c in df.columns}\n",
    "        ren = {}\n",
    "        for want in [\"Date\",\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"RF\"]:\n",
    "            key = want.lower().replace(\" \", \"\")\n",
    "            if key in col_map:\n",
    "                ren[col_map[key]] = want\n",
    "        df = df.rename(columns=ren)\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "        factor_cols = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"RF\"]\n",
    "        df[factor_cols] = df[factor_cols].apply(pd.to_numeric, errors=\"coerce\") / 100.0\n",
    "        df = df.dropna(subset=factor_cols)\n",
    "        return df\n",
    "\n",
    "    df = _cached_read(FF5_DAILY_ZIP, _builder, ttl_days=7)\n",
    "\n",
    "    # Optional external cache file output for your own debugging\n",
    "    if cache_csv_path:\n",
    "        try:\n",
    "            df.to_csv(cache_csv_path, index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[ff5] could not write cache_csv_path: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ff5_mom_daily():\n",
    "    \"\"\"\n",
    "    Return daily factors as decimals with columns:\n",
    "    ['Mkt-RF','SMB','HML','RMW','CMA','MOM','RF'] on a common date index.\n",
    "    \"\"\"\n",
    "    ff5_only = get_ff5_daily()   # <-- was wrongly calling get_ff5_mom_daily()\n",
    "    mom = get_mom_daily()\n",
    "\n",
    "    out = ff5_only.join(mom, how=\"inner\").sort_index()\n",
    "    # reorder defensively (only keep columns that exist)\n",
    "    cols = [c for c in [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\",\"RF\"] if c in out.columns]\n",
    "    return out[cols]\n",
    "\n",
    "\n",
    "# -------- Foreign Exchange from Yahoo Finance --------\n",
    "def _last_numeric(x):\n",
    "    v = x.iloc[-1]\n",
    "    if isinstance(v, pd.Series):\n",
    "        v = v.iloc[0]\n",
    "    return float(v)\n",
    "\n",
    "def get_usd_aud_fx(default=1.50):\n",
    "    try:\n",
    "        px = yf.download(\"AUDUSD=X\", period=\"5d\", interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)[\"Close\"].dropna()\n",
    "        last = _last_numeric(px)\n",
    "        if last > 0:\n",
    "            return 1.0 / last                  # AUD per 1 USD\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        px = yf.download(\"USDAUD=X\", period=\"5d\", interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)[\"Close\"].dropna()\n",
    "        last = _last_numeric(px)\n",
    "        if last > 0:\n",
    "            return last                        # AUD per 1 USD\n",
    "    except Exception:\n",
    "        pass\n",
    "    return float(default)\n",
    "\n",
    "def fx_to_aud_for_tickers(tickers, usd_aud_rate):\n",
    "    \"\"\"1.0 for AUS tickers (*.AX) & indices (^...), usd_aud_rate for others (assume USD).\"\"\"\n",
    "    out = {}\n",
    "    for t in map(str, tickers):\n",
    "        out[t] = 1.0 if (t.startswith(\"^\") or t.endswith(\".AX\")) else float(usd_aud_rate)\n",
    "    return pd.Series(out, name=\"FX to AUD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 3 Downloading Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] Benchmarks downloaded successfully: ['^AORD', '^GSPC', '^IXIC']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) DOWNLOAD PRICES  — universe comes from Holdings sheet + static starters\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "# If Block 7 defines `filename`, we’ll reuse it. Otherwise set your path here.\n",
    "_XL_PATH = globals().get(\"filename\", _default_excel_path())\n",
    "\n",
    "# Your static “starter” universe (kept as a safety net / defaults)\n",
    "STATIC_STARTERS = ['^AORD']\n",
    "\n",
    "EXCLUDE_FROM_OPT = {'^AORD'}\n",
    "rf_annual = get_rba_cash_rate_target_current()\n",
    "rf_label = f\"{rf_annual*100:.2f}%\"\n",
    "chart_title = f\"Efficient Frontier & CAL (rf={rf_label})\"\n",
    "gamma_cgt = 1.0\n",
    "beta_brokerage = 5.0\n",
    "MIN_TRADE_VALUE = 200.0\n",
    "\n",
    "def _tickers_from_holdings(xl_path, sheet='Holdings'):\n",
    "    \"\"\"Extract 'Security' values using pandas (no COM).\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet)\n",
    "    except Exception:\n",
    "        return []\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty or \"Security\" not in df.columns:\n",
    "        return []\n",
    "    sec = (df[\"Security\"].dropna().astype(str).str.strip())\n",
    "    return list(dict.fromkeys([t for t in sec if t]))\n",
    "\n",
    "# 0) Build the universe\n",
    "tickers_from_sheet = _tickers_from_holdings(_XL_PATH, sheet='Holdings')  # dynamic\n",
    "tickers = list(dict.fromkeys((tickers_from_sheet or []) + STATIC_STARTERS))\n",
    "if '^AORD' not in tickers:\n",
    "    tickers.insert(0, '^AORD')  # always include benchmark\n",
    "\n",
    "# 1) Download prices (robust to single/ multiple tickers)\n",
    "PRICE_PERIOD = '2y'  # set '1y'/'3y' as you like\n",
    "dl = yf.download(tickers, period=PRICE_PERIOD, auto_adjust=True, threads=False, progress=False)\n",
    "\n",
    "if isinstance(dl, pd.DataFrame) and 'Close' in dl.columns:\n",
    "    prices = dl['Close']\n",
    "else:\n",
    "    # yfinance can return a Series for a single ticker\n",
    "    prices = dl if isinstance(dl, pd.Series) else pd.DataFrame()\n",
    "    if isinstance(prices, pd.Series):\n",
    "        prices = prices.to_frame(name=tickers[0])\n",
    "prices.index = pd.to_datetime(prices.index)\n",
    "prices = prices.sort_index()\n",
    "prices = prices.loc[:, ~prices.columns.duplicated()]  # de-dup any duplicate tickers defensively\n",
    "\n",
    "# ------------- FX conversion for US stocks (to AUD for returns) ------------------\n",
    "\n",
    "# 1) AUD per 1 USD (ensure we end up with a Series)\n",
    "fx_raw = yf.download(\"USDAUD=X\", period=\"5y\", interval=\"1d\",\n",
    "                     auto_adjust=True, threads=False, progress=False)\n",
    "fx = fx_raw[\"Close\"] if isinstance(fx_raw, pd.DataFrame) else fx_raw\n",
    "if isinstance(fx, pd.DataFrame):\n",
    "    fx = fx.iloc[:, 0]\n",
    "fx = pd.to_numeric(fx, errors=\"coerce\").reindex(prices.index).ffill()\n",
    "\n",
    "# identify USD-priced tickers\n",
    "usd_cols = [str(c) for c in prices.columns if not str(c).endswith(\".AX\") and not str(c).startswith(\"^\")]\n",
    "\n",
    "# build an AUD-converted copy safely\n",
    "prices_aud_for_returns = prices.copy()\n",
    "usd_part = prices.loc[:, usd_cols].mul(fx, axis=0)  # align by date\n",
    "prices_aud_for_returns.update(usd_part)\n",
    "\n",
    "# 4) Compute returns *from AUD-converted prices*\n",
    "df = prices_aud_for_returns.reset_index()\n",
    "df_melt = (\n",
    "    prices_aud_for_returns.reset_index()\n",
    "      .melt(id_vars='Date', var_name='Security', value_name='Close')\n",
    "      .sort_values(['Security','Date'])\n",
    ")\n",
    "df_melt['Return'] = df_melt.groupby('Security', sort=False)['Close'].pct_change(fill_method=None)\n",
    "df_melt = df_melt.dropna()\n",
    "\n",
    "# 5) FX map for holdings (last-price conversion in the sheet)\n",
    "usd_aud = get_usd_aud_fx()\n",
    "fx_map_all = fx_to_aud_for_tickers(prices.columns, usd_aud)\n",
    "\n",
    "# ------------- Benchmark Indices for Performance Comparison ------------------\n",
    "\n",
    "try:\n",
    "    benchmarks = [\"^AORD\", \"^GSPC\", \"^IXIC\"]  # ASX All Ords, S&P500, NASDAQ\n",
    "    start_date = prices.index[0]\n",
    "    end_date = prices.index[-1]\n",
    "\n",
    "    benchmark_data = yf.download(\n",
    "        benchmarks,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        progress=False,\n",
    "        auto_adjust=True,\n",
    "        threads=False\n",
    "    )\n",
    "\n",
    "    # Handle both multi- and single-index formats\n",
    "    if isinstance(benchmark_data.columns, pd.MultiIndex):\n",
    "        benchmark_data = benchmark_data[\"Close\"]\n",
    "\n",
    "    benchmark_data = benchmark_data.ffill().bfill()\n",
    "    print(f\"[data] Benchmarks downloaded successfully: {list(benchmark_data.columns)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[data] Skipped benchmark download: {e}\")\n",
    "    benchmark_data = pd.DataFrame()\n",
    "\n",
    "# --- Store benchmark data for downstream reporting (PowerPoint, etc.) ---\n",
    "if \"data_dict\" not in globals():\n",
    "    data_dict = {}\n",
    "\n",
    "data_dict[\"benchmark_data\"] = benchmark_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 4 Creating the Stock Holdings Dialog Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2) GUI portfolio editor (Tkinter) + helpers — CLEAN VERSION\n",
    "# -------------------------------\n",
    "\n",
    "def _fetch_prices_for_new_tickers(tickers_new, base_prices, period='5y'):\n",
    "    add = [t for t in map(str, tickers_new) if t not in base_prices.columns]\n",
    "    if not add:\n",
    "        return base_prices\n",
    "    try:\n",
    "        dl = yf.download(add, period=period, auto_adjust=True, threads=False, progress=False)\n",
    "        if isinstance(dl, pd.DataFrame) and 'Close' in dl.columns:\n",
    "            dl = dl['Close']          # wide DataFrame if multiple tickers\n",
    "        if isinstance(dl, pd.Series):  # single ticker case → rename to that ticker\n",
    "            name = add[0]\n",
    "            dl = dl.rename(name).to_frame()\n",
    "        dl.index = pd.to_datetime(dl.index)\n",
    "        out = base_prices.join(dl, how='outer').sort_index()\n",
    "        out = out.loc[:, ~out.columns.duplicated()]\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not fetch some tickers {add}: {e}\")\n",
    "        return base_prices\n",
    "\n",
    "# -------- File-based seed readers (no COM, reliable) --------\n",
    "def _read_holdings_seed_from_path(xl_path, sheet_name=\"Holdings\"):\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed-path] holdings: {e} -> EMPTY\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty or \"Security\" not in df.columns:\n",
    "        print(\"[seed-path] holdings: empty/malformed -> EMPTY\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "\n",
    "    units = pd.to_numeric(df.get(\"Units\", 0.0), errors=\"coerce\").fillna(0.0)\n",
    "    if \"Include?\" in df.columns:\n",
    "        inc = df[\"Include?\"].astype(str).str.strip().str.upper().isin({\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"})\n",
    "    else:\n",
    "        inc = pd.Series(True, index=df.index)\n",
    "\n",
    "    units = pd.Series(units.values, index=df[\"Security\"])\n",
    "    include = dict(zip(df[\"Security\"], inc.astype(bool)))\n",
    "    print(f\"[seed-path] holdings: rows={len(units)}, nonzero={int((units!=0).sum())}\")\n",
    "    return units, include\n",
    "\n",
    "\n",
    "def _read_tilts_seed_from_path(xl_path, sheet_name=\"Tilts\"):\n",
    "    # respect global factor list if you defined MOM in Block 2:\n",
    "    # e.g. TILT_FACTORS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "    factors = list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
    "    default = pd.DataFrame(\n",
    "        {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "         \"Band\":   [0.05]*len(factors),\n",
    "         \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "        index=factors\n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed-path] tilts: {e} -> DEFAULTS\"); return default\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        print(\"[seed-path] tilts: empty -> DEFAULTS\"); return default\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    need = {\"Factor\",\"Target\",\"Band\",\"Use?\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        print(\"[seed-path] tilts: malformed -> DEFAULTS\"); return default\n",
    "\n",
    "    df[\"Factor\"] = df[\"Factor\"].astype(str).str.strip()\n",
    "    df = df.set_index(\"Factor\").reindex(factors)\n",
    "    out = default.copy()\n",
    "    out.loc[df.index, \"Target\"] = pd.to_numeric(df[\"Target\"], errors=\"coerce\")\n",
    "    out.loc[df.index, \"Band\"]   = pd.to_numeric(df[\"Band\"],   errors=\"coerce\")\n",
    "    out.loc[df.index, \"Use?\"]   = df[\"Use?\"].astype(str).str.upper().isin([\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"])\n",
    "    out[\"Target\"] = out[\"Target\"].fillna(default[\"Target\"]).astype(float)\n",
    "    out[\"Band\"]   = out[\"Band\"].fillna(default[\"Band\"]).astype(float)\n",
    "    return out.reindex(factors)\n",
    "\n",
    "# -------------------------------\n",
    "# SAFE seeds I/O used by Block 7 (readers only)\n",
    "# -------------------------------\n",
    "def _read_holdings_seed_from_sheet(wb, sheet_name=\"Holdings\"):\n",
    "    if wb is None:\n",
    "        print(\"[seed] holdings: wb is None -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        print(f\"[seed] holdings: sheet '{sheet_name}' not found -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "    try:\n",
    "        ur = sht.used_range\n",
    "        if ur is None:\n",
    "            print(\"[seed] holdings: used_range is None -> EMPTY seeds\")\n",
    "            return pd.Series(dtype=float), {}\n",
    "        vals = ur.options(ndim=2).value\n",
    "        if not vals or not vals[0] or all(h is None for h in vals[0]):\n",
    "            print(\"[seed] holdings: used_range has no headers -> EMPTY seeds\")\n",
    "            return pd.Series(dtype=float), {}\n",
    "        headers = [str(c).strip() if c is not None else \"\" for c in vals[0]]\n",
    "        rows = vals[1:] if len(vals) > 1 else []\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed] holdings: failed to read table: {e}\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    if df.empty or \"Security\" not in df.columns:\n",
    "        print(\"[seed] holdings: empty/malformed -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "    units = pd.to_numeric(df.get(\"Units\", 0.0), errors=\"coerce\").fillna(0.0)\n",
    "    if \"Include?\" in df.columns:\n",
    "        inc = df[\"Include?\"].astype(str).str.strip().str.upper().isin({\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"})\n",
    "    else:\n",
    "        inc = pd.Series(True, index=df.index)\n",
    "    units = pd.Series(units.values, index=df[\"Security\"])\n",
    "    include = dict(zip(df[\"Security\"], inc.astype(bool)))\n",
    "    print(f\"[seed] holdings: loaded {int((units!=0).sum())} non-zero unit rows (of {len(units)})\")\n",
    "    return units, include\n",
    "\n",
    "\n",
    "def _read_tilts_seed_from_sheet(wb, sheet_name=\"Tilts\"):\n",
    "    factors = list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
    "    default = pd.DataFrame(\n",
    "        {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "         \"Band\":   [0.05]*len(factors),\n",
    "         \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "        index=factors\n",
    "    )\n",
    "\n",
    "    if wb is None:\n",
    "        print(\"[seed] tilts: wb is None -> DEFAULTS\"); return default\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        print(f\"[seed] tilts: sheet '{sheet_name}' not found -> DEFAULTS\"); return default\n",
    "\n",
    "    try:\n",
    "        ur = sht.used_range\n",
    "        if ur is None:\n",
    "            print(\"[seed] tilts: used_range is None -> DEFAULTS\"); return default\n",
    "        vals = ur.options(ndim=2).value\n",
    "        if not vals or not vals[0] or all(h is None for h in vals[0]):\n",
    "            print(\"[seed] tilts: no data -> DEFAULTS\"); return default\n",
    "        headers = [str(c).strip() if c is not None else \"\" for c in vals[0]]\n",
    "        rows = vals[1:] if len(vals) > 1 else []\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed] tilts: failed to read table: {e} -> DEFAULTS\"); return default\n",
    "\n",
    "    need = {\"Factor\",\"Target\",\"Band\",\"Use?\"}\n",
    "    if df.empty or not need.issubset(df.columns):\n",
    "        print(\"[seed] tilts: malformed -> DEFAULTS\"); return default\n",
    "\n",
    "    df[\"Factor\"] = df[\"Factor\"].astype(str).str.strip()\n",
    "    df = df.set_index(\"Factor\").reindex(factors)\n",
    "\n",
    "    out = default.copy()\n",
    "    out.loc[df.index, \"Target\"] = pd.to_numeric(df[\"Target\"], errors=\"coerce\")\n",
    "    out.loc[df.index, \"Band\"]   = pd.to_numeric(df[\"Band\"],   errors=\"coerce\")\n",
    "    out.loc[df.index, \"Use?\"]   = df[\"Use?\"].astype(str).str.upper().isin([\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"])\n",
    "    out[\"Target\"] = out[\"Target\"].fillna(default[\"Target\"]).astype(float)\n",
    "    out[\"Band\"]   = out[\"Band\"].fillna(default[\"Band\"]).astype(float)\n",
    "    return out.reindex(factors)\n",
    "\n",
    "# -------------------------------\n",
    "# Writers (used by Block 7)\n",
    "# -------------------------------\n",
    "def _write_tilts_sheet(wb, tilts_df, sheet_name=\"Tilts\"):\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        sht = wb.sheets.add(sheet_name, after=wb.sheets[-1])\n",
    "    try:\n",
    "        sht.used_range.clear_contents()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    out = tilts_df.reset_index().rename(columns={\"index\": \"Factor\"})\n",
    "    out = out[[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "    sht.range(\"A1\").value = [[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "    sht.range(\"A2\").options(index=False, header=False).value = out\n",
    "    last_row = 1 + len(out)\n",
    "    try:\n",
    "        sht.range(f\"B2:B{last_row}\").api.NumberFormat = \"0.000\"\n",
    "        sht.range(f\"C2:C{last_row}\").api.NumberFormat = \"0.000\"\n",
    "        val_rng = sht.range(f\"D2:D{last_row}\").api\n",
    "        val_rng.Validation.Delete()\n",
    "        val_rng.Validation.Add(3, 1, 1, \"TRUE,FALSE\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    sht.autofit()\n",
    "\n",
    "\n",
    "def _write_holdings_sheet(wb, prices, units, include_flags,\n",
    "                          sheet_name=\"Holdings\", fx_to_aud_map=None):\n",
    "    if fx_to_aud_map is None:\n",
    "        usd_aud = get_usd_aud_fx()\n",
    "        fx_to_aud_map = fx_to_aud_for_tickers(prices.columns, usd_aud)\n",
    "\n",
    "    tickers_all = [\n",
    "        t for t in prices.columns \n",
    "        if t != \"PortfolioValue\"\n",
    "    ]    \n",
    "    last_px = prices.ffill().iloc[-1]\n",
    "    rows = []\n",
    "    units_s = pd.Series(units)\n",
    "    include_s = pd.Series(include_flags)\n",
    "    for t in tickers_all:\n",
    "        inc = bool(include_s.get(t, False))\n",
    "        rows.append({\n",
    "            \"Security\": t,\n",
    "            \"Units\": float(units_s.get(t, 0.0)),\n",
    "            \"Last Price\": float(pd.Series(last_px).get(t, np.nan)),\n",
    "            \"FX to AUD\": float(pd.Series(fx_to_aud_map).get(t, 1.0)),\n",
    "            \"Market Value\": 0.0,\n",
    "            \"Weight\": 0.0,\n",
    "            \"Include?\": inc\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        sht = wb.sheets.add(sheet_name, after=wb.sheets[-1])\n",
    "    try:\n",
    "        sht.used_range.clear_contents()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    sht.range('A1').value = [[\"Security\",\"Units\",\"Last Price\",\"FX to AUD\",\"Market Value\",\"Weight\",\"Include?\"]]\n",
    "    sht.range('A2').options(index=False, header=False).value = df\n",
    "    n = len(df); last_row = 1 + n\n",
    "    last_row = 1 + len(df)\n",
    "    if n >= 1:\n",
    "        sht.range('E2').formula = \"=B2*C2*D2\"\n",
    "        if n > 1:\n",
    "            sht.range(f\"E2:E{last_row}\").api.FillDown()\n",
    "        sumif_den = f\"SUMIF($G$2:$G${last_row},TRUE,$E$2:$E${last_row})\"\n",
    "        sht.range('F2').formula = f\"=IF({sumif_den}=0,0,IF($G2,E2/{sumif_den},0))\"\n",
    "        if n > 1:\n",
    "            sht.range(f\"F2:F{last_row}\").api.FillDown()\n",
    "        try:\n",
    "            val_rng = sht.range(f\"G2:G{last_row}\").api\n",
    "            val_rng.Validation.Delete()\n",
    "            val_rng.Validation.Add(3, 1, 1, \"TRUE,FALSE\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            sht.range(f\"C2:C{last_row}\").api.NumberFormat = \"0.0000\"\n",
    "            sht.range(f\"D2:D{last_row}\").api.NumberFormat = \"0.0000\"\n",
    "            sht.range(f\"E2:E{last_row}\").api.NumberFormat = \"$0.00\"\n",
    "            sht.range(f\"F2:F{last_row}\").api.NumberFormat = \"0.00%\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    sht.autofit()\n",
    "\n",
    "# -------------------------------\n",
    "# Dialog shims (no windows here)\n",
    "# -------------------------------\n",
    "def edit_holdings_dialog(prices, exclude, seed_units, seed_include, title=\"Edit Portfolio Holdings\"):\n",
    "    units_ser = seed_units.copy()\n",
    "    include_flags = dict(seed_include)\n",
    "    last_price_ser = prices.ffill().iloc[-1].reindex(units_ser.index)\n",
    "    return units_ser, last_price_ser, prices, include_flags\n",
    "\n",
    "def edit_tilts_dialog(seed_df):\n",
    "    return seed_df.copy()\n",
    "\n",
    "# -------------------------------\n",
    "# Combined dialog (one window)\n",
    "# -------------------------------\n",
    "def edit_holdings_and_tilts_dialog(prices, exclude, seed_units, seed_include, seed_tilts,\n",
    "                                   title=\"Edit Holdings & Factor Tilts\"):\n",
    "    \"\"\"\n",
    "    Returns: (units_series, last_price_series, prices_df, include_flags_dict, tilts_df)\n",
    "    \"\"\"\n",
    "    tickers_all = [t for t in prices.columns if t != \"PortfolioValue\"]\n",
    "    exclude = set(exclude or [])\n",
    "    last_px = prices.ffill().iloc[-1]\n",
    "\n",
    "    # factor list (use global TILT_FACTORS if set, so MOM shows up)\n",
    "    factors = list(seed_tilts.index) if isinstance(seed_tilts, pd.DataFrame) and not seed_tilts.empty \\\n",
    "              else (list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"])\n",
    "    if not isinstance(seed_tilts, pd.DataFrame) or seed_tilts.empty:\n",
    "        seed_tilts = pd.DataFrame(\n",
    "            {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "             \"Band\":   [0.05]*len(factors),\n",
    "             \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "            index=factors\n",
    "        )\n",
    "\n",
    "    root = _tk.Tk()\n",
    "    root.title(title)\n",
    "    root.geometry(\"980x640\")\n",
    "    root.minsize(920, 560)\n",
    "\n",
    "    # === Main layout ===\n",
    "    frm_main = _ttk.Frame(root, padding=10); frm_main.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # Left: holdings\n",
    "    frm_left = _ttk.LabelFrame(frm_main, text=\"Holdings\", padding=10)\n",
    "    frm_left.pack(side=\"left\", fill=\"both\", expand=True, padx=(0, 6))\n",
    "    for i in range(3):\n",
    "        frm_left.rowconfigure(i, weight=(1 if i == 1 else 0))\n",
    "    frm_left.columnconfigure(0, weight=1)\n",
    "\n",
    "    # Header\n",
    "    header = _ttk.Frame(frm_left); header.grid(row=0, column=0, sticky=\"ew\")\n",
    "    _ttk.Label(header, text=\"Inc?\", width=5).grid(row=0, column=0, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Del?\", width=5).grid(row=0, column=1, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Security\", width=20).grid(row=0, column=2, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Units\", width=14).grid(row=0, column=3, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Last Price\", width=12).grid(row=0, column=4, sticky=\"w\")\n",
    "\n",
    "    # Scrollable list\n",
    "    list_container = _ttk.Frame(frm_left); list_container.grid(row=1, column=0, sticky=\"nsew\", pady=(4, 6))\n",
    "    list_container.rowconfigure(0, weight=1); list_container.columnconfigure(0, weight=1)\n",
    "    canvas = _tk.Canvas(list_container, highlightthickness=0)\n",
    "    scroll_y = _ttk.Scrollbar(list_container, orient=\"vertical\", command=canvas.yview)\n",
    "    body = _ttk.Frame(canvas)\n",
    "    body.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "    canvas.create_window((0, 0), window=body, anchor=\"nw\")\n",
    "    canvas.configure(yscrollcommand=scroll_y.set)\n",
    "    canvas.grid(row=0, column=0, sticky=\"nsew\"); scroll_y.grid(row=0, column=1, sticky=\"ns\")\n",
    "\n",
    "    def _on_mousewheel(event):\n",
    "        if event.delta:\n",
    "            canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
    "        elif getattr(event, \"num\", None) in (4, 5):\n",
    "            canvas.yview_scroll(-1 if event.num == 4 else 1, \"units\")\n",
    "    body.bind(\"<Enter>\", lambda e: canvas.bind_all(\"<MouseWheel>\", _on_mousewheel))\n",
    "    body.bind(\"<Leave>\", lambda e: canvas.unbind_all(\"<MouseWheel>\"))\n",
    "    canvas.bind_all(\"<Button-4>\", _on_mousewheel); canvas.bind_all(\"<Button-5>\", _on_mousewheel)\n",
    "\n",
    "    row_vars = {}\n",
    "    def _add_row(ticker, units_default=0.0, include_default=True, disabled=False):\n",
    "        r = len(row_vars) + 1\n",
    "        v_inc = _tk.BooleanVar(value=(False if disabled else bool(include_default)))\n",
    "        v_del = _tk.BooleanVar(value=False)\n",
    "        v_units = _tk.StringVar(value=(\"0\" if disabled else str(float(units_default))))\n",
    "        chk_inc = _ttk.Checkbutton(body, variable=v_inc)\n",
    "        chk_del = _ttk.Checkbutton(body, variable=v_del)\n",
    "        ent = _ttk.Entry(body, textvariable=v_units, width=16)\n",
    "        lbl_t = _ttk.Label(body, text=str(ticker), width=20)\n",
    "        last_px_str = f\"{float(last_px.get(ticker, float('nan'))):.4f}\"\n",
    "        lbl_px = _ttk.Label(body, text=last_px_str, width=12)\n",
    "        if disabled:\n",
    "            chk_inc.state([\"disabled\"]); ent.state([\"disabled\"]); lbl_t.configure(foreground=\"#888\")\n",
    "        chk_inc.grid(row=r, column=0, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        chk_del.grid(row=r, column=1, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        lbl_t.grid(row=r, column=2, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        ent.grid(row=r, column=3, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        lbl_px.grid(row=r, column=4, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        row_vars[ticker] = {\"inc\": v_inc, \"del\": v_del, \"units\": v_units, \"disabled\": disabled, \"lbl_px\": lbl_px}\n",
    "\n",
    "    # Prefill rows\n",
    "    for t in tickers_all:\n",
    "        disabled = (t in exclude)\n",
    "        inc_default = bool(pd.Series(seed_include).get(t, True)) and not disabled\n",
    "        units_default = float(pd.Series(seed_units).get(t, 0.0))\n",
    "        _add_row(t, units_default=units_default, include_default=inc_default, disabled=disabled)\n",
    "\n",
    "    # Add-holding box\n",
    "    add_box = _ttk.LabelFrame(frm_left, text=\"Add holding\", padding=10)\n",
    "    add_box.grid(row=2, column=0, sticky=\"ew\")\n",
    "    _ttk.Label(add_box, text=\"Ticker\").grid(row=0, column=0, sticky=\"w\")\n",
    "    ent_new_ticker = _ttk.Entry(add_box, width=18); ent_new_ticker.grid(row=0, column=1, sticky=\"w\", padx=(4, 12))\n",
    "    _ttk.Label(add_box, text=\"Units\").grid(row=0, column=2, sticky=\"w\")\n",
    "    ent_new_units = _ttk.Entry(add_box, width=14); ent_new_units.grid(row=0, column=3, sticky=\"w\", padx=(4, 12))\n",
    "    _btn_add = _ttk.Button(add_box, text=\"Add\"); _btn_add.grid(row=0, column=4, sticky=\"w\")\n",
    "    added_tickers = []\n",
    "    def _do_add():\n",
    "        t = ent_new_ticker.get().strip()\n",
    "        if not t:\n",
    "            _mb.showwarning(\"Add holding\", \"Please enter a ticker.\"); return\n",
    "        t = t.upper()\n",
    "        if t in row_vars:\n",
    "            _mb.showinfo(\"Add holding\", f\"{t} already listed.\"); return\n",
    "        try:\n",
    "            u = float(ent_new_units.get().strip()) if ent_new_units.get().strip() else 0.0\n",
    "        except ValueError:\n",
    "            _mb.showwarning(\"Add holding\", \"Units must be numeric.\"); return\n",
    "        _add_row(t, units_default=u, include_default=True, disabled=(t in exclude))\n",
    "        added_tickers.append(t)\n",
    "        ent_new_ticker.delete(0, _tk.END); ent_new_units.delete(0, _tk.END)\n",
    "    _btn_add.configure(command=_do_add)\n",
    "\n",
    "    # Right panel — Factor Tilts\n",
    "    frm_right = _ttk.LabelFrame(frm_main, text=\"Factor Tilts\", padding=10)\n",
    "    frm_right.pack(side=\"right\", fill=\"y\", padx=(6, 0))\n",
    "    _ttk.Label(frm_right, text=\"Use?\",    width=5 ).grid(row=0, column=0, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Factor\",  width=12).grid(row=0, column=1, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Target β\",width=10).grid(row=0, column=2, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Band\",    width=10).grid(row=0, column=3, sticky=\"w\")\n",
    "\n",
    "    tilt_vars = {}\n",
    "    for i, f in enumerate(factors, start=1):\n",
    "        use_default  = bool(seed_tilts.loc[f, \"Use?\"])   if f in seed_tilts.index else False\n",
    "        tgt_default  = float(seed_tilts.loc[f, \"Target\"]) if f in seed_tilts.index else 0.0\n",
    "        band_default = float(seed_tilts.loc[f, \"Band\"])   if f in seed_tilts.index else 0.05\n",
    "        v_use = _tk.BooleanVar(value=use_default)\n",
    "        v_tgt = _tk.StringVar(value=f\"{tgt_default:.3f}\")\n",
    "        v_bnd = _tk.StringVar(value=f\"{band_default:.3f}\")\n",
    "        _ttk.Checkbutton(frm_right, variable=v_use).grid(row=i, column=0, sticky=\"w\", pady=2)\n",
    "        _ttk.Label(frm_right, text=f, width=12).grid(row=i, column=1, sticky=\"w\", pady=2)\n",
    "        _ttk.Entry(frm_right, textvariable=v_tgt, width=10).grid(row=i, column=2, sticky=\"w\", pady=2)\n",
    "        _ttk.Entry(frm_right, textvariable=v_bnd, width=10).grid(row=i, column=3, sticky=\"w\", pady=2)\n",
    "        tilt_vars[f] = (v_use, v_tgt, v_bnd)\n",
    "\n",
    "    # after fac_cols/f_mean_ann are available (you have them earlier), pass them in or recompute locally.\n",
    "    def _compute_recommended_tilts():\n",
    "        try:\n",
    "            ff = get_ff5_mom_daily().tail(FF5_LOOKBACK_DAYS)\n",
    "            fac_cols = [c for c in ff.columns if c != \"RF\"]\n",
    "            Fcov_daily = ff[fac_cols].cov()\n",
    "            f_mean_ann = ff[fac_cols].mean() * 252.0\n",
    "            # use the betas you already computed for the current prices window\n",
    "            reco, _wtilt = recommend_factor_tilts_achievable(B, f_mean_ann, Fcov_daily)\n",
    "            # ensure we return values for all factors in the dialog order\n",
    "            return reco.reindex(list(seed_tilts.index)).fillna(0.0)\n",
    "        except Exception:\n",
    "            return pd.Series(0.0, index=list(seed_tilts.index))\n",
    "    \n",
    "    def _apply_recommended_tilts():\n",
    "        rec = _compute_recommended_tilts()\n",
    "        for f in factors:\n",
    "            v_use, v_tgt, v_bnd = tilt_vars[f]\n",
    "            v_use.set(True)\n",
    "            v_tgt.set(f\"{float(rec.get(f,0.0)):.3f}\")\n",
    "            # keep user band or set to a gentle default:\n",
    "            if not v_bnd.get():\n",
    "                v_bnd.set(\"0.200\")\n",
    "        _mb.showinfo(\"Tilts\", \"Recommended tilts applied.\\n(You can still edit before Save.)\")\n",
    "    \n",
    "    btn_reco = _ttk.Button(frm_right, text=\"Auto-recommend tilts\", command=_apply_recommended_tilts)\n",
    "    btn_reco.grid(row=len(factors)+2, column=0, columnspan=4, sticky=\"ew\", pady=(12,0))\n",
    "\n",
    "    # Buttons\n",
    "    def _reset_to_seed_units():\n",
    "        su = pd.Series(seed_units).astype(float)  # seed_units is already a parameter to this function\n",
    "        for t, vs in row_vars.items():\n",
    "            if vs.get(\"disabled\"):\n",
    "                continue\n",
    "            vs[\"units\"].set(str(int(round(su.get(t, 0.0)))))\n",
    "        _mb.showinfo(\"Holdings\", \"Units reset to the values loaded from Excel at the start of this run.\")\n",
    "\n",
    "    \n",
    "    frm_btns = _ttk.Frame(root, padding=(10, 0, 10, 10)); frm_btns.pack(fill=\"x\")\n",
    "    _ttk.Button(frm_btns, text=\"Reset to Seed\", command=_reset_to_seed_units).pack(side=\"left\", padx=6)\n",
    "    _ttk.Button(frm_btns, text=\"Cancel\", command=root.destroy).pack(side=\"right\", padx=6)\n",
    "\n",
    "    def _on_save():\n",
    "        nonlocal prices\n",
    "        if added_tickers:\n",
    "            prices = _fetch_prices_for_new_tickers(added_tickers, prices)\n",
    "\n",
    "        to_delete = []\n",
    "        units_out, include_flags = {}, {}\n",
    "        for t, vs in row_vars.items():\n",
    "            mark_delete = bool(vs[\"del\"].get())\n",
    "            disabled = vs[\"disabled\"]\n",
    "            inc = bool(vs[\"inc\"].get()) and not disabled and not mark_delete\n",
    "            include_flags[t] = inc\n",
    "            if mark_delete:\n",
    "                to_delete.append(t)\n",
    "                continue\n",
    "            if not disabled:\n",
    "                txt = vs[\"units\"].get().strip()\n",
    "                try:\n",
    "                    val = float(txt) if txt else 0.0\n",
    "                except ValueError:\n",
    "                    val = 0.0\n",
    "                units_out[t] = val\n",
    "            # refresh last px label\n",
    "            if t in prices.columns:\n",
    "                try:\n",
    "                    lp = float(prices.ffill().iloc[-1].get(t, float('nan')))\n",
    "                    vs[\"lbl_px\"].configure(text=f\"{lp:.4f}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # remove deleted names from the price panel so they don’t enter μ/Σ\n",
    "        if to_delete:\n",
    "            keep = [c for c in prices.columns if c not in set(to_delete)]\n",
    "            prices = prices.reindex(columns=keep)\n",
    "\n",
    "        units_ser = pd.Series(units_out, dtype=float)\n",
    "        last_price_ser = prices.ffill().iloc[-1].reindex(units_ser.index)\n",
    "\n",
    "        out_rows = []\n",
    "        for f, (v_use, v_tgt, v_bnd) in tilt_vars.items():\n",
    "            try:  tgt = float(v_tgt.get())\n",
    "            except ValueError: tgt = 0.0\n",
    "            try:  bnd = float(v_bnd.get())\n",
    "            except ValueError: bnd = 0.05\n",
    "            out_rows.append({\"Factor\": f, \"Target\": tgt, \"Band\": bnd, \"Use?\": bool(v_use.get())})\n",
    "        tilts_df = pd.DataFrame(out_rows).set_index(\"Factor\").reindex(factors)\n",
    "\n",
    "        edit_holdings_and_tilts_dialog.result = (units_ser, last_price_ser, prices, include_flags, tilts_df)\n",
    "        root.destroy()\n",
    "\n",
    "    _ttk.Button(frm_btns, text=\"Save\", command=_on_save).pack(side=\"right\", padx=6)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", root.destroy)\n",
    "    root.mainloop()\n",
    "    return getattr(edit_holdings_and_tilts_dialog, \"result\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 5 Creating the Covariance Matrix and the Rest of the OPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FX-adjusted returns for Sigma?: True (max |diff|=0.00e+00)\n",
      "\n",
      "Recommended factor tilts (based on current factor premia):\n",
      "Mkt-RF    1.000\n",
      "SMB      -1.203\n",
      "HML       1.349\n",
      "RMW      -0.828\n",
      "CMA      -0.871\n",
      "MOM       0.350\n",
      "Name: Recommended β, dtype: float64\n",
      "\n",
      "=== LOTS_DF HEAD ===\n",
      "   Security    AcqDate  Units  CostBaseAUD\n",
      "0    AT1.AX 2025-11-07    869     0.024000\n",
      "1    AT1.AX 2025-11-07     12     0.024000\n",
      "2    AT1.AX 2025-11-07     18     0.024000\n",
      "3    AT1.AX 2025-11-07     14     0.024000\n",
      "4    AT1.AX 2025-11-07     53     0.024000\n",
      "5    LKE.AX 2025-11-14  28051     0.057000\n",
      "6    AT1.AX 2025-11-21   1840     0.025000\n",
      "7    VSO.AX 2025-11-21     20    74.779999\n",
      "8    VSO.AX 2025-11-21      1    74.730003\n",
      "9    VSO.AX 2025-11-21     54    74.639999\n",
      "10  SMLL.AX 2025-11-21     36     4.495000\n",
      "11   AT1.AX 2025-11-21  27045     0.027000\n",
      "12  ETHI.AX 2025-11-21    273    16.200001\n",
      "13      GME 2025-11-21    270    30.918965\n",
      "14   LKE.AX 2025-11-21   5376     0.062000\n",
      "15  MTUM.AX 2025-11-21    126    28.549999\n",
      "16   NDQ.AX 2025-11-21     71    55.169998\n",
      "17  QLTY.AX 2025-11-21    122    32.419998\n",
      "18  QUAL.AX 2025-11-21    205    60.930000\n",
      "19  SMLL.AX 2025-11-21   1089     4.470000\n",
      "\n",
      "--- DEBUG CHECK: Sigma_opt / mu_vec_opt ---\n",
      "Any NaN in Sigma_opt: False\n",
      "Any NaN in mu_vec_opt: False\n",
      "Min variance: 4.193233307339958e-05\n",
      "Number of assets: 30\n",
      "          A200.AX   ACDC.AX    AT1.AX   BBUS.AX   BEAR.AX        BHP.AX  \\\n",
      "A200.AX  0.000059  0.000001 -0.000002 -0.000003 -0.000002 -1.140744e-08   \n",
      "ACDC.AX  0.000001  0.000169  0.000001 -0.000004 -0.000001  5.542393e-08   \n",
      "AT1.AX  -0.000002  0.000001  0.002684  0.000001  0.000003 -1.224184e-07   \n",
      "BBUS.AX -0.000003 -0.000004  0.000001  0.000623  0.000004 -4.908184e-08   \n",
      "BEAR.AX -0.000002 -0.000001  0.000003  0.000004  0.000060 -1.886002e-07   \n",
      "\n",
      "             BLOK    CBA.AX        CSL.AX       ETHI.AX  ...       SMLL.AX  \\\n",
      "A200.AX  0.000010  0.000002  5.995056e-07  1.157309e-06  ...  6.654853e-07   \n",
      "ACDC.AX  0.000005  0.000002  1.018810e-06  1.542335e-06  ...  2.423456e-07   \n",
      "AT1.AX  -0.000072 -0.000003  1.251367e-06  3.258165e-07  ... -1.917500e-06   \n",
      "BBUS.AX -0.000007 -0.000004 -2.540940e-06 -3.445005e-06  ... -1.991330e-06   \n",
      "BEAR.AX -0.000016 -0.000002 -2.877126e-07 -1.228785e-06  ... -1.037570e-06   \n",
      "\n",
      "                  SPY       VDHG.AX       VLUE.AX       VMIN.AX        VSO.AX  \\\n",
      "A200.AX  4.053655e-06  1.033790e-06  1.081760e-06  6.369458e-07  9.031886e-07   \n",
      "ACDC.AX  2.333147e-06  1.217192e-06  1.530788e-06  6.389361e-07  9.471808e-07   \n",
      "AT1.AX  -3.720297e-05 -3.441537e-07  8.276575e-07  4.874423e-07  4.342871e-07   \n",
      "BBUS.AX -7.234141e-07 -3.219449e-06 -3.562918e-06 -2.427935e-06 -2.790382e-06   \n",
      "BEAR.AX -6.376465e-06 -1.154254e-06 -1.158300e-06 -7.178885e-07 -1.062851e-06   \n",
      "\n",
      "          VVLU.AX        WDS.AX        WTC.AX       YMAX.AX  \n",
      "A200.AX  0.000002  1.252604e-06  1.160692e-06  1.049828e-06  \n",
      "ACDC.AX  0.000002  1.793996e-06  1.247125e-06  9.463349e-07  \n",
      "AT1.AX   0.000001 -8.504287e-07 -5.972456e-06 -4.368497e-06  \n",
      "BBUS.AX -0.000005 -3.596190e-06 -7.148337e-07 -2.188361e-06  \n",
      "BEAR.AX -0.000002 -1.230670e-06 -1.435516e-06 -1.425652e-06  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "A200.AX    0.154133\n",
      "ACDC.AX    0.223551\n",
      "AT1.AX     0.524559\n",
      "BBUS.AX   -0.432816\n",
      "BEAR.AX   -0.094067\n",
      "dtype: float64\n",
      "OPT TICKERS: ['A200.AX', 'ACDC.AX', 'AT1.AX', 'BBUS.AX', 'BEAR.AX', 'BHP.AX', 'BLOK', 'CBA.AX', 'CSL.AX', 'ETHI.AX', 'FMG.AX', 'GME', 'LKE.AX', 'MQG.AX', 'MTUM.AX', 'NDQ.AX', 'PNV.AX', 'QLTY.AX', 'QUAL.AX', 'SMH', 'SMLL.AX', 'SPY', 'VDHG.AX', 'VLUE.AX', 'VMIN.AX', 'VSO.AX', 'VVLU.AX', 'WDS.AX', 'WTC.AX', 'YMAX.AX']\n",
      "mu: count    30.000000\n",
      "mean      0.172023\n",
      "std       0.300308\n",
      "min      -0.652518\n",
      "25%       0.092813\n",
      "50%       0.186061\n",
      "75%       0.253090\n",
      "max       0.995254\n",
      "dtype: float64\n",
      "Sigma diag min/max: 4.193233307339958e-05 0.005690542558378446\n"
     ]
    }
   ],
   "source": [
    "# === Analytics helpers (moved from Block 4) ===================================\n",
    "def holdings_portfolio_returns(prices: pd.DataFrame, units: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build a value-weighted portfolio from 'prices' and 'units', and return daily pct-change.\n",
    "    - prices: wide DataFrame of Close in AUD (or AUD-converted) with Date index.\n",
    "    - units:  Series of current units held per ticker (can include zeros/missing).\n",
    "    Returns a daily return Series aligned to prices' index.\n",
    "    \"\"\"\n",
    "    units = pd.Series(units).reindex(prices.columns).fillna(0.0)\n",
    "    if units.abs().sum() == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "    px = prices.reindex(columns=units.index).ffill()\n",
    "    port_val = (px * units.values).sum(axis=1)\n",
    "    ret = port_val.pct_change(fill_method=None)\n",
    "    return ret.dropna()\n",
    "\n",
    "def current_holdings_weights(units: pd.Series,\n",
    "                             last_prices: pd.Series,\n",
    "                             investable: list[str],\n",
    "                             fx_to_aud: pd.Series | float | None = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute FX-aware weights of current holdings over the investable set (long-only, renormalised).\n",
    "    - units:         Series of unit counts indexed by Security\n",
    "    - last_prices:   Series of last Close (native currency)\n",
    "    - investable:    list of tickers included in optimisation (order matters)\n",
    "    - fx_to_aud:     Series of FX-to-AUD per Security (or scalar 1.0); if None, assume 1.0\n",
    "    Returns a Series of weights indexed by investable tickers (sums to 1 if MV>0).\n",
    "    \"\"\"\n",
    "    # FX handling\n",
    "    if isinstance(fx_to_aud, pd.Series):\n",
    "        fx = fx_to_aud.reindex(units.index).fillna(1.0)\n",
    "    else:\n",
    "        fx = 1.0\n",
    "\n",
    "    mv = (pd.Series(units, dtype=float) * pd.Series(last_prices, dtype=float) * fx)\n",
    "    mv = mv.reindex(investable).fillna(0.0)\n",
    "    den = mv.sum()\n",
    "    return (mv / den) if den > 0 else mv\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) COVARIANCE MATRIX (daily)\n",
    "# ------------------------------------------------------------\n",
    "df_cov_wide = (\n",
    "    df_melt[['Date','Security','Return']]\n",
    "    .pivot(index='Date', columns='Security', values='Return')\n",
    ")\n",
    "\n",
    "Sigma_daily = df_cov_wide.cov()  # DAILY cov (AUD returns)\n",
    "\n",
    "# (Optional) sanity that Sigma came from AUD-converted prices\n",
    "Sigma_from_aud = (\n",
    "    pd.melt(prices_aud_for_returns.reset_index(), id_vars=\"Date\",\n",
    "            var_name=\"Security\", value_name=\"Close\")\n",
    "      .sort_values([\"Security\",\"Date\"])\n",
    "      .assign(Return=lambda d: d.groupby(\"Security\")[\"Close\"].pct_change(fill_method=None))\n",
    "      .pivot(index=\"Date\", columns=\"Security\", values=\"Return\")\n",
    "      .cov()\n",
    ").reindex(index=Sigma_daily.index, columns=Sigma_daily.columns)\n",
    "max_abs_diff = (Sigma_daily - Sigma_from_aud).abs().to_numpy().max()\n",
    "using_fx = np.allclose(Sigma_daily.to_numpy(), Sigma_from_aud.to_numpy(), rtol=0, atol=1e-12)\n",
    "print(f\"Using FX-adjusted returns for Sigma?: {using_fx} (max |diff|={max_abs_diff:.2e})\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) GEOMETRIC (LOG-BASED) EXPECTED RETURNS (annual) — sample μ\n",
    "# ------------------------------------------------------------\n",
    "df_melt['LogRet'] = np.log1p(df_melt['Return'])\n",
    "mu_log_ann = df_melt.groupby('Security')['LogRet'].mean() * 252.0\n",
    "mu_ann_geo = np.expm1(mu_log_ann)  # ANNUAL (geom)\n",
    "\n",
    "# Align\n",
    "securities_all = [s for s in Sigma_daily.columns if s != \"PortfolioValue\"]\n",
    "Sigma_daily = Sigma_daily.loc[securities_all, securities_all]\n",
    "mu_vec_all = mu_ann_geo.reindex(securities_all)\n",
    "\n",
    "valid_all = [s for s in securities_all\n",
    "             if pd.notna(mu_vec_all.get(s, np.nan)) and pd.notna(Sigma_daily.loc[s, s])]\n",
    "Sigma_daily = Sigma_daily.loc[valid_all, valid_all]\n",
    "mu_vec_all = mu_vec_all.reindex(valid_all)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Build FF5 betas ONCE (so tilts are always available)\n",
    "# ------------------------------------------------------------\n",
    "# --- Configurable lookback (shared) ---\n",
    "FF5_LOOKBACK_DAYS = globals().get(\"FF5_LOOKBACK_DAYS\", 252*2)  # ~2 years\n",
    "\n",
    "def compute_ff5_betas(df_cov_wide, ff, min_obs=200):\n",
    "    fac = [c for c in ff.columns if c != \"RF\"]    # <— key change (auto includes MOM)\n",
    "    B_rows, alpha, resid = [], {}, {}\n",
    "    for t in df_cov_wide.columns:\n",
    "        r = df_cov_wide[t].dropna()\n",
    "        idx = r.index.intersection(ff.index)\n",
    "        if len(idx) < min_obs:\n",
    "            continue\n",
    "        y = (r.loc[idx] - ff.loc[idx, \"RF\"]).astype(float)\n",
    "        X = sm.add_constant(ff.loc[idx, fac].astype(float))\n",
    "        res = sm.OLS(y, X, missing=\"drop\").fit()\n",
    "        alpha[t] = float(res.params.get(\"const\", 0.0))\n",
    "        B_rows.append((t, res.params.reindex(fac).fillna(0.0).values))\n",
    "        resid[t] = float(res.resid.var(ddof=1))\n",
    "    if not B_rows:\n",
    "        return None, None, None\n",
    "    B = pd.DataFrame([b for _, b in B_rows], index=[t for t,_ in B_rows], columns=fac)\n",
    "    return B, pd.Series(alpha), pd.Series(resid)\n",
    "\n",
    "\n",
    "ff5 = get_ff5_mom_daily()                     # DAILY, decimals\n",
    "ff5_win = ff5.tail(FF5_LOOKBACK_DAYS)     # use same window everywhere\n",
    "B, alpha_daily, resid_var = compute_ff5_betas(df_cov_wide, ff5_win, min_obs=120)\n",
    "\n",
    "def recommend_factor_tilts_achievable(B: pd.DataFrame,\n",
    "                                      f_mean_ann: pd.Series,\n",
    "                                      Fcov_daily: pd.DataFrame,\n",
    "                                      normalise_to_mkt: bool = True,\n",
    "                                      lam_w: float = 0.0,\n",
    "                                      w0: pd.Series | None = None) -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Project the unconstrained factor target t* = Σ_f^{-1} μ_f onto the long-only simplex:\n",
    "        min_w  0.5 || B^T w - t* ||^2  + 0.5 * lam_w * ||w||^2\n",
    "        s.t.   w >= 0, 1'w = 1\n",
    "    Returns (tilt_reco_achievable, w_tilt).\n",
    "    \"\"\"\n",
    "    fac = [c for c in B.columns]          # factor order\n",
    "    mu = f_mean_ann.reindex(fac).astype(float).values\n",
    "    Sig = Fcov_daily.loc[fac, fac].astype(float).values\n",
    "\n",
    "    # unconstrained \"ideal\" target in factor space\n",
    "    t_star = pinv(Sig) @ mu\n",
    "    if normalise_to_mkt and \"Mkt-RF\" in fac:\n",
    "        m_idx = fac.index(\"Mkt-RF\")\n",
    "        if abs(t_star[m_idx]) > 1e-12:\n",
    "            t_star = t_star / t_star[m_idx]\n",
    "\n",
    "    # optimise over portfolio weights\n",
    "    tick = list(B.index)\n",
    "    n = len(tick)\n",
    "    Bt = B[fac].T.values  # shape (F, n)\n",
    "\n",
    "    # start from current holdings weights if provided, else uniform\n",
    "    if isinstance(w0, pd.Series):\n",
    "        w0v = w0.reindex(tick).fillna(0.0).values\n",
    "        s = w0v.sum(); w0v = (w0v / s) if s > 0 else np.full(n, 1.0/n)\n",
    "    else:\n",
    "        w0v = np.full(n, 1.0/n)\n",
    "\n",
    "    def obj(w):\n",
    "        diff = Bt @ w - t_star\n",
    "        return 0.5 * (diff @ diff) + 0.5 * lam_w * (w @ w)\n",
    "\n",
    "    def grad(w):\n",
    "        diff = Bt @ w - t_star\n",
    "        return Bt.T @ diff + lam_w * w\n",
    "\n",
    "    cons = (\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0, 'jac': lambda w: np.ones_like(w)},\n",
    "    )\n",
    "    bounds = [(0.0, 1.0)] * n\n",
    "\n",
    "    res = minimize(obj, w0v, method='SLSQP', jac=grad, bounds=bounds, constraints=cons,\n",
    "                   options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False})\n",
    "    w_hat = (res.x if res.success else w0v)\n",
    "    w_hat = np.clip(w_hat, 0, 1); w_hat = w_hat / max(1e-12, w_hat.sum())\n",
    "\n",
    "    t_ach = (Bt @ w_hat)\n",
    "    tilt_reco = pd.Series(t_ach, index=fac, name=\"Achievable β\")\n",
    "    w_tilt = pd.Series(w_hat, index=tick, name=\"w_tilt\")\n",
    "    return tilt_reco, w_tilt\n",
    "\n",
    "def compute_factor_feasible_ranges(B: pd.DataFrame,\n",
    "                                   include_flags: dict[str, bool] | None = None,\n",
    "                                   factor_order: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each factor f in B.columns, solve:\n",
    "        min/max   B[:, f]^T w\n",
    "        s.t.      w >= 0, 1'w = 1, and (optionally) w_i = 0 if include_flags[ticker] is False.\n",
    "    Returns a DataFrame with columns: ['Min β','Max β'] indexed by factor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.optimize import linprog\n",
    "    except Exception as e:\n",
    "        # Graceful fallback if SciPy isn't available\n",
    "        facs = list(B.columns) if factor_order is None else list(factor_order)\n",
    "        return pd.DataFrame({\"Min β\": np.nan, \"Max β\": np.nan}, index=facs)\n",
    "\n",
    "    tickers = list(B.index)\n",
    "    n = len(tickers)\n",
    "    if factor_order is None:\n",
    "        factor_order = list(B.columns)\n",
    "    factor_order = [f for f in factor_order if f in B.columns]\n",
    "\n",
    "    # equality: sum w = 1\n",
    "    A_eq = np.ones((1, n))\n",
    "    b_eq = np.array([1.0])\n",
    "\n",
    "    # bounds: 0 <= w_i <= 1, and optionally force 0 for excluded tickers\n",
    "    if include_flags:\n",
    "        bounds = [(0.0, 1.0 if bool(include_flags.get(t, True)) else 0.0) for t in tickers]\n",
    "    else:\n",
    "        bounds = [(0.0, 1.0)] * n\n",
    "\n",
    "    mins, maxs = [], []\n",
    "    for f in factor_order:\n",
    "        c = B[f].astype(float).values  # objective coefficients\n",
    "\n",
    "        # minimise c^T w\n",
    "        res_min = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "        beta_min = float(res_min.fun) if res_min.success else np.nan\n",
    "\n",
    "        # maximise c^T w  <=> minimise (-c)^T w\n",
    "        res_max = linprog(-c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "        beta_max = (-float(res_max.fun)) if res_max.success else np.nan\n",
    "\n",
    "        mins.append(beta_min); maxs.append(beta_max)\n",
    "\n",
    "    out = pd.DataFrame({\"Min β\": mins, \"Max β\": maxs}, index=factor_order)\n",
    "    return out\n",
    "\n",
    "# ------------------------------\n",
    "# Soft penalties for CGT and brokerage\n",
    "# ------------------------------\n",
    "\n",
    "def estimate_trade_units(curr_units, target_weights, prices):\n",
    "    # Convert weight targets into units\n",
    "    port_value = (curr_units * prices).sum()\n",
    "    target_values = target_weights * port_value\n",
    "    target_units = (target_values / prices).fillna(0)\n",
    "\n",
    "    d_units = target_units - curr_units\n",
    "    return d_units\n",
    "\n",
    "\n",
    "def estimate_brokerage_cost(d_units, brokerage_per_trade=11.0):\n",
    "    # Brokerage charged once per security traded\n",
    "    traded = (d_units.abs() > 0.0001)\n",
    "    n_trades = traded.sum()\n",
    "    return n_trades * brokerage_per_trade\n",
    "\n",
    "\n",
    "def estimate_cgt_cost(d_units, lots_df=None, prices=None, sale_date=None):\n",
    "    \"\"\"\n",
    "    Fast approximate CGT cost:\n",
    "      - Uses precomputed LOTS_CACHE (per-security arrays)\n",
    "      - Only loops over securities that actually have a *sell* (Δ < 0)\n",
    "      - Applies 50% discount for positive gains on long-term lots (>= 365 days)\n",
    "    \"\"\"\n",
    "    est_cost = 0.0\n",
    "\n",
    "    # normalise to a Series-like interface\n",
    "    if not hasattr(d_units, \"items\"):\n",
    "        d_units = pd.Series(d_units)\n",
    "\n",
    "    for sec, du in d_units.items():\n",
    "        if du >= 0:\n",
    "            continue  # buys don’t create CGT\n",
    "\n",
    "        info = LOTS_CACHE.get(sec)\n",
    "        if not info:\n",
    "            continue  # no lot info for this security\n",
    "\n",
    "        qty_to_sell = float(abs(du))\n",
    "        units_arr   = info[\"units\"]\n",
    "        cost_arr    = info[\"cost\"]\n",
    "        long_term   = info[\"long_term\"]\n",
    "        sale_price  = info[\"sale_price\"]\n",
    "\n",
    "        # Walk the lots in order (FIFO) and “consume” units\n",
    "        for lot_units, cost_per_unit, is_lt in zip(units_arr, cost_arr, long_term):\n",
    "            if qty_to_sell <= 0:\n",
    "                break\n",
    "\n",
    "            take = min(qty_to_sell, lot_units)\n",
    "            qty_to_sell -= take\n",
    "\n",
    "            gain = (sale_price - cost_per_unit) * take\n",
    "\n",
    "            # 50% discount on *positive* long-term gains\n",
    "            if gain > 0 and is_lt:\n",
    "                gain *= 0.5\n",
    "\n",
    "            if gain > 0:\n",
    "                est_cost += MARGINAL_TAX_RATE * gain\n",
    "\n",
    "    return est_cost\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Choose μ and Σ source for the optimiser\n",
    "#       - Sample: Sigma_daily (DAILY), mu_ann_geo (ANNUAL)\n",
    "#       - FF5:    Sigma_ff (DAILY),   mu_ff_ann (ANNUAL)\n",
    "# ------------------------------------------------------------\n",
    "USE_FF5 = True  # flip to False to use sample moments\n",
    "\n",
    "if USE_FF5 and (B is not None) and not B.empty:\n",
    "    fac_cols = [c for c in ff5_win.columns if c != \"RF\"]  # auto-includes MOM if present\n",
    "    Fcov_daily = ff5_win[fac_cols].cov()\n",
    "    S_diag = resid_var.reindex(B.index).clip(lower=0.0).fillna(0.0)\n",
    "\n",
    "    Sigma_ff_daily = B @ Fcov_daily @ B.T + np.diag(S_diag)\n",
    "    Sigma_ff_daily = pd.DataFrame(Sigma_ff_daily, index=B.index, columns=B.index)\n",
    "\n",
    "    f_mean_ann = ff5_win[fac_cols].mean() * 252.0        # ANNUAL premia\n",
    "    \n",
    "    # === RECOMMENDED FACTOR TILTS ================================================\n",
    "    # Compute an achievable recommendation based on your current investable set\n",
    "    tilt_reco_achievable, w_tilt = recommend_factor_tilts_achievable(B, f_mean_ann, Fcov_daily,\n",
    "                                                                 normalise_to_mkt=True,\n",
    "                                                                 lam_w=0.0,\n",
    "                                                                 w0=None)  # or pass current weights if you prefer\n",
    "    \n",
    "    def recommend_factor_tilts(f_mean_ann, Fcov_daily, normalise=True):\n",
    "        \"\"\"\n",
    "        Recommend optimal factor tilts given estimated factor premia and covariance.\n",
    "        Returns a Series of recommended beta targets for each factor.\n",
    "        \"\"\"\n",
    "        fac = f_mean_ann.index\n",
    "        mu = f_mean_ann.values\n",
    "        Sigma = Fcov_daily.loc[fac, fac].values\n",
    "    \n",
    "        # Mean–variance optimal factor exposure vector: Σ⁻¹ μ\n",
    "        Sigma_inv = np.linalg.pinv(Sigma)\n",
    "        t_opt = Sigma_inv @ mu\n",
    "    \n",
    "        # Normalise so that Market β = 1 (interpretable scaling)\n",
    "        if normalise and \"Mkt-RF\" in fac:\n",
    "            t_opt = t_opt / t_opt[list(fac).index(\"Mkt-RF\")]\n",
    "    \n",
    "        return pd.Series(t_opt, index=fac, name=\"Recommended β\")\n",
    "    \n",
    "    # Compute and display recommended tilts\n",
    "    tilt_reco = recommend_factor_tilts(f_mean_ann, Fcov_daily)\n",
    "    print(\"\\nRecommended factor tilts (based on current factor premia):\")\n",
    "    print(tilt_reco.round(3))\n",
    "    # ==============================================================================\n",
    "    \n",
    "    alpha_ann  = alpha_daily * 252.0                     # ANNUAL alpha\n",
    "    mu_ff_ann  = alpha_ann.reindex(B.index).fillna(0.0) + (B @ f_mean_ann).rename(None) + rf_annual\n",
    "  \n",
    "    securities_opt = [t for t in Sigma_ff_daily.index if t not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_ff_daily.loc[securities_opt, securities_opt]   # DAILY\n",
    "    mu_vec_opt = mu_ff_ann.reindex(securities_opt)                   # ANNUAL\n",
    "    exp_ret_label = \"Expected Return (annual, FF5)\"\n",
    "else:\n",
    "    \n",
    "    securities_opt = [s for s in valid_all if s not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_daily.loc[securities_opt, securities_opt]      # DAILY\n",
    "    mu_vec_opt = mu_vec_all.reindex(securities_opt)                  # ANNUAL\n",
    "    exp_ret_label = \"Expected Return (ann., geom)\"\n",
    "\n",
    "# Display tables (once μ/Σ are final)\n",
    "n_opt = len(securities_opt)\n",
    "cov_plus = pd.DataFrame(0.0, index=securities_opt + ['w'], columns=securities_opt + ['w'])\n",
    "cov_plus.iloc[:n_opt, :n_opt] = Sigma_opt.values\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) OPTIMISATION UTILITIES (unconstrained + tilt-constrained)\n",
    "# ------------------------------------------------------------\n",
    "def optimise_long_only(mu, Sigma, target_return):\n",
    "    \"\"\"\n",
    "    Long-only optimiser with variance+soft-penalties:\n",
    "      penalty = gamma_cgt * estimated_CGT + beta_brokerage * estimated_brokerage\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.optimize import minimize\n",
    "\n",
    "        n = len(mu)\n",
    "        mu = np.asarray(mu, dtype=float)\n",
    "        Sigma = np.asarray(Sigma, dtype=float)\n",
    "\n",
    "        # Feasibility check\n",
    "        if not (mu.min() - 1e-12 <= target_return <= mu.max() + 1e-12):\n",
    "            return np.full(n, np.nan), False, \"Target outside long-only feasible range.\"\n",
    "\n",
    "        # === Objective with soft penalties ======================================\n",
    "        def obj(w):\n",
    "            # base portfolio variance\n",
    "            var = float(w @ Sigma @ w)\n",
    "\n",
    "            # === Convert to Series so estimate functions can work ===\n",
    "            w_series = pd.Series(w, index=securities_opt)\n",
    "\n",
    "            # === Compute trade deltas in units ===\n",
    "            d_units = estimate_trade_units(\n",
    "                curr_units=current_holdings_units,\n",
    "                target_weights=w_series,\n",
    "                prices=last_px_hold\n",
    "            )\n",
    "\n",
    "            # === Brokerage estimate ===\n",
    "            brokerage_est = estimate_brokerage_cost(d_units)\n",
    "\n",
    "            # === CGT estimate ===\n",
    "            sale_date = pd.Timestamp(prices.index[-1])\n",
    "            cgt_est = estimate_cgt_cost(d_units, lots_df, last_px_hold, sale_date)\n",
    "\n",
    "            # === Soft penalty combines them ===\n",
    "            penalty = gamma_cgt * cgt_est + beta_brokerage * brokerage_est\n",
    "\n",
    "            return var + penalty\n",
    "\n",
    "        # === Constraints ===\n",
    "        cons = (\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "            {'type': 'eq', 'fun': lambda w: float(mu @ w) - float(target_return)},\n",
    "        )\n",
    "\n",
    "        bounds = [(0.0, 1.0)] * n\n",
    "        w0 = np.full(n, 1.0/n)\n",
    "\n",
    "        # === Solve ===\n",
    "        res = minimize(\n",
    "            obj, w0, method='SLSQP',\n",
    "            bounds=bounds, constraints=cons,\n",
    "            options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False}\n",
    "        )\n",
    "\n",
    "        if res.success and np.isfinite(res.fun):\n",
    "            return res.x, True, \"SLSQP success.\"\n",
    "\n",
    "        return np.full(n, np.nan), False, \"SLSQP failed.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return np.full(len(mu), np.nan), False, f\"SLSQP unavailable or error: {e}\"\n",
    "\n",
    "\n",
    "def optimise_unconstrained_analytic(mu, Sigma, target_return):\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    Sigma = np.asarray(Sigma, dtype=float)\n",
    "    n = len(mu); ones = np.ones(n)\n",
    "    Sigma_inv = np.linalg.pinv(Sigma)\n",
    "    A = ones @ Sigma_inv @ ones\n",
    "    Bv = ones @ Sigma_inv @ mu\n",
    "    C = mu @ Sigma_inv @ mu\n",
    "    M = np.array([[A, Bv], [Bv, C]]); rhs = np.array([1.0, float(target_return)])\n",
    "    try:\n",
    "        alpha, beta = np.linalg.solve(M, rhs)\n",
    "        w = Sigma_inv @ (alpha * ones + beta * mu)\n",
    "        return w, \"Analytic solution.\"\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.full(n, np.nan), \"Analytic solver failed (singular).\"\n",
    "\n",
    "def optimise_long_only_with_tilts(mu, Sigma, target_return, B, tilt_targets, tilt_bands, use_mask):\n",
    "    from scipy.optimize import minimize\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    Sigma = np.asarray(Sigma, dtype=float)\n",
    "    n = len(mu)\n",
    "    def obj(w): return float(w @ Sigma @ w)\n",
    "    cons = [\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "        {'type': 'eq', 'fun': lambda w: float(mu @ w) - float(target_return)},\n",
    "    ]\n",
    "    for f in [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]:\n",
    "        if not use_mask.get(f, True): \n",
    "            continue\n",
    "        t = float(tilt_targets.get(f, 0.0))\n",
    "        b = float(tilt_bands.get(f, 0.05))\n",
    "        v = B[f].values\n",
    "        cons.append({'type':'ineq', 'fun': (lambda v=v, t=t, b=b: lambda w: (t + b) - float(v @ w))()})\n",
    "        cons.append({'type':'ineq', 'fun': (lambda v=v, t=t, b=b: lambda w:  float(v @ w) - (t - b))()})\n",
    "    bounds = [(0.0, 1.0)] * n\n",
    "    w0 = np.full(n, 1.0/n)\n",
    "    res = minimize(obj, w0, method='SLSQP', bounds=bounds, constraints=cons,\n",
    "                   options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False})\n",
    "    if res.success and np.isfinite(res.fun):\n",
    "        return res.x, \"tilt SLSQP success\"\n",
    "    return np.full(n, np.nan), f\"tilt SLSQP failed ({getattr(res,'message','unknown')})\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) FRONTIERS: unconstrained and tilt-constrained\n",
    "# ------------------------------------------------------------\n",
    "W, stats_df, tan_ret, tan_vol = _build_frontier(\n",
    "    mu_vec_opt,\n",
    "    Sigma_opt,\n",
    "    target_returns=None,       # let the function choose\n",
    "    n_points=20,               # similar density as before\n",
    "    max_excess_return=0.40     # adjustable: rf + 40%\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) PREPARE A Trade Plan\n",
    "# ------------------------------------------------------------\n",
    "cov_plus = cov_plus.fillna(0.0)\n",
    "\n",
    "# investable assets only (matches weights grid)\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "# or, if you prefer to show all (incl. ^AORD), use mu_vec_all instead.\n",
    "\n",
    "def make_trade_plan(units_cur, last_px, fx_map, w_target, include_flags, include_zero_lines=False):\n",
    "    \"\"\"Return (trade_df, residual_cash) to move from current units to target weights (AUD).\n",
    "       If include_zero_lines=True, keep rows with Δ Units = 0 in the output table.\"\"\"\n",
    "    tickers = list(w_target.index)\n",
    "    inc = pd.Series(include_flags).reindex(tickers).fillna(True).astype(bool)\n",
    "    tickers = [t for t in tickers if inc.get(t, True)]\n",
    "\n",
    "    lp_aud = (pd.Series(last_px).reindex(tickers).astype(float) *\n",
    "              pd.Series(fx_map).reindex(tickers).fillna(1.0).astype(float))\n",
    "    cur_units = pd.Series(units_cur).reindex(tickers).fillna(0.0).astype(float)\n",
    "    cur_val = (cur_units * lp_aud).sum()\n",
    "    cur_val = float(cur_val)\n",
    "\n",
    "    if cur_val <= 0:\n",
    "        out = pd.DataFrame(columns=[\n",
    "            \"Security\",\"Curr Units\",\"Target Units\",\"Δ Units\",\n",
    "            \"Last Px (AUD)\",\"Cash Flow (AUD)\"\n",
    "        ])\n",
    "        return out, 0.0\n",
    "\n",
    "    tgt_val = pd.Series(w_target).reindex(tickers).fillna(0.0) * cur_val\n",
    "    tgt_units_float = (tgt_val / lp_aud).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    tgt_units_int = tgt_units_float.round().astype(int)\n",
    "\n",
    "    delta_units = (tgt_units_int - cur_units).round().astype(int)\n",
    "    cash_impact = (-delta_units * lp_aud).astype(float)     # +ve for sells, -ve for buys\n",
    "    residual = float((tgt_val - tgt_units_int * lp_aud).sum())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Security\": tickers,\n",
    "        \"Curr Units\": cur_units.astype(int).values,\n",
    "        \"Target Units\": tgt_units_int.values,\n",
    "        \"Δ Units\": delta_units.values,\n",
    "        \"Last Px (AUD)\": lp_aud.values,\n",
    "        \"Cash Flow (AUD)\": cash_impact.values,\n",
    "    })\n",
    "\n",
    "    # === DEBUG: first nonzero trade ===\n",
    "    try:\n",
    "        nz = out.loc[out[\"Δ Units\"] != 0]\n",
    "        print(\"\\n=== DEBUG FIRST NONZERO TRADE (inside make_trade_plan) ===\")\n",
    "        if nz.empty:\n",
    "            print(\"No trades in this scenario.\")\n",
    "        else:\n",
    "            print(nz.iloc[:1])\n",
    "    except Exception as e:\n",
    "        print(\"\\n=== DEBUG FIRST NONZERO TRADE ERROR (inside make_trade_plan) ===\")\n",
    "        print(e)\n",
    "\n",
    "    # Compute per-row brokerage\n",
    "    brokerage_total, brokerage_series = compute_brokerage(out)\n",
    "\n",
    "    # Add brokerage column\n",
    "    out[\"Brokerage (AUD)\"] = brokerage_series.values\n",
    "\n",
    "    # Adjust cash flow to INCLUDE brokerage cost:\n",
    "    #  - sells: reduce net cash (CF = proceeds - brokerage)\n",
    "    #  - buys: increase outflow (CF = negative amount, more negative after brokerage)\n",
    "    out[\"Cash Flow (AUD)\"] = out[\"Cash Flow (AUD)\"] - out[\"Brokerage (AUD)\"]\n",
    "\n",
    "    if not include_zero_lines:\n",
    "        out = out.loc[out[\"Δ Units\"] != 0]\n",
    "\n",
    "    return out.reset_index(drop=True), residual\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_target_units_for_holdings(units_cur, last_px, fx_map, w_target, include_flags):\n",
    "    tickers = list(pd.Index(w_target.index))\n",
    "    inc = pd.Series(include_flags).reindex(tickers).fillna(True).astype(bool)\n",
    "    tickers = [t for t in tickers if inc.get(t, True)]\n",
    "\n",
    "    lp_aud = (pd.Series(last_px).reindex(tickers).astype(float) *\n",
    "              pd.Series(fx_map).reindex(tickers).fillna(1.0).astype(float))\n",
    "    cur_units = pd.Series(units_cur).reindex(tickers).fillna(0.0).astype(float)\n",
    "    cur_val = float((cur_units * lp_aud).sum())\n",
    "    if cur_val <= 0:\n",
    "        return pd.Series(0, index=w_target.index, dtype=int)\n",
    "    # --- Soft penalty for small trades ---\n",
    "    # Access current holdings from outer scope\n",
    "    global current_holdings_units\n",
    "    \n",
    "    if current_holdings_units is not None:\n",
    "        # build target_units first (the variable was missing)\n",
    "        target_units = (w_target * cur_val / lp_aud).fillna(0)\n",
    "    \n",
    "        delta = target_units - current_holdings_units.reindex(target_units.index).fillna(0)\n",
    "    \n",
    "        small_trade_mask = delta.abs() <= 2\n",
    "        target_units.loc[small_trade_mask] = current_holdings_units.reindex(target_units.index)[small_trade_mask]\n",
    "\n",
    "    tgt_val = pd.Series(w_target).reindex(tickers).fillna(0.0) * cur_val\n",
    "    tgt_units_float = (tgt_val / lp_aud).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    tgt_units_int = tgt_units_float.round().astype(int)\n",
    "    return tgt_units_int.reindex(w_target.index).fillna(0).astype(int)\n",
    "\n",
    "def compute_achieved_tilts(B: pd.DataFrame, w: pd.Series, factors=None, renormalise_missing=True) -> pd.Series:\n",
    "    if B is None or B.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    w_all = pd.Series(w).reindex(B.index).fillna(0.0)\n",
    "    if renormalise_missing and w_all.sum() > 0:\n",
    "        w_use = w_all / w_all.sum()\n",
    "    else:\n",
    "        w_use = w_all\n",
    "    t = (B.T @ w_use).rename(\"Achieved β\")\n",
    "    if factors is not None:\n",
    "        t = t.reindex(factors)\n",
    "    return t\n",
    "\n",
    "def _build_frontier(\n",
    "    mu_vec_opt: pd.Series,\n",
    "    Sigma_opt: pd.DataFrame,\n",
    "    target_returns: list[float] | None = None,\n",
    "    *,\n",
    "    n_points: int = 18,\n",
    "    max_excess_return: float = 0.40,   # cap frontier at rf + xx% p.a.\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, float, float]:\n",
    "    \"\"\"\n",
    "    Build a long-only efficient frontier on a *realistic* range of target returns.\n",
    "\n",
    "    If target_returns is None, we:\n",
    "      - look at the min / max of mu_vec_opt\n",
    "      - cap the high end at rf_annual + max_excess_return\n",
    "      - generate n_points evenly spaced targets between low and high\n",
    "    \"\"\"\n",
    "    mu_clean = pd.to_numeric(mu_vec_opt, errors=\"coerce\").dropna()\n",
    "    if mu_clean.empty:\n",
    "        raise ValueError(\"mu_vec_opt has no finite entries\")\n",
    "\n",
    "    mu_min = float(mu_clean.min())\n",
    "    mu_max = float(mu_clean.max())\n",
    "\n",
    "    # Low end of the grid: don't go below 0%, and don't go below the min asset\n",
    "    low = max(0.0, min(mu_min, rf_annual))\n",
    "\n",
    "    # High end of the grid: can't exceed highest asset and don't go crazy above rf\n",
    "    high = min(mu_max, rf_annual + max_excess_return)\n",
    "\n",
    "    # If everything collapsed (e.g. mu_max is tiny), widen a bit so the frontier is not degenerate\n",
    "    if high <= low + 0.01:\n",
    "        high = low + 0.06   # force at least a 6% span\n",
    "\n",
    "    if target_returns is None:\n",
    "        target_returns = np.linspace(low, high, n_points).tolist()\n",
    "\n",
    "    weights_dict: dict[float, np.ndarray] = {}\n",
    "    stats_rows: list[dict] = []\n",
    "\n",
    "    mu = mu_vec_opt.reindex(Sigma_opt.index).to_numpy(dtype=float)\n",
    "    S = Sigma_opt.to_numpy(dtype=float)\n",
    "\n",
    "    for R in target_returns:\n",
    "        w, ok, note = optimise_long_only(mu, S, R)\n",
    "        weights_dict[R] = w\n",
    "        if np.all(np.isfinite(w)):\n",
    "            vol_ann = float(np.sqrt(w @ S @ w) * np.sqrt(252.0))\n",
    "            achieved = float(mu @ w)\n",
    "        else:\n",
    "            vol_ann = np.nan\n",
    "            achieved = np.nan\n",
    "\n",
    "        sharpe = (achieved - rf_annual) / vol_ann if (pd.notna(vol_ann) and vol_ann > 0) else np.nan\n",
    "\n",
    "        stats_rows.append({\n",
    "            \"Target Return\":    R,\n",
    "            \"Achieved Return\":  achieved,\n",
    "            \"Volatility (ann.)\": vol_ann,\n",
    "            \"Sharpe\":           sharpe,\n",
    "            \"Method\":           \"Long-only SLSQP\",\n",
    "            \"Note\":             note,\n",
    "        })\n",
    "\n",
    "    # Pretty column labels like \"4.0%\", \"7.5%\", etc\n",
    "    cols = [\n",
    "        f\"{int(r*1000)/10:.1f}%\"\n",
    "        if (r*100) % 1 != 0\n",
    "        else f\"{int(r*100):d}%\"\n",
    "        for r in target_returns\n",
    "    ]\n",
    "\n",
    "    W = pd.DataFrame({c: weights_dict[R] for c, R in zip(cols, target_returns)},\n",
    "                     index=Sigma_opt.index)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_rows)\n",
    "    stats_df.insert(0, \"Target (%)\", cols)\n",
    "    stats_df = stats_df.drop(columns=[\"Target Return\"])\n",
    "\n",
    "    # Robust tangency selection\n",
    "    sh = pd.to_numeric(stats_df[\"Sharpe\"], errors=\"coerce\")\n",
    "    if sh.notna().any():\n",
    "        best_idx = int(sh.idxmax())\n",
    "    else:\n",
    "        vol_series = pd.to_numeric(stats_df[\"Volatility (ann.)\"], errors=\"coerce\")\n",
    "        best_idx = int(vol_series.idxmin()) if vol_series.notna().any() else 0\n",
    "\n",
    "    tan_ret = float(pd.to_numeric(stats_df.loc[best_idx, \"Achieved Return\"], errors=\"coerce\"))\n",
    "    tan_vol = float(pd.to_numeric(stats_df.loc[best_idx, \"Volatility (ann.)\"], errors=\"coerce\"))\n",
    "    if not np.isfinite(tan_ret) or not np.isfinite(tan_vol):\n",
    "        tan_ret, tan_vol = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    return W, stats_df, tan_ret, tan_vol\n",
    "\n",
    "\n",
    "# Load parcels once (if the sheet is missing, you just get an empty table)\n",
    "lots_df = _read_lots_from_path(filename, \"Lots\")\n",
    "# === DEBUG: inspect LOTS sheet structure ===\n",
    "print(\"\\n=== LOTS_DF HEAD ===\")\n",
    "print(lots_df.head(20))\n",
    "\n",
    "# ---- Precompute lightweight lots cache for fast CGT penalty ----\n",
    "\n",
    "def _precompute_lots_cache(lots_df, last_prices, sale_date):\n",
    "    \"\"\"\n",
    "    Build a simple dict for each security:\n",
    "        sec -> {\n",
    "            'units':      np.array([...]),\n",
    "            'cost':       np.array([...]),   # cost base per unit (AUD)\n",
    "            'long_term':  np.array([...]),   # bool per lot (>= 365 days)\n",
    "            'sale_price': float,             # current price (AUD)\n",
    "        }\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "    if lots_df is None or lots_df.empty:\n",
    "        return cache\n",
    "\n",
    "    lots = lots_df.copy()\n",
    "    lots = lots.dropna(subset=[\"Security\", \"Units\", \"CostBaseAUD\"])\n",
    "    lots[\"Units\"]       = pd.to_numeric(lots[\"Units\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "    lots[\"CostBaseAUD\"] = pd.to_numeric(lots[\"CostBaseAUD\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "    lots[\"AcqDate\"]     = pd.to_datetime(lots[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    for sec, grp in lots.groupby(\"Security\"):\n",
    "        grp = grp.sort_values(\"AcqDate\")\n",
    "        units_arr = grp[\"Units\"].to_numpy(dtype=float)\n",
    "        cost_arr  = grp[\"CostBaseAUD\"].to_numpy(dtype=float)\n",
    "\n",
    "        # holding period and LT flag (12-month rule)\n",
    "        holding_days = (sale_date - grp[\"AcqDate\"]).dt.days.to_numpy()\n",
    "        long_term    = holding_days >= 365\n",
    "\n",
    "        sale_price = float(last_prices.get(sec, np.nan))\n",
    "\n",
    "        cache[sec] = {\n",
    "            \"units\":      units_arr,\n",
    "            \"cost\":       cost_arr,\n",
    "            \"long_term\":  long_term,\n",
    "            \"sale_price\": sale_price,\n",
    "        }\n",
    "\n",
    "    return cache\n",
    "\n",
    "\n",
    "# One-off cache build for the optimiser’s soft CGT penalty\n",
    "SALE_DATE   = pd.Timestamp(prices.index[-1])\n",
    "LAST_PRICES = prices.ffill().iloc[-1]          # last close in AUD\n",
    "LOTS_CACHE  = _precompute_lots_cache(lots_df, LAST_PRICES, SALE_DATE)\n",
    "\n",
    "\n",
    "def _cost_adjust_stats(W, stats_df, units, last_px, fx_map, include_flags):\n",
    "    mv_aud = float((pd.Series(units, dtype=float).reindex(W.index).fillna(0.0) *\n",
    "                   last_px.reindex(W.index).astype(float) *\n",
    "                   pd.Series(fx_map).reindex(W.index).fillna(1.0)).sum())\n",
    "    sale_date = pd.Timestamp(prices.index[-1])\n",
    "\n",
    "    costs = []\n",
    "    for col in W.columns:\n",
    "        w = W[col].reindex(W.index).fillna(0.0)\n",
    "        trade, _resid = make_trade_plan(units, last_px, fx_map, w, include_flags)\n",
    "        c = evaluate_transaction_costs(trade, lots_df, sale_date, MARGINAL_TAX_RATE)\n",
    "        # Achieved (model) return already in stats_df, but compute directly to be safe:\n",
    "        ach = float(mu_vec_opt.reindex(W.index).fillna(0.0).values @ w.values)\n",
    "        net_ret = ach - (c[\"total_cost\"] / mv_aud if mv_aud > 0 else 0.0)\n",
    "        costs.append({\"Target (%)\": col,\n",
    "                      \"Txn Costs (AUD)\": c[\"total_cost\"],\n",
    "                      \"Net Achieved Return\": net_ret})\n",
    "    extra = pd.DataFrame(costs)\n",
    "    out = stats_df.merge(extra, on=\"Target (%)\", how=\"left\")\n",
    "    out[\"Net Sharpe\"] = (out[\"Net Achieved Return\"] - rf_annual) / out[\"Volatility (ann.)\"]\n",
    "    return out\n",
    "\n",
    "    units = pd.Series(0, index=mu_vec_opt.index)\n",
    "    last_px_hold = prices.ffill().iloc[-1].reindex(units.index)\n",
    "    include_flags = {t: True for t in units.index}\n",
    "    \n",
    "    stats_df = _cost_adjust_stats(W, stats_df, units, last_px_hold, fx_map_all, include_flags)\n",
    "\n",
    "def expand_with_lots(trade_df, lots_df, sale_date, method=\"FIFO\"):\n",
    "    \"\"\"\n",
    "    Expand trade_df by matching sells (Δ Units < 0) to lots_df parcels.\n",
    "\n",
    "    Returns new DataFrame with:\n",
    "        Security, Δ Units, Last Px (AUD), Cash Flow (AUD), Brokerage (AUD),\n",
    "        AcqDate, UnitsSold, AcqPrice, CostBase, RealisedGain\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean and prepare\n",
    "    lots = lots_df.copy()\n",
    "    lots = lots.dropna(subset=[\"Security\", \"Units\", \"CostBaseAUD\"])\n",
    "    lots[\"Units\"] = lots[\"Units\"].astype(int)\n",
    "    lots[\"CostBaseAUD\"] = lots[\"CostBaseAUD\"].astype(float)\n",
    "    lots[\"AcqDate\"] = pd.to_datetime(lots[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    out_rows = []\n",
    "\n",
    "    for idx, row in trade_df.iterrows():\n",
    "        sec = row[\"Security\"]\n",
    "        delta = int(row[\"Δ Units\"])\n",
    "\n",
    "        # Only process sells\n",
    "        if delta >= 0:\n",
    "            continue\n",
    "\n",
    "        units_to_sell = -delta\n",
    "\n",
    "        # Get lots for this security\n",
    "        sec_lots = lots[lots[\"Security\"] == sec].copy()\n",
    "        if sec_lots.empty:\n",
    "            # No lots? Produce a placeholder row but warn\n",
    "            out_rows.append({\n",
    "                \"Security\": sec,\n",
    "                \"AcqDate\": pd.NaT,\n",
    "                \"UnitsSold\": units_to_sell,\n",
    "                \"AcqPrice\": float(\"nan\"),\n",
    "                \"CostBase\": float(\"nan\"),\n",
    "                \"Last Px (AUD)\": row[\"Last Px (AUD)\"],\n",
    "                \"Cash Flow (AUD)\": row[\"Cash Flow (AUD)\"],\n",
    "                \"Brokerage (AUD)\": row[\"Brokerage (AUD)\"],\n",
    "                \"RealisedGain\": float(\"nan\"),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Choose method\n",
    "        if method == \"FIFO\":\n",
    "            sec_lots = sec_lots.sort_values(\"AcqDate\")\n",
    "        elif method == \"HIFO\":\n",
    "            sec_lots = sec_lots.sort_values(\"CostBaseAUD\", ascending=False)\n",
    "\n",
    "        # Consume lots\n",
    "        for _, lot in sec_lots.iterrows():\n",
    "            if units_to_sell <= 0:\n",
    "                break\n",
    "\n",
    "            take = min(units_to_sell, lot[\"Units\"])\n",
    "            units_to_sell -= take\n",
    "\n",
    "            acq_price = lot[\"CostBaseAUD\"]\n",
    "            cost_base = take * acq_price\n",
    "            proceeds = take * row[\"Last Px (AUD)\"]\n",
    "            realised = proceeds - cost_base\n",
    "\n",
    "            out_rows.append({\n",
    "                \"Security\": sec,\n",
    "                \"AcqDate\": lot[\"AcqDate\"],\n",
    "                \"UnitsSold\": int(take),\n",
    "                \"AcqPrice\": float(acq_price),\n",
    "                \"CostBase\": float(cost_base),\n",
    "                \"Last Px (AUD)\": row[\"Last Px (AUD)\"],\n",
    "                \"Cash Flow (AUD)\": row[\"Cash Flow (AUD)\"],\n",
    "                \"Brokerage (AUD)\": row[\"Brokerage (AUD)\"],\n",
    "                \"RealisedGain\": float(realised),\n",
    "            })\n",
    "\n",
    "        # If not enough lots — warn and attach unmatched\n",
    "        if units_to_sell > 0:\n",
    "            out_rows.append({\n",
    "                \"Security\": sec,\n",
    "                \"AcqDate\": pd.NaT,\n",
    "                \"UnitsSold\": int(units_to_sell),\n",
    "                \"AcqPrice\": float(\"nan\"),\n",
    "                \"CostBase\": float(\"nan\"),\n",
    "                \"Last Px (AUD)\": row[\"Last Px (AUD)\"],\n",
    "                \"Cash Flow (AUD)\": row[\"Cash Flow (AUD)\"],\n",
    "                \"Brokerage (AUD)\": row[\"Brokerage (AUD)\"],\n",
    "                \"RealisedGain\": float(\"nan\"),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "print(\"\\n--- DEBUG CHECK: Sigma_opt / mu_vec_opt ---\")\n",
    "print(\"Any NaN in Sigma_opt:\", Sigma_opt.isna().any().any())\n",
    "print(\"Any NaN in mu_vec_opt:\", mu_vec_opt.isna().any())\n",
    "print(\"Min variance:\", np.min(np.diag(Sigma_opt)))\n",
    "print(\"Number of assets:\", len(Sigma_opt))\n",
    "print(Sigma_opt.head())\n",
    "print(mu_vec_opt.head())\n",
    "print(\"OPT TICKERS:\", list(securities_opt))\n",
    "print(\"mu:\", mu_vec_opt.describe())\n",
    "print(\"Sigma diag min/max:\", Sigma_opt.values.diagonal().min(), Sigma_opt.values.diagonal().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 6 Transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _market_of(ticker: str) -> str:\n",
    "    t = str(ticker)\n",
    "    if t.startswith(\"^\"): return \"INDEX\"\n",
    "    if t.endswith(\".AX\"): return \"ASX\"\n",
    "    return \"US\"\n",
    "\n",
    "def compute_brokerage(trade_df: pd.DataFrame) -> tuple[float, pd.Series]:\n",
    "    \"\"\"Return (total_brokerage_AUD, per_row_series).\"\"\"\n",
    "    if trade_df.empty:\n",
    "        return 0.0, pd.Series(dtype=float)\n",
    "\n",
    "    fees = []\n",
    "    asx_buy_candidates = []  # (row_idx, trade_value) eligible for $0\n",
    "\n",
    "    for i, r in trade_df.iterrows():\n",
    "        # Skip rows with no actual trade\n",
    "        units = float(r.get(\"Δ Units\", 0.0))\n",
    "        if abs(units) < 1e-12:\n",
    "            fees.append(0.0)\n",
    "            continue\n",
    "\n",
    "        mkt = _market_of(r[\"Security\"])\n",
    "        px  = float(r.get(\"Last Px (AUD)\", 0.0))\n",
    "        trade_val = abs(units) * px\n",
    "\n",
    "        if mkt == \"US\":\n",
    "            fee = 0.0\n",
    "        elif mkt == \"ASX\":\n",
    "            fee = max(BROKERAGE[\"ASX\"][\"min_fee\"], BROKERAGE[\"ASX\"][\"rate\"] * trade_val)\n",
    "            # Track eligible “first buy ≤ $1k”\n",
    "            if units > 0 and trade_val <= BROKERAGE[\"ASX\"][\"first_buy_free_threshold\"] + 1e-9:\n",
    "                asx_buy_candidates.append((i, trade_val))\n",
    "        else:\n",
    "            fee = 0.0\n",
    "\n",
    "        fees.append(fee)\n",
    "\n",
    "    fees = pd.Series(fees, index=trade_df.index, name=\"Brokerage (AUD)\")\n",
    "\n",
    "    # Apply “first ASX buy ≤ $1k is $0” to ONE eligible row\n",
    "    if asx_buy_candidates:\n",
    "        # (Leave as smallest-eligible; change to reverse=True to pick the largest-eligible instead.)\n",
    "        idx0 = sorted(asx_buy_candidates, key=lambda x: x[1])[0][0]\n",
    "        fees.loc[idx0] = 0.0\n",
    "\n",
    "    return float(fees.sum()), fees\n",
    "\n",
    "\n",
    "def _read_lots_from_path(xl_path, sheet=\"Lots\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lots sheet schema:\n",
    "      Security | AcqDate | Units | CostBaseAUD\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet)\n",
    "    except Exception:\n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "    if df.empty: \n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "    if \"AcqDate\" in df.columns:\n",
    "        df[\"AcqDate\"] = pd.to_datetime(df[\"AcqDate\"], errors=\"coerce\")\n",
    "    for col in [\"Units\",\"CostBaseAUD\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def _is_long_term_au(acq_date: pd.Timestamp, sale_date: pd.Timestamp) -> bool:\n",
    "    \"\"\"\n",
    "    Australian CGT 50% discount rule:\n",
    "    asset must be held for at least 12 months between acquisition and sale.\n",
    "    Uses relativedelta to handle leap years correctly.\n",
    "    \"\"\"\n",
    "    if pd.isna(acq_date) or pd.isna(sale_date):\n",
    "        return False\n",
    "    return sale_date >= (pd.Timestamp(acq_date) + relativedelta(years=1))\n",
    "\n",
    "def _allocate_sale_to_lots(lots: pd.DataFrame, sell_units: float, sale_price_aud: float,\n",
    "                           sale_date: pd.Timestamp, method: str = \"HIFO\"):\n",
    "    \"\"\"\n",
    "    Consume lot units to satisfy a sale. Returns list of dicts with:\n",
    "      qty, acq_date, proceed, cost_base, gain, long_term\n",
    "    \"\"\"\n",
    "    if lots.empty or sell_units <= 0:\n",
    "        return []\n",
    "\n",
    "    lots = lots.copy()\n",
    "    if \"AcqDate\" in lots.columns:\n",
    "        lots[\"AcqDate\"] = pd.to_datetime(lots[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    # Sort by matching method\n",
    "    if method.upper() == \"HIFO\":\n",
    "        lots = lots.sort_values(by=[\"CostBaseAUD\", \"AcqDate\"], ascending=[False, True])\n",
    "    else:  # FIFO\n",
    "        lots = lots.sort_values(by=[\"AcqDate\"], ascending=True)\n",
    "\n",
    "    out = []\n",
    "    remaining = float(sell_units)\n",
    "    for _, L in lots.iterrows():\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        have = float(L[\"Units\"])\n",
    "        if have <= 0:\n",
    "            continue\n",
    "\n",
    "        qty = min(remaining, have)\n",
    "        cb_unit = float(L[\"CostBaseAUD\"])\n",
    "        acq = pd.Timestamp(L[\"AcqDate\"])\n",
    "\n",
    "        proceed = float(sale_price_aud) * qty\n",
    "        cost_base = cb_unit * qty\n",
    "        gain = proceed - cost_base\n",
    "        long_term = _is_long_term_au(acq, sale_date)\n",
    "\n",
    "        out.append({\n",
    "            \"qty\": qty,\n",
    "            \"acq_date\": acq,\n",
    "            \"proceed\": proceed,\n",
    "            \"cost_base\": cost_base,\n",
    "            \"gain\": gain,\n",
    "            \"long_term\": bool(long_term),\n",
    "        })\n",
    "        remaining -= qty\n",
    "\n",
    "    return out\n",
    "\n",
    "def compute_cgt_tax(trade_df: pd.DataFrame, lots_df: pd.DataFrame, sale_date: pd.Timestamp,\n",
    "                    marginal_rate: float, carry_forward_loss: float = 0.0,\n",
    "                    method: str = \"HIFO\") -> tuple[float, dict]:\n",
    "    \"\"\"\n",
    "    Returns (tax_AUD, breakdown_dict) with an 'audit' DataFrame so users can see exactly\n",
    "    how CGT was computed (per-lot).\n",
    "    \"\"\"\n",
    "    if trade_df.empty:\n",
    "        return 0.0, {\"st_gain\":0.0, \"lt_gain\":0.0, \"losses\":0.0,\n",
    "                     \"discounted_lt_after_losses\":0.0, \"taxable\":0.0, \"audit\": pd.DataFrame()}\n",
    "\n",
    "    lots_df = lots_df.copy()\n",
    "    if \"AcqDate\" in lots_df.columns:\n",
    "        lots_df[\"AcqDate\"] = pd.to_datetime(lots_df[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    # === DEBUG: inspect LOTS sheet structure ===\n",
    "    print(\"\\n=== LOTS_DF HEAD ===\")\n",
    "    print(lots_df.head(20))\n",
    "\n",
    "    # group lots by security for fast lookup\n",
    "    lots_by_sec = {s: g.copy() for s, g in lots_df.groupby(\"Security\")} if not lots_df.empty else {}\n",
    "\n",
    "    audit_rows = []\n",
    "    st_gain = 0.0; lt_gain = 0.0; losses = 0.0\n",
    "\n",
    "    for _, r in trade_df.iterrows():\n",
    "        dU = int(r.get(\"Δ Units\", 0))\n",
    "        if dU >= 0:  # only sells trigger CGT\n",
    "            continue\n",
    "        sec  = str(r[\"Security\"])\n",
    "        px_aud = float(r[\"Last Px (AUD)\"])\n",
    "        sell_qty = abs(dU)\n",
    "\n",
    "        ledger = _allocate_sale_to_lots(\n",
    "            lots_by_sec.get(sec, pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])),\n",
    "            sell_qty, px_aud, sale_date, method=method\n",
    "        )\n",
    "        sold = 0.0\n",
    "        for row in ledger:\n",
    "            sold += row[\"qty\"]\n",
    "            g = row[\"gain\"]\n",
    "            audit_rows.append({\n",
    "                \"Security\": sec,\n",
    "                \"Qty\": row[\"qty\"],\n",
    "                \"AcqDate\": row[\"acq_date\"],\n",
    "                \"SaleDate\": pd.Timestamp(sale_date),\n",
    "                \"Proceeds\": row[\"proceed\"],\n",
    "                \"CostBase\": row[\"cost_base\"],\n",
    "                \"Gain\": row[\"gain\"],\n",
    "                \"LongTermEligible\": bool(row[\"long_term\"])\n",
    "            })\n",
    "            if g >= 0:\n",
    "                if row[\"long_term\"]:\n",
    "                    lt_gain += g\n",
    "                else:\n",
    "                    st_gain += g\n",
    "            else:\n",
    "                losses += -g  # store as positive\n",
    "\n",
    "        # excess sells beyond recorded lots → treat as zero-gain (conservative)\n",
    "        _unused = max(0.0, sell_qty - sold)\n",
    "\n",
    "    # Apply losses (including carry-forward) first, optimally vs ST then LT\n",
    "    rem_losses = float(carry_forward_loss) + float(losses)\n",
    "    st_off = min(rem_losses, st_gain);  st_gain -= st_off;  rem_losses -= st_off\n",
    "    lt_off = min(rem_losses, lt_gain);  lt_gain -= lt_off;  rem_losses -= lt_off\n",
    "\n",
    "    # 50% discount on remaining long-term gains (AU individual rule)\n",
    "    discounted_lt = 0.5 * max(0.0, lt_gain)\n",
    "    taxable = max(0.0, st_gain + discounted_lt)\n",
    "\n",
    "    tax = float(marginal_rate) * float(taxable)\n",
    "    audit_df = pd.DataFrame(audit_rows)\n",
    "\n",
    "    bkd = {\n",
    "        \"st_gain\": float(st_gain),\n",
    "        \"lt_gain\": float(lt_gain),\n",
    "        \"losses\": float(losses + carry_forward_loss),\n",
    "        \"discounted_lt_after_losses\": float(discounted_lt),\n",
    "        \"taxable\": float(taxable),\n",
    "        \"audit\": audit_df\n",
    "    }\n",
    "    return float(tax), bkd\n",
    "\n",
    "def evaluate_transaction_costs(trade_df: pd.DataFrame, lots_df: pd.DataFrame,\n",
    "                               sale_date: pd.Timestamp, marginal_rate: float) -> dict:\n",
    "    brok_total, brok_series = compute_brokerage(trade_df)\n",
    "    tax_total, tax_bkd = compute_cgt_tax(trade_df, lots_df, sale_date,\n",
    "                                         marginal_rate=MARGINAL_TAX_RATE,\n",
    "                                         carry_forward_loss=CAPITAL_LOSS_CARRY_FWD,\n",
    "                                         method=LOT_MATCH_METHOD)\n",
    "    return {\"brokerage\": brok_total, \"cgt_tax\": tax_total,\n",
    "            \"total_cost\": brok_total + tax_total, \"breakdown\": tax_bkd,\n",
    "            \"per_row_brokerage\": brok_series}\n",
    "\n",
    "def _update_lots_after_trades(lots_df: pd.DataFrame, trade_df: pd.DataFrame,\n",
    "                              sale_date: pd.Timestamp, fx_map: pd.Series | dict):\n",
    "    \"\"\"\n",
    "    Apply executed trades to the Lots table:\n",
    "      - Sells: decrement matched lots using the current LOT_MATCH_METHOD (HIFO/FIFO).\n",
    "      - Buys:  append a new lot with AcqDate = sale_date and CostBaseAUD = Last Px (AUD).\n",
    "    Returns a NEW lots DataFrame (original not mutated).\n",
    "    \"\"\"\n",
    "    out = lots_df.copy()\n",
    "    if \"AcqDate\" in out.columns:\n",
    "        out[\"AcqDate\"] = pd.to_datetime(out[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    for _, tr in trade_df.iterrows():\n",
    "        sec = str(tr[\"Security\"])\n",
    "        dU = int(tr.get(\"Δ Units\", 0))\n",
    "        px_aud = float(tr.get(\"Last Px (AUD)\", 0.0))\n",
    "\n",
    "        if dU < 0:\n",
    "            # Sells: consume existing lots in the same order used for CGT allocation\n",
    "            lot_block = out[out[\"Security\"] == sec].copy()\n",
    "            if LOT_MATCH_METHOD.upper() == \"HIFO\":\n",
    "                lot_block = lot_block.sort_values(by=[\"CostBaseAUD\",\"AcqDate\"], ascending=[False, True])\n",
    "            else:\n",
    "                lot_block = lot_block.sort_values(by=[\"AcqDate\"], ascending=True)\n",
    "\n",
    "            remaining = abs(dU)\n",
    "            for i in lot_block.index:\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                have = float(out.at[i, \"Units\"])\n",
    "                take = min(remaining, have)\n",
    "                out.at[i, \"Units\"] = have - take\n",
    "                remaining -= take\n",
    "\n",
    "            # remove fully consumed lots\n",
    "            out = out[out[\"Units\"] > 0.0].copy()\n",
    "\n",
    "        elif dU > 0:\n",
    "            # Buys: create a new lot at today's AUD price\n",
    "            out = pd.concat([out, pd.DataFrame([{\n",
    "                \"Security\": sec,\n",
    "                \"AcqDate\": pd.Timestamp(sale_date),\n",
    "                \"Units\": int(dU),\n",
    "                \"CostBaseAUD\": px_aud\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        # dU == 0 → no action for this row\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block 7 Writing into the excel (i.e. formatting and building the actual sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed-path] holdings: rows=31, nonzero=19\n",
      "1 name: Chart 1 | title: Efficient Frontier & CAL (rf=4.00%)\n",
      "2 name: Chart 2 | title: Efficient Frontier & CAL (rf={rf_label})\n",
      "\n",
      "=== DEBUG FIRST NONZERO TRADE (inside make_trade_plan) ===\n",
      "  Security  Curr Units  Target Units  Δ Units  Last Px (AUD)  Cash Flow (AUD)\n",
      "0  A200.AX           0            29       29     141.029999     -4089.869965\n",
      "\n",
      "=== LOTS_DF HEAD ===\n",
      "   Security    AcqDate  Units  CostBaseAUD\n",
      "0    AT1.AX 2025-11-07    869     0.024000\n",
      "1    AT1.AX 2025-11-07     12     0.024000\n",
      "2    AT1.AX 2025-11-07     18     0.024000\n",
      "3    AT1.AX 2025-11-07     14     0.024000\n",
      "4    AT1.AX 2025-11-07     53     0.024000\n",
      "5    LKE.AX 2025-11-14  28051     0.057000\n",
      "6    AT1.AX 2025-11-21   1840     0.025000\n",
      "7    VSO.AX 2025-11-21     20    74.779999\n",
      "8    VSO.AX 2025-11-21      1    74.730003\n",
      "9    VSO.AX 2025-11-21     54    74.639999\n",
      "10  SMLL.AX 2025-11-21     36     4.495000\n",
      "11   AT1.AX 2025-11-21  27045     0.027000\n",
      "12  ETHI.AX 2025-11-21    273    16.200001\n",
      "13      GME 2025-11-21    270    30.918965\n",
      "14   LKE.AX 2025-11-21   5376     0.062000\n",
      "15  MTUM.AX 2025-11-21    126    28.549999\n",
      "16   NDQ.AX 2025-11-21     71    55.169998\n",
      "17  QLTY.AX 2025-11-21    122    32.419998\n",
      "18  QUAL.AX 2025-11-21    205    60.930000\n",
      "19  SMLL.AX 2025-11-21   1089     4.470000\n",
      "\n",
      "=== LOT-EXPANDED TABLE ===\n",
      "   Security    AcqDate  UnitsSold   AcqPrice     CostBase  Last Px (AUD)  \\\n",
      "0    AT1.AX 2025-11-07        869   0.024000    20.856000       0.027000   \n",
      "1    AT1.AX 2025-11-07         12   0.024000     0.288000       0.027000   \n",
      "2    AT1.AX 2025-11-07         18   0.024000     0.432000       0.027000   \n",
      "3    AT1.AX 2025-11-07         14   0.024000     0.336000       0.027000   \n",
      "4    AT1.AX 2025-11-07         53   0.024000     1.272000       0.027000   \n",
      "5    AT1.AX 2025-11-21       1840   0.025000    46.000001       0.027000   \n",
      "6    AT1.AX 2025-11-21      23644   0.027000   638.388017       0.027000   \n",
      "7      BLOK        NaT          6        NaN          NaN      86.046185   \n",
      "8    CSL.AX        NaT         26        NaN          NaN     179.160004   \n",
      "9       GME 2025-11-21        270  30.918965  8348.120507      30.936910   \n",
      "10      GME        NaT         17        NaN          NaN      30.936910   \n",
      "11   LKE.AX 2025-11-14       5369   0.057000   306.033000       0.062000   \n",
      "12  MTUM.AX 2025-11-21          2  28.549999    57.099998      28.549999   \n",
      "13  QUAL.AX 2025-11-21        141  60.930000  8591.130043      60.930000   \n",
      "14  VLUE.AX 2025-11-21         62  31.700001  1965.400047      31.700001   \n",
      "15  VMIN.AX 2025-11-21         37  62.450001  2310.650028      62.450001   \n",
      "16  VVLU.AX 2025-11-21         11  76.860001   845.460007      76.860001   \n",
      "17   WDS.AX 2025-11-21        154  25.549999  3934.699883      25.549999   \n",
      "18   WDS.AX        NaT          7        NaN          NaN      25.549999   \n",
      "\n",
      "    Cash Flow (AUD)  Brokerage (AUD)  RealisedGain  \n",
      "0        703.150019             11.0      2.607000  \n",
      "1        703.150019             11.0      0.036000  \n",
      "2        703.150019             11.0      0.054000  \n",
      "3        703.150019             11.0      0.042000  \n",
      "4        703.150019             11.0      0.159000  \n",
      "5        703.150019             11.0      3.680001  \n",
      "6        703.150019             11.0      0.000000  \n",
      "7        516.277112              0.0           NaN  \n",
      "8       4647.160095             11.0           NaN  \n",
      "9       8878.893080              0.0      4.845109  \n",
      "10      8878.893080              0.0           NaN  \n",
      "11       321.877995             11.0     26.844994  \n",
      "12        46.099998             11.0      0.000000  \n",
      "13      8580.130043             11.0      0.000000  \n",
      "14      1954.400047             11.0      0.000000  \n",
      "15      2299.650028             11.0      0.000000  \n",
      "16       834.460007             11.0      0.000000  \n",
      "17      4102.549877             11.0      0.000000  \n",
      "18      4102.549877             11.0           NaN  \n",
      "[debug] Current totals → Portfolio: 93195.72, Net Invested: 93115.12\n",
      "[debug] Previous totals → Portfolio: 92973.34, Net Invested: 93419.70\n",
      "[debug] Saved new state → Portfolio: 93195.72, Net Invested: 93115.12\n",
      "[pptx prep] PortfolioValue series computed for 31 securities.\n",
      "[pptx] Report saved to: C:\\Users\\Fionn Guina\\Portfolio_Optimiser\\Portfolio_Report.pptx\n",
      "Workbook Successfully Updated\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 10) WRITE TO EXCEL \n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Define path for saving portfolio state if not already defined\n",
    "state_path = os.path.join(os.path.dirname(filename), \"portfolio_state.json\")\n",
    "global results\n",
    "\n",
    "# ---- 10A) Read seeds (no COM; avoids UsedRange issues) ----\n",
    "seed_units, seed_include = _read_holdings_seed_from_path(filename, \"Holdings\")\n",
    "tilt_seed = _read_tilts_seed_from_path(filename, \"Tilts\")\n",
    "\n",
    "# Ensure MOM exists in the seed and rows are in the canonical order\n",
    "if not isinstance(tilt_seed, pd.DataFrame) or tilt_seed.empty:\n",
    "    tilt_seed = pd.DataFrame(\n",
    "        {\"Target\":[1.0] + [0.0]*(len(TILT_FACTORS)-1),\n",
    "         \"Band\":[0.20]*len(TILT_FACTORS),\n",
    "         \"Use?\":[True] + [False]*(len(TILT_FACTORS)-1)},\n",
    "        index=TILT_FACTORS\n",
    "    )\n",
    "else:\n",
    "    for f in TILT_FACTORS:\n",
    "        if f not in tilt_seed.index:\n",
    "            tilt_seed.loc[f] = {\"Target\":0.0, \"Band\":0.20, \"Use?\":False}\n",
    "    tilt_seed = tilt_seed.reindex(TILT_FACTORS)\n",
    "\n",
    "# ---- 10B) Combined dialog (holdings + tilts) ----\n",
    "res = edit_holdings_and_tilts_dialog(\n",
    "    prices=prices,\n",
    "    exclude=EXCLUDE_FROM_OPT,\n",
    "    seed_units=seed_units,\n",
    "    seed_include=seed_include,\n",
    "    seed_tilts=tilt_seed\n",
    ")\n",
    "if res is None:\n",
    "    units = seed_units.copy()\n",
    "    include_flags = seed_include.copy()\n",
    "    last_px_hold = prices.ffill().iloc[-1].reindex(units.index)\n",
    "    tilt_df = tilt_seed.copy()\n",
    "else:\n",
    "    units, last_px_hold, prices, include_flags, tilt_df = res\n",
    "    current_holdings_units = units.copy() \n",
    "\n",
    "# ---- Make optimiser globals available ----\n",
    "current_holdings_units = units\n",
    "securities_opt = list(units.index)\n",
    "lots_df = lots_df  # already loaded earlier in block 7\n",
    "gamma_cgt = 0.005        # soft penalty weight for CGT (tune as desired)\n",
    "beta_brokerage = 0.25    # soft penalty weight for brokerage (tune as desired)\n",
    "\n",
    "# --- helper: rebuild analytics from (possibly updated) prices ---\n",
    "def _rebuild_core_from_prices(prices, fx_ticker=\"USDAUD=X\", period=\"5y\"):\n",
    "    fx_raw = yf.download(fx_ticker, period=period, interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)\n",
    "    fx = fx_raw[\"Close\"] if isinstance(fx_raw, pd.DataFrame) else fx_raw\n",
    "    if isinstance(fx, pd.DataFrame):\n",
    "        fx = fx.iloc[:, 0]\n",
    "    fx = pd.to_numeric(fx, errors=\"coerce\").reindex(prices.index).ffill()\n",
    "\n",
    "    usd_cols = [c for c in prices.columns\n",
    "                if not str(c).endswith(\".AX\") and not str(c).startswith(\"^\")]\n",
    "    prices_aud = prices.copy()\n",
    "    if usd_cols:\n",
    "        prices_aud.update(prices.loc[:, usd_cols].mul(fx, axis=0))\n",
    "\n",
    "    d = (prices_aud.reset_index()\n",
    "         .melt(id_vars=\"Date\", var_name=\"Security\", value_name=\"Close\")\n",
    "         .sort_values([\"Security\", \"Date\"]))\n",
    "    d[\"Return\"] = d.groupby(\"Security\", sort=False)[\"Close\"].pct_change(fill_method=None)\n",
    "    d = d.dropna()\n",
    "\n",
    "    df_cov_wide = d.pivot(index=\"Date\", columns=\"Security\", values=\"Return\").sort_index()\n",
    "    Sigma_daily = df_cov_wide.cov()\n",
    "\n",
    "    d[\"LogRet\"] = np.log1p(d[\"Return\"])\n",
    "    mu_log_ann = d.groupby(\"Security\")[\"LogRet\"].mean() * 252.0\n",
    "    mu_ann_geo = np.expm1(mu_log_ann)\n",
    "\n",
    "    return prices_aud, d, df_cov_wide, Sigma_daily, mu_ann_geo\n",
    "\n",
    "# === Rebuild core analytics ===\n",
    "prices_aud_for_returns, df_melt, df_cov_wide, Sigma_daily, mu_ann_geo = _rebuild_core_from_prices(prices)\n",
    "\n",
    "# ---- Factors (FF5 + MOM) & betas ----\n",
    "FF5_LOOKBACK_DAYS = globals().get(\"FF5_LOOKBACK_DAYS\", 252*2)\n",
    "ff = get_ff5_mom_daily()\n",
    "ff_win = ff.tail(FF5_LOOKBACK_DAYS)\n",
    "fac_cols = [c for c in ff_win.columns if c != \"RF\"]\n",
    "B, alpha_daily, resid_var = compute_ff5_betas(df_cov_wide, ff_win, min_obs=120)\n",
    "\n",
    "# --- Force alignment and drop missing securities ---\n",
    "common = Sigma_daily.index.intersection(mu_ann_geo.index)\n",
    "common = [c for c in common if c not in EXCLUDE_FROM_OPT]\n",
    "\n",
    "Sigma_daily = Sigma_daily.loc[common, common]\n",
    "mu_ann_geo  = mu_ann_geo.loc[common]\n",
    "\n",
    "# Extra safety: drop zero-variance assets\n",
    "valid_var = Sigma_daily.sum(axis=1) > 0\n",
    "Sigma_daily = Sigma_daily.loc[valid_var, valid_var]\n",
    "mu_ann_geo  = mu_ann_geo.loc[valid_var]\n",
    "\n",
    "# ---- Choose μ and Σ source ----\n",
    "USE_FF5 = True\n",
    "if USE_FF5 and (B is not None) and not B.empty:\n",
    "    Fcov_daily = ff_win[fac_cols].cov()\n",
    "    S_diag = resid_var.reindex(B.index).clip(lower=0.0).fillna(0.0)\n",
    "    Sigma_ff_daily = B @ Fcov_daily @ B.T + np.diag(S_diag)\n",
    "    Sigma_ff_daily = pd.DataFrame(Sigma_ff_daily, index=B.index, columns=B.index)\n",
    "\n",
    "    f_mean_ann = ff_win[fac_cols].mean() * 252.0\n",
    "    mu_ff_ann  = (alpha_daily * 252.0).reindex(B.index).fillna(0.0) + (B @ f_mean_ann).rename(None) + rf_annual\n",
    "\n",
    "    securities_opt = [t for t in Sigma_ff_daily.index if t not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_ff_daily.loc[securities_opt, securities_opt]\n",
    "    mu_vec_opt = mu_ff_ann.reindex(securities_opt)\n",
    "    exp_ret_label = \"Expected Return (annual, FF5+MOM)\"\n",
    "else:\n",
    "    securities_all = [s for s in Sigma_daily.columns if s != \"PortfolioValue\"]\n",
    "    mu_vec_all = mu_ann_geo.reindex(securities_all)\n",
    "    valid_all = [s for s in securities_all\n",
    "                 if pd.notna(mu_vec_all.get(s)) and pd.notna(Sigma_daily.loc[s, s])]\n",
    "    securities_opt = [s for s in valid_all if s not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_daily.loc[securities_opt, securities_opt]\n",
    "    mu_vec_opt = mu_vec_all.reindex(securities_opt)\n",
    "    exp_ret_label = \"Expected Return (ann., geom)\"\n",
    "\n",
    "# Tables used later\n",
    "n_opt = len(securities_opt)\n",
    "cov_plus = pd.DataFrame(0.0, index=securities_opt + ['w'], columns=securities_opt + ['w'])\n",
    "cov_plus.iloc[:n_opt, :n_opt] = Sigma_opt.values\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "\n",
    "# FX map used by Holdings + trade plan\n",
    "usd_aud    = get_usd_aud_fx()\n",
    "fx_map_all = fx_to_aud_for_tickers(prices.columns, usd_aud)\n",
    "\n",
    "# ---- 10D) Reopen Excel and WRITE everything, then close ----\n",
    "if USE_XLWINGS:\n",
    "    try:\n",
    "        with xw.App(visible=False, add_book=False) as app:\n",
    "            wb = app.books.open(filename, update_links=False, read_only=False)\n",
    "            if bool(wb.api.ReadOnly):\n",
    "                raise RuntimeError(\"Workbook opened read-only; close it in Excel and try again.\")\n",
    "            wb.activate()\n",
    "            app.display_alerts = False\n",
    "            app.screen_updating = False\n",
    "            try: app.api.EnableEvents = False\n",
    "            except Exception: pass\n",
    "            time.sleep(0.2)\n",
    "\n",
    "            # Pick the max-Sharpe portfolio column once for reuse\n",
    "            sh = pd.to_numeric(stats_df['Sharpe'], errors='coerce').fillna(-1)\n",
    "            best_idx = int(sh.values.argmax()) if len(sh) else 0\n",
    "            w_star = W.iloc[:, best_idx].reindex(W.index).fillna(0.0)\n",
    "\n",
    "            # 1) Cov sheet\n",
    "            try:\n",
    "                cov = wb.sheets['Cov']; cov.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                cov = wb.sheets.add('Cov', after=wb.sheets[-1])\n",
    "            cov.range('A1').options(pd.DataFrame, index=True, header=True).value = Sigma_opt\n",
    "\n",
    "            # 2) Input sheet\n",
    "            try:\n",
    "                inp = wb.sheets['Input']; inp.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                inp = wb.sheets.add('Input', after=wb.sheets[-1])\n",
    "            inp.range('A1').options(pd.DataFrame, index=False, header=True).value = df_melt\n",
    "\n",
    "            # 3) OPT sheet\n",
    "            try:\n",
    "                opt = wb.sheets['OPT']; opt.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                opt = wb.sheets.add('OPT', after=wb.sheets[-1])\n",
    "\n",
    "            # Header\n",
    "            opt.range('A1').value = 'Optimal Portfolio Theory (long-only where possible)'\n",
    "            opt.range('A2').value = f\"Generated: {datetime.now():%Y-%m-%d %H:%M:%S}\"\n",
    "            opt.range('A3').value = 'Expected returns use geometric (log-based) annualisation.'\n",
    "            opt.range('A4').value = 'Variance is daily; annual vol = sqrt(252) * stdev.'\n",
    "            try:\n",
    "                opt.range('A1').api.Font.Bold = True; opt.range('A1').api.Font.Size = 14\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Expected returns\n",
    "            opt.range('A6').value = exp_ret_label\n",
    "            opt.range('A7').options(pd.DataFrame, index=True, header=True).value = exp_ret_df\n",
    "            n_rows = exp_ret_df.shape[0] + 1\n",
    "            try:\n",
    "                opt.range(f\"B8:B{7+n_rows}\").api.NumberFormat = \"0.00%\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Covariance (+ weight row/col)\n",
    "            start_cov_row = 9 + n_rows\n",
    "            opt.range(f\"A{start_cov_row}\").value = 'Covariance Matrix (daily, model) with weight row/column'\n",
    "            opt.range(f\"A{start_cov_row+1}\").options(pd.DataFrame, index=True, header=True).value = cov_plus.fillna(0.0)\n",
    "\n",
    "            # Weights grid\n",
    "            start_w_row = start_cov_row + cov_plus.shape[0] + 4\n",
    "            opt.range(f\"A{start_w_row}\").value = 'Optimised Weights by Target Return'\n",
    "            opt.range(f\"A{start_w_row+1}\").options(pd.DataFrame, index=True, header=True).value = W\n",
    "            # --- Dynamic format for W (optimised weights table) ---\n",
    "            w_first = start_w_row + 1               # header row\n",
    "            w_data_first = w_first + 1              # first data row\n",
    "            w_rows = W.shape[0]\n",
    "            w_cols = W.shape[1]\n",
    "            \n",
    "            # Percent format for all weight cells\n",
    "            rng_w = opt.range(\n",
    "                f\"B{w_data_first}:{chr(ord('A')+w_cols)}{w_data_first + w_rows - 1}\"\n",
    "            )\n",
    "            try:\n",
    "                rng_w.api.NumberFormat = \"0.00%\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Portfolio Statistics\n",
    "            start_s_row = start_w_row + W.shape[0] + 4\n",
    "            opt.range(f\"A{start_s_row}\").value = 'Portfolio Statistics'\n",
    "            opt.range(f\"A{start_s_row+1}\").options(pd.DataFrame, index=False, header=True).value = stats_df\n",
    "            # ==========================================================\n",
    "            #  Efficient Frontier Chart – SINGLE CREATION + POSITIONING\n",
    "            # ==========================================================\n",
    "            \n",
    "            chart_title = \"Efficient Frontier & CAL (rf={rf_label})\"\n",
    "            co = opt.api.ChartObjects()\n",
    "            \n",
    "            # 1. Find existing chart (by title)\n",
    "            chart_obj = None\n",
    "            for i in range(1, co.Count + 1):\n",
    "                o = co.Item(i)\n",
    "                try:\n",
    "                    if o.Chart.HasTitle and o.Chart.ChartTitle.Text.strip() == chart_title:\n",
    "                        chart_obj = o\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # 2. If no chart exists, create one\n",
    "            if chart_obj is None:\n",
    "                left = opt.range(\"I1\").api.Left                 # right of stats table\n",
    "                top  = opt.range(f\"A{start_s_row+1}\").api.Top    # align with stats header row\n",
    "                width = 480\n",
    "                height = 245\n",
    "                chart_obj = co.Add(left, top, width, height)\n",
    "                chart_obj.Chart.ChartType = -4169               # XY scatter\n",
    "                chart_obj.Chart.HasTitle = True\n",
    "                chart_obj.Chart.ChartTitle.Text = chart_title\n",
    "            \n",
    "            # 3. Reposition every run (side-by-side with stats)\n",
    "            chart_obj.Left = opt.range(\"I1\").api.Left\n",
    "            chart_obj.Top  = opt.range(f\"A{start_s_row+1}\").api.Top\n",
    "            chart_obj.Width = 480\n",
    "            chart_obj.Height = 245\n",
    "            \n",
    "            # This is the chart updater target\n",
    "            chart_for_updater = chart_obj\n",
    "            \n",
    "            # ----------------------------------------------------------\n",
    "            # Format Portfolio Statistics\n",
    "            # ----------------------------------------------------------\n",
    "            \n",
    "            stat_rows = stats_df.shape[0]\n",
    "            if stat_rows > 0:\n",
    "                header_row = start_s_row + 1\n",
    "                data_first = header_row + 1\n",
    "            \n",
    "                for col_name, fmt in {\n",
    "                    \"Achieved Return\": \"0.00%\",\n",
    "                    \"Volatility (ann.)\": \"0.00%\",\n",
    "                    \"Sharpe\": \"0.00\"\n",
    "                }.items():\n",
    "                    if col_name in stats_df.columns:\n",
    "                        col_idx = list(stats_df.columns).index(col_name)\n",
    "                        col_letter = chr(ord(\"A\") + col_idx)\n",
    "                        try:\n",
    "                            opt.range(\n",
    "                                f\"{col_letter}{data_first}:{col_letter}{data_first + stat_rows - 1}\"\n",
    "                            ).api.NumberFormat = fmt\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            # ================= Efficient Frontier chart updater =================\n",
    "            def _col_letter(idx0: int) -> str:\n",
    "                n = idx0 + 1  # A=1\n",
    "                letters = \"\"\n",
    "                while n:\n",
    "                    n, rem = divmod(n - 1, 26)\n",
    "                    letters = chr(65 + rem) + letters\n",
    "                return letters\n",
    "            \n",
    "            def _get_chart_by_title(opt_sheet, title_text: str):\n",
    "                \"\"\"Return the COM Chart object whose Title text equals title_text (case/space-insensitive).\"\"\"\n",
    "                def _norm(s): return \" \".join(str(s).split()).casefold()\n",
    "                co = opt_sheet.api.ChartObjects()\n",
    "                want = _norm(title_text)\n",
    "                for i in range(1, co.Count + 1):\n",
    "                    o = co.Item(i)\n",
    "                    try:\n",
    "                        ch = o.Chart\n",
    "                        if ch.HasTitle and _norm(ch.ChartTitle.Text) == want:\n",
    "                            return ch\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                raise RuntimeError(f\"Chart with title '{title_text}' not found on sheet '{opt_sheet.name}'\")\n",
    "            \n",
    "                def update_efficient_frontier_chart(\n",
    "                    opt_sheet,\n",
    "                    stats_df: pd.DataFrame,\n",
    "                    start_s_row: int,\n",
    "                    *,\n",
    "                    rf_annual: float,\n",
    "                    tan_ret: float,\n",
    "                    tan_vol: float,\n",
    "                    current_point: tuple | None = None,\n",
    "                    title_text: str | None = None\n",
    "                ):\n",
    "                    # Set dynamic title if none provided\n",
    "                    if title_text is None:\n",
    "                        title_text = chart_title\n",
    "                \n",
    "                # ---- Validate columns in stats_df ----\n",
    "                cols = list(stats_df.columns)\n",
    "                try:\n",
    "                    j_ret = cols.index(\"Achieved Return\")\n",
    "                    j_vol = cols.index(\"Volatility (ann.)\")\n",
    "                except ValueError:\n",
    "                    raise RuntimeError(\"stats_df must have columns 'Achieved Return' and 'Volatility (ann.)'.\")\n",
    "            \n",
    "                nrows = int(stats_df.shape[0])\n",
    "                if nrows <= 0:\n",
    "                    raise RuntimeError(\"stats_df has no rows; nothing to plot.\")\n",
    "            \n",
    "                # ---- Build Excel range references for X (Vol) and Y (Return) from the table you wrote ----\n",
    "                header_row = start_s_row + 1      # header row in Excel where you wrote stats_df header\n",
    "                first_row  = header_row + 1       # first data row\n",
    "                col_vol = _col_letter(j_vol)      # zero-based -> Excel column letters relative to column A\n",
    "                col_ret = _col_letter(j_ret)\n",
    "                x_rng = opt_sheet.range(f\"{col_vol}{first_row}:{col_vol}{first_row + nrows - 1}\").api\n",
    "                y_rng = opt_sheet.range(f\"{col_ret}{first_row}:{col_ret}{first_row + nrows - 1}\").api\n",
    "            \n",
    "                # ---- Grab the chart ----\n",
    "                rf = rf_annual\n",
    "                ch = _get_chart_by_title(opt_sheet, title_text)\n",
    "            \n",
    "                # ---- Clear existing series (keep object & styling) ----\n",
    "                try:\n",
    "                    while ch.SeriesCollection().Count > 0:\n",
    "                        ch.SeriesCollection(1).Delete()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "                # Excel ChartType constants (avoid win32com constants; use literals)\n",
    "                XL_XY_SCATTER              = -4169  # points only\n",
    "                XL_XY_SCATTER_LINES        = 74     # scatter with lines (markers on)\n",
    "                XL_MARKERSTYLE_NONE        = -4142\n",
    "                XL_MARKERSTYLE_CIRCLE      = 8\n",
    "                XL_MARKERSTYLE_PLUS        = 2\n",
    "                XL_AXIS_CATEGORY           = 1      # for XY charts Excel still treats X as a value axis, but this works for formatting\n",
    "                XL_AXIS_VALUE              = 2\n",
    "            \n",
    "                # ---- Efficient Frontier (smooth line, no markers) ----\n",
    "                s_front = ch.SeriesCollection().NewSeries()\n",
    "                s_front.Name = '=\"Efficient Frontier\"'\n",
    "                s_front.XValues = x_rng\n",
    "                s_front.Values  = y_rng\n",
    "                s_front.ChartType = XL_XY_SCATTER_LINES\n",
    "                try:\n",
    "                    s_front.MarkerStyle = XL_MARKERSTYLE_NONE\n",
    "                    s_front.Smooth = True\n",
    "                    # optional line weight for visibility\n",
    "                    s_front.Format.Line.Weight = 1.5\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "                # ---- CAL (smooth line from (0, rf) to (tan_vol, tan_ret)) ----\n",
    "                if np.all(np.isfinite([rf_annual, tan_ret, tan_vol])):\n",
    "                    s_cal = ch.SeriesCollection().NewSeries()\n",
    "                    s_cal.Name = '=\"CAL\"'\n",
    "                    s_cal.XValues = (0.0, float(tan_vol))\n",
    "                    s_cal.Values  = (float(rf_annual), float(tan_ret))\n",
    "                    s_cal.ChartType = XL_XY_SCATTER_LINES\n",
    "                    try:\n",
    "                        s_cal.MarkerStyle = XL_MARKERSTYLE_NONE\n",
    "                        s_cal.Smooth = True\n",
    "                        s_cal.Format.Line.Weight = 1.25\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            \n",
    "                # ---- MVP (single point at min volatility) ----\n",
    "                try:\n",
    "                    vol_series = pd.to_numeric(stats_df[\"Volatility (ann.)\"], errors=\"coerce\")\n",
    "                    ret_series = pd.to_numeric(stats_df[\"Achieved Return\"], errors=\"coerce\")\n",
    "                    mask = vol_series.notna() & ret_series.notna()\n",
    "                    if mask.any():\n",
    "                        idx_mvp = vol_series[mask].idxmin()\n",
    "                        mvp_x = float(vol_series.loc[idx_mvp])\n",
    "                        mvp_y = float(ret_series.loc[idx_mvp])\n",
    "                        s_mvp = ch.SeriesCollection().NewSeries()\n",
    "                        s_mvp.Name    = '=\"MVP\"'\n",
    "                        s_mvp.XValues = (mvp_x,)   # tuples, not lists, play nicer with COM\n",
    "                        s_mvp.Values  = (mvp_y,)\n",
    "                        s_mvp.ChartType = XL_XY_SCATTER\n",
    "                        try:\n",
    "                            s_mvp.MarkerStyle = XL_MARKERSTYLE_CIRCLE\n",
    "                            s_mvp.MarkerSize  = 8\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                except Exception as e:\n",
    "                    print(f\"[chart] MVP error: {e}\")\n",
    "            \n",
    "                # ---- Current portfolio (single point) ----\n",
    "                if current_point is not None:\n",
    "                    try:\n",
    "                        curr_vol, curr_ret = map(float, current_point)\n",
    "                        if np.isfinite(curr_vol) and np.isfinite(curr_ret):\n",
    "                            s_cur = ch.SeriesCollection().NewSeries()\n",
    "                            s_cur.Name    = '=\"Current\"'\n",
    "                            s_cur.XValues = (curr_vol,)\n",
    "                            s_cur.Values  = (curr_ret,)\n",
    "                            s_cur.ChartType = XL_XY_SCATTER\n",
    "                            try:\n",
    "                                s_cur.MarkerStyle = XL_MARKERSTYLE_PLUS\n",
    "                                s_cur.MarkerSize  = 10\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                    except Exception as e:\n",
    "                        print(f\"[chart] Current point error: {e}\")\n",
    "                        print(\"Did Block 7 create results?\", \"results\" in globals())\n",
    "\n",
    "                # ---- Axis number formats to percentages (best-effort) ----\n",
    "                for ax_type in (XL_AXIS_CATEGORY, XL_AXIS_VALUE):\n",
    "                    try:\n",
    "                        ch.Axes(ax_type).TickLabels.NumberFormat = \"0.0%\"\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            \n",
    "                # Keep legend; if chart had one it stays. Optionally ensure it exists:\n",
    "                try:\n",
    "                    ch.HasLegend = True\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # ================= End chart updater =================            \n",
    "            # -------- Example usage (fits your existing variables) --------\n",
    "            # Compute current portfolio point if you want it plotted; otherwise pass current_point=None.\n",
    "            current_point = None\n",
    "            try:\n",
    "                curr_w = current_holdings_weights(\n",
    "                    units=units,\n",
    "                    last_prices=last_px_hold,\n",
    "                    investable=list(Sigma_opt.index),\n",
    "                    fx_to_aud=fx_map_all\n",
    "                ).reindex(Sigma_opt.index).fillna(0.0)\n",
    "            \n",
    "                mu_use = mu_vec_opt.reindex(Sigma_opt.index).fillna(0.0).values\n",
    "                S_use  = Sigma_opt.values\n",
    "                wv     = curr_w.values\n",
    "            \n",
    "                curr_ret = float(mu_use @ wv)\n",
    "                curr_vol = float(np.sqrt(wv @ S_use @ wv) * np.sqrt(252.0))\n",
    "                current_point = (curr_vol, curr_ret)\n",
    "            except Exception as e:\n",
    "                print(f\"[chart] Current point compute error: {e}\")\n",
    "                current_point = None\n",
    "            \n",
    "            # Finally, update the existing chart on 'OPT'\n",
    "            # --- Efficient Frontier Chart Update (safe version) ---\n",
    "            try:\n",
    "                update_efficient_frontier_chart(\n",
    "                    opt_sheet=opt,\n",
    "                    stats_df=stats_df,\n",
    "                    start_s_row=start_s_row,\n",
    "                    rf_annual=float(rf_annual),\n",
    "                    tan_ret=float(tan_ret),\n",
    "                    tan_vol=float(tan_vol),\n",
    "                    current_point=current_point,\n",
    "                    title_text=chart_title\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[chart] Skipping chart update: {e}\")\n",
    " \n",
    "            co = opt.api.ChartObjects()\n",
    "            for i in range(1, co.Count + 1):\n",
    "                o = co.Item(i)\n",
    "                title = \"\"\n",
    "                try:\n",
    "                    if o.Chart.HasTitle:\n",
    "                        title = o.Chart.ChartTitle.Text\n",
    "                except Exception:\n",
    "                    pass\n",
    "                print(i, \"name:\", o.Name, \"| title:\", title)\n",
    "\n",
    "          \n",
    "            # ---- Build trade plan & costs BEFORE writing Trade Plan/Costs/Tilts ----\n",
    "            trade_rec, resid_rec = make_trade_plan(\n",
    "                units, last_px_hold, fx_map_all, w_star, include_zero_lines=True, include_flags=include_flags\n",
    "            )\n",
    "\n",
    "            costs_rec = evaluate_transaction_costs(\n",
    "                trade_rec, lots_df, pd.Timestamp(prices.index[-1]), MARGINAL_TAX_RATE\n",
    "            )\n",
    "\n",
    "            trade_rec = trade_rec.copy()\n",
    "            trade_rec[\"Brokerage (AUD)\"] = costs_rec[\"per_row_brokerage\"].reindex(trade_rec.index).fillna(0.0).round(2)\n",
    "\n",
    "            trade_rec.drop(columns=[c for c in trade_rec.columns if c.lower().startswith(\"promo\")],\n",
    "                           errors=\"ignore\", inplace=True)\n",
    "\n",
    "            lot_expanded = expand_with_lots(\n",
    "                trade_rec,\n",
    "                lots_df,\n",
    "                sale_date=pd.Timestamp(prices.index[-1]),\n",
    "                method=\"FIFO\"\n",
    "            )\n",
    "            print(\"\\n=== LOT-EXPANDED TABLE ===\")\n",
    "            print(lot_expanded.head(20))\n",
    "\n",
    "            # === Build CGT audit table (parcel-level) ===\n",
    "            try:\n",
    "                tax_bkd = costs_rec.get(\"breakdown\", {})\n",
    "                audit_df = tax_bkd.get(\"audit\", pd.DataFrame()).copy()\n",
    "\n",
    "                if not audit_df.empty:\n",
    "                    # Ensure proper dtypes\n",
    "                    audit_df[\"AcqDate\"] = pd.to_datetime(audit_df[\"AcqDate\"], errors=\"coerce\")\n",
    "                    audit_df[\"SaleDate\"] = pd.to_datetime(audit_df[\"SaleDate\"], errors=\"coerce\")\n",
    "                    audit_df[\"Qty\"]      = pd.to_numeric(audit_df[\"Qty\"], errors=\"coerce\")\n",
    "                    audit_df[\"Proceeds\"] = pd.to_numeric(audit_df[\"Proceeds\"], errors=\"coerce\")\n",
    "                    audit_df[\"CostBase\"] = pd.to_numeric(audit_df[\"CostBase\"], errors=\"coerce\")\n",
    "                    audit_df[\"Gain\"]     = pd.to_numeric(audit_df[\"Gain\"], errors=\"coerce\")\n",
    "\n",
    "                    # Holding period & discount flag (12-month rule)\n",
    "                    audit_df[\"HoldingDays\"] = (audit_df[\"SaleDate\"] - audit_df[\"AcqDate\"]).dt.days\n",
    "                    audit_df[\"LongTermEligible\"] = audit_df[\"LongTermEligible\"].astype(bool)\n",
    "\n",
    "                    # 50% discount only for positive gains that are LT eligible\n",
    "                    audit_df[\"DiscountRate\"] = 0.0\n",
    "                    audit_df.loc[(audit_df[\"Gain\"] > 0) & (audit_df[\"LongTermEligible\"]), \"DiscountRate\"] = 0.5\n",
    "\n",
    "                    audit_df[\"DiscountedGainIllustrative\"] = audit_df[\"Gain\"]\n",
    "                    mask_disc = (audit_df[\"Gain\"] > 0) & (audit_df[\"LongTermEligible\"])\n",
    "                    audit_df.loc[mask_disc, \"DiscountedGainIllustrative\"] = (\n",
    "                        audit_df.loc[mask_disc, \"Gain\"] * 0.5\n",
    "                    )\n",
    "\n",
    "                    # === Write parcel-level audit sheet ===\n",
    "                    try:\n",
    "                        try:\n",
    "                            sht_cgt = wb.sheets[\"CGT_Audit\"]\n",
    "                        except Exception:\n",
    "                            sht_cgt = wb.sheets.add(\"CGT_Audit\", after=wb.sheets[-1])\n",
    "\n",
    "                        sht_cgt.used_range.clear_contents()\n",
    "                        sht_cgt.range(\"A1\").value = [[\n",
    "                            \"Security\",\n",
    "                            \"Qty\",\n",
    "                            \"AcqDate\",\n",
    "                            \"SaleDate\",\n",
    "                            \"Proceeds\",\n",
    "                            \"CostBase\",\n",
    "                            \"Gain\",\n",
    "                            \"LongTermEligible\",\n",
    "                            \"HoldingDays\",\n",
    "                            \"DiscountRate\",\n",
    "                            \"DiscountedGainIllustrative\",\n",
    "                        ]]\n",
    "                        sht_cgt.range(\"A2\").options(index=False, header=False).value = audit_df[\n",
    "                            [\n",
    "                                \"Security\",\n",
    "                                \"Qty\",\n",
    "                                \"AcqDate\",\n",
    "                                \"SaleDate\",\n",
    "                                \"Proceeds\",\n",
    "                                \"CostBase\",\n",
    "                                \"Gain\",\n",
    "                                \"LongTermEligible\",\n",
    "                                \"HoldingDays\",\n",
    "                                \"DiscountRate\",\n",
    "                                \"DiscountedGainIllustrative\",\n",
    "                            ]\n",
    "                        ]\n",
    "                    except Exception as e_cgt_sheet:\n",
    "                        print(f\"[cgt] could not write CGT_Audit sheet: {e_cgt_sheet}\")\n",
    "\n",
    "                    # === Optional security-level summary ===\n",
    "                    try:\n",
    "                        sec_grp = audit_df.groupby(\"Security\", as_index=False).agg(\n",
    "                            ProceedsTotal=(\"Proceeds\", \"sum\"),\n",
    "                            CostBaseTotal=(\"CostBase\", \"sum\"),\n",
    "                            GainTotal=(\"Gain\", \"sum\"),\n",
    "                        )\n",
    "\n",
    "                        lt_mask = audit_df[\"LongTermEligible\"]\n",
    "                        st_mask = ~audit_df[\"LongTermEligible\"]\n",
    "\n",
    "                        lt_sum = (\n",
    "                            audit_df.loc[lt_mask]\n",
    "                            .groupby(\"Security\")[\"Gain\"]\n",
    "                            .sum()\n",
    "                            .rename(\"LongTermGain\")\n",
    "                        )\n",
    "                        st_sum = (\n",
    "                            audit_df.loc[st_mask]\n",
    "                            .groupby(\"Security\")[\"Gain\"]\n",
    "                            .sum()\n",
    "                            .rename(\"ShortTermGain\")\n",
    "                        )\n",
    "\n",
    "                        sec_summary = (\n",
    "                            sec_grp\n",
    "                            .merge(lt_sum, on=\"Security\", how=\"left\")\n",
    "                            .merge(st_sum, on=\"Security\", how=\"left\")\n",
    "                            .fillna(0.0)\n",
    "                        )\n",
    "\n",
    "                        sht_cgt.range(\"L1\").value = [[\n",
    "                            \"Security\",\n",
    "                            \"ProceedsTotal\",\n",
    "                            \"CostBaseTotal\",\n",
    "                            \"GainTotal\",\n",
    "                            \"LongTermGain\",\n",
    "                            \"ShortTermGain\",\n",
    "                        ]]\n",
    "                        sht_cgt.range(\"L2\").options(index=False, header=False).value = sec_summary[\n",
    "                            [\n",
    "                                \"Security\",\n",
    "                                \"ProceedsTotal\",\n",
    "                                \"CostBaseTotal\",\n",
    "                                \"GainTotal\",\n",
    "                                \"LongTermGain\",\n",
    "                                \"ShortTermGain\",\n",
    "                            ]\n",
    "                        ]\n",
    "                    except Exception as e_cgt_summary:\n",
    "                        print(f\"[cgt] could not write CGT summary: {e_cgt_summary}\")\n",
    "\n",
    "                else:\n",
    "                    print(\"[cgt] audit_df is empty (no CGT-relevant sells).\")\n",
    "\n",
    "            except Exception as e_cgt:\n",
    "                print(f\"[cgt] error building CGT audit table: {e_cgt}\")\n",
    "\n",
    "            \n",
    "            # ---- Achieved factor tilts table (from B and w_star) ----\n",
    "            tilts_out = None\n",
    "            if (B is not None) and (not B.empty):\n",
    "                factor_order = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "                w_use = w_star.reindex(B.index).fillna(0.0)\n",
    "                if float(w_use.sum()) > 0:\n",
    "                    w_use = w_use / float(w_use.sum())\n",
    "                achieved_series = (B.T @ w_use).rename(\"Achieved β\").reindex(factor_order)\n",
    "\n",
    "                if isinstance(tilt_df, pd.DataFrame) and not tilt_df.empty:\n",
    "                    tgt = tilt_df.reindex(factor_order)\n",
    "                    tilts_out = pd.DataFrame({\n",
    "                        \"Use?\":      tgt[\"Use?\"].astype(bool).map({True: \"Yes\", False: \"No\"}),\n",
    "                        \"Target β\":  pd.to_numeric(tgt[\"Target\"], errors=\"coerce\"),\n",
    "                        \"Band\":      pd.to_numeric(tgt[\"Band\"],   errors=\"coerce\"),\n",
    "                        \"Achieved β\": achieved_series,\n",
    "                    })\n",
    "                    tilts_out[\"Diff\"] = tilts_out[\"Achieved β\"] - tilts_out[\"Target β\"]\n",
    "                    tilts_out[\"Within Band?\"] = (tilts_out[\"Diff\"].abs() <= tilts_out[\"Band\"]).map({True: \"Yes\", False: \"No\"})\n",
    "                else:\n",
    "                    tilts_out = achieved_series.to_frame()\n",
    "\n",
    "            # ---------- Layout anchors (avoid overlaps) ----------\n",
    "            anchor_row = start_s_row + stats_df.shape[0] + 4\n",
    "            TP_COL, COST_COL, TILT_COL = \"A\", \"J\", \"M\"\n",
    "\n",
    "            # ---------- LEFT: Trade Plan ----------\n",
    "            opt.range(f\"{TP_COL}{anchor_row}\").value = \"Trade Plan (rounded units)\"\n",
    "            opt.range(f\"{TP_COL}{anchor_row+1}\").options(pd.DataFrame, index=False, header=True).value = trade_rec\n",
    "            # --- Dynamic formatting for Trade Plan table ---\n",
    "            tp_start = anchor_row + 1\n",
    "            tp_data_first = tp_start + 1\n",
    "            tp_rows = trade_rec.shape[0]\n",
    "            tp_cols = trade_rec.shape[1]\n",
    "            \n",
    "            for col in trade_rec.columns:\n",
    "                col_idx = list(trade_rec.columns).index(col)\n",
    "                col_letter = chr(ord(\"A\") + col_idx)\n",
    "                rng = opt.range(f\"{col_letter}{tp_data_first}:{col_letter}{tp_data_first + tp_rows - 1}\")\n",
    "            \n",
    "                fmt = None\n",
    "                if \"Px\" in col or \"Flow\" in col or \"Brokerage\" in col:\n",
    "                    fmt = \"$#,##0.00\"\n",
    "                elif \"Units\" in col:\n",
    "                    fmt = \"0\"\n",
    "                if fmt:\n",
    "                    try:\n",
    "                        rng.api.NumberFormat = fmt\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            # --- Add portfolio value & cash summary underneath the Trade Plan ---\n",
    "            net_invested = 0.0\n",
    "            cash_balance = 0.0\n",
    "        \n",
    "            if not trade_rec.empty:\n",
    "                # Value of target holdings\n",
    "                tgt_units = pd.to_numeric(trade_rec[\"Target Units\"], errors=\"coerce\").fillna(0.0)\n",
    "                last_px_aud = pd.to_numeric(trade_rec[\"Last Px (AUD)\"], errors=\"coerce\").fillna(0.0)\n",
    "                net_invested = float((tgt_units * last_px_aud).sum())\n",
    "        \n",
    "                # Net cash after trades (positive = cash released, negative = extra cash needed)\n",
    "                cash_balance = float(pd.to_numeric(trade_rec[\"Cash Flow (AUD)\"], errors=\"coerce\").fillna(0.0).sum())\n",
    "        \n",
    "            total_portfolio = net_invested + cash_balance\n",
    "        \n",
    "            summary_row = anchor_row + trade_rec.shape[0] + 4\n",
    "            opt.range(f\"{TP_COL}{summary_row}\").value = [\n",
    "                [\"Portfolio Value (Holdings)\", net_invested],\n",
    "                [\"Cash\",                      cash_balance],\n",
    "                [\"Total Portfolio\",           total_portfolio],\n",
    "            ]\n",
    "            try:\n",
    "                # Bold the three summary labels and format the numbers as currency\n",
    "                rng_labels = opt.range(f\"{TP_COL}{summary_row}:{TP_COL}{summary_row+2}\").api\n",
    "                rng_labels.Font.Bold = True\n",
    "                rng_vals = opt.range(f\"{TP_COL}{summary_row}:{TP_COL}{summary_row+2}\").offset(0, 1).api\n",
    "                rng_vals.NumberFormat = \"$0.00\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # ---------- MIDDLE: Transaction Costs summary ----------\n",
    "            opt.range(f\"{COST_COL}{anchor_row}\").value = \"Transaction Costs (AUD)\"\n",
    "            opt.range(f\"{COST_COL}{anchor_row+1}\").value = [\n",
    "                [\"Brokerage\", \"CGT Tax\", \"Total\"],\n",
    "                [costs_rec[\"brokerage\"], costs_rec[\"cgt_tax\"], costs_rec[\"total_cost\"]],\n",
    "            ]\n",
    "            try:\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").api.NumberFormat = \"0.00\"\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").offset(0,1).api.NumberFormat = \"0.00\"\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").offset(0,2).api.NumberFormat = \"0.00\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # ---------- RIGHT: Achieved Factor Tilts ----------\n",
    "            if tilts_out is not None:\n",
    "                opt.range(f\"{TILT_COL}{anchor_row}\").value = \"Achieved Factor Tilts vs Targets\"\n",
    "                opt.range(f\"{TILT_COL}{anchor_row+1}\").options(pd.DataFrame, index=True, header=True).value = tilts_out\n",
    "                t_rows = tilts_out.shape[0] + 1\n",
    "                t_first = anchor_row + 1\n",
    "                t_data_first = t_first + 1\n",
    "                try:\n",
    "                    for col_name in [\"Target β\",\"Band\",\"Achieved β\",\"Diff\"]:\n",
    "                        if col_name in tilts_out.columns:\n",
    "                            idx = list(tilts_out.columns).index(col_name)\n",
    "                            col_letter = chr(ord(TILT_COL) + 1 + idx)  # after index column\n",
    "                            opt.range(f\"{col_letter}{t_data_first}:{col_letter}{t_first+t_rows}\").api.NumberFormat = \"0.000\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # ---------- BELOW RIGHT: Factor Feasible Ranges (long-only, sum=1) ----------\n",
    "            if (B is not None) and (not B.empty):\n",
    "                factor_order = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "                rng_df = compute_factor_feasible_ranges(B, include_flags=include_flags, factor_order=factor_order)\n",
    "            \n",
    "                # Optional: show your target & achieved alongside the ranges\n",
    "                if isinstance(tilts_out, pd.DataFrame):\n",
    "                    # pull Target and Achieved columns safely\n",
    "                    tgt = pd.to_numeric(tilts_out.get(\"Target β\", np.nan), errors=\"coerce\")\n",
    "                    ach = pd.to_numeric(tilts_out.get(\"Achieved β\", np.nan), errors=\"coerce\")\n",
    "                    rng_df = rng_df.join(tgt.rename(\"Target β\")).join(ach.rename(\"Achieved β\"))\n",
    "                    rng_df[\"Within Range?\"] = (rng_df[\"Target β\"] >= rng_df[\"Min β\"]) & (rng_df[\"Target β\"] <= rng_df[\"Max β\"])\n",
    "            \n",
    "                # place a few rows *below* the achieved-tilts table to avoid overlap\n",
    "                tilt_rows = (tilts_out.shape[0] + 2) if isinstance(tilts_out, pd.DataFrame) else 3\n",
    "                ranges_anchor = anchor_row + tilt_rows + 2\n",
    "            \n",
    "                opt.range(f\"{TILT_COL}{ranges_anchor}\").value = \"Factor Feasible Ranges (long-only, sum=1)\"\n",
    "                opt.range(f\"{TILT_COL}{ranges_anchor+1}\").options(pd.DataFrame, index=True, header=True).value = rng_df\n",
    "            \n",
    "                # number formats\n",
    "                rr = ranges_anchor + 1\n",
    "                rr_rows = rng_df.shape[0] + 1\n",
    "                try:\n",
    "                    # format numeric columns to 3 decimals if present\n",
    "                    for col_name in [\"Min β\",\"Max β\",\"Target β\",\"Achieved β\"]:\n",
    "                        if col_name in rng_df.columns:\n",
    "                            idx = list(rng_df.columns).index(col_name)\n",
    "                            # first data column is one to the right of TILT_COL\n",
    "                            col_letter = chr(ord(TILT_COL) + 1 + idx)\n",
    "                            opt.range(f\"{col_letter}{rr+1}:{col_letter}{rr+rr_rows}\").api.NumberFormat = \"0.000\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Final tidy\n",
    "            try: opt.autofit()\n",
    "            except Exception: pass\n",
    "\n",
    "            # 4) FF5F sheet (optional transparency)\n",
    "            try:\n",
    "                ff5s = wb.sheets['FF5F']; ff5s.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                ff5s = wb.sheets.add('FF5F', after=wb.sheets[-1])\n",
    "            ff5s.range('A1').options(pd.DataFrame, index=True, header=True).value = ff\n",
    "\n",
    "            # ---- Update Lots and overwrite Holdings with target units (for next run) ----\n",
    "            UPDATED_LOTS = _update_lots_after_trades(lots_df, trade_rec, pd.Timestamp(prices.index[-1]), fx_map_all)\n",
    "            try:\n",
    "                sht_lots = wb.sheets['Lots']\n",
    "            except Exception:\n",
    "                sht_lots = wb.sheets.add('Lots', after=wb.sheets[-1])\n",
    "            sht_lots.used_range.clear_contents()\n",
    "            sht_lots.range(\"A1\").value = [[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"]]\n",
    "            sht_lots.range(\"A2\").options(index=False, header=False).value = UPDATED_LOTS\n",
    "\n",
    "            tgt_units_full = compute_target_units_for_holdings(\n",
    "                units, last_px_hold, fx_map_all, w_star, include_flags\n",
    "            )\n",
    "            _write_holdings_sheet(wb, prices, tgt_units_full, include_flags,\n",
    "                                  sheet_name=\"Holdings\", fx_to_aud_map=fx_map_all)\n",
    "\n",
    "            # --- Step 1: Compute current portfolio values ---\n",
    "            if not trade_rec.empty:\n",
    "                trade_rec[\"Target Units\"] = pd.to_numeric(trade_rec[\"Target Units\"], errors=\"coerce\").fillna(0.0)\n",
    "                trade_rec[\"Last Px (AUD)\"] = pd.to_numeric(trade_rec[\"Last Px (AUD)\"], errors=\"coerce\").fillna(0.0)\n",
    "                trade_rec[\"Value\"] = trade_rec[\"Target Units\"] * trade_rec[\"Last Px (AUD)\"]\n",
    "                net_invested = float(trade_rec[\"Value\"].sum())\n",
    "                # Net cash after trades (already net of brokerage)\n",
    "                cash_balance = float(pd.to_numeric(trade_rec[\"Cash Flow (AUD)\"], errors=\"coerce\").fillna(0.0).sum())\n",
    "            else:\n",
    "                net_invested = 0.0\n",
    "                cash_balance = 0.0\n",
    "        \n",
    "            # Brokerage (for reporting only – already baked into cash_balance)\n",
    "            total_brokerage = float(costs_rec.get(\"brokerage\", 0.0))\n",
    "        \n",
    "            # Total portfolio = holdings + cash\n",
    "            total_portfolio = net_invested + cash_balance\n",
    "            \n",
    "            print(f\"[debug] Current totals → Portfolio: {total_portfolio:.2f}, Net Invested: {net_invested:.2f}\")\n",
    "            \n",
    "            # --- Step 2: Load previous run data (AFTER calculating current totals) ---\n",
    "            if os.path.exists(state_path):\n",
    "                with open(state_path, \"r\") as f:\n",
    "                    prev_state = json.load(f)\n",
    "                previous_portfolio = prev_state.get(\"portfolio_value\", 0.0)\n",
    "                previous_invested = prev_state.get(\"net_invested\", 0.0)\n",
    "                print(f\"[debug] Previous totals → Portfolio: {previous_portfolio:.2f}, Net Invested: {previous_invested:.2f}\")\n",
    "            else:\n",
    "                previous_portfolio = 0.0\n",
    "                previous_invested = 0.0\n",
    "                print(\"[info] No previous state file found — starting fresh deltas at 0.\")\n",
    "            \n",
    "            # --- Step 3: Compute deltas for PowerPoint ---\n",
    "            results = {\n",
    "                \"total_brokerage\": total_brokerage,\n",
    "                \"net_invested\": net_invested,\n",
    "                \"total_portfolio_value\": total_portfolio,\n",
    "                \"portfolio_change\": total_portfolio - previous_portfolio,\n",
    "                \"net_invested_change\": net_invested - previous_invested,\n",
    "            }\n",
    "            \n",
    "            # --- Step 4: Save current state for next comparison ---\n",
    "            with open(state_path, \"w\") as f:\n",
    "                json.dump(\n",
    "                    {\"portfolio_value\": total_portfolio, \"net_invested\": net_invested},\n",
    "                    f,\n",
    "                    indent=2\n",
    "                )\n",
    "            print(f\"[debug] Saved new state → Portfolio: {total_portfolio:.2f}, Net Invested: {net_invested:.2f}\")\n",
    "            \n",
    "            # --- Step 5: Generate PowerPoint summary ---\n",
    "            trades = trade_rec.copy()\n",
    "            charts = None\n",
    "            \n",
    "            # --- Step 6: Compute PortfolioValue for PowerPoint charts ---\n",
    "            try:\n",
    "                holdings_df = pd.read_excel(filename, sheet_name=\"Holdings\")\n",
    "                holdings_df = holdings_df.dropna(subset=[\"Security\", \"Units\"])\n",
    "                valid_tickers = [t for t in holdings_df[\"Security\"].astype(str) if t in prices.columns]\n",
    "                if not valid_tickers:\n",
    "                    raise ValueError(\"No valid tickers found in prices for holdings.\")\n",
    "                port_prices = prices[valid_tickers].copy()\n",
    "                units = holdings_df.set_index(\"Security\").loc[valid_tickers, \"Units\"]\n",
    "                port_prices = port_prices.ffill().bfill()\n",
    "                portfolio_value_series = (port_prices * units.values).sum(axis=1)\n",
    "                portfolio_value_series = portfolio_value_series.ffill().bfill()\n",
    "                print(f\"[pptx prep] PortfolioValue series computed for {len(valid_tickers)} securities.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[pptx prep] Could not compute PortfolioValue: {e}\")            \n",
    "            try:\n",
    "                ppt_path = export_to_ppt(results, trades, charts)\n",
    "            except Exception as e:\n",
    "                print(f\"[pptx] Skipped PowerPoint generation: {e}\")\n",
    "\n",
    "           \n",
    "            wb.save()\n",
    "            wb.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Excel fallback] xlwings/COM error → exporting CSVs instead: {e}\")\n",
    "        export_dir = os.path.join(os.path.dirname(filename), \"Exports\")\n",
    "        try: os.makedirs(export_dir, exist_ok=True)\n",
    "        except Exception: pass\n",
    "        try: exp_ret_df.to_csv(os.path.join(export_dir, \"expected_returns.csv\"))\n",
    "        except Exception as ee: print(f\"[export] expected_returns.csv: {ee}\")\n",
    "        try: cov_plus.to_csv(os.path.join(export_dir, \"covariance_plus.csv\"))\n",
    "        except Exception as ee: print(f\"[export] covariance_plus.csv: {ee}\")\n",
    "        try: W.to_csv(os.path.join(export_dir, \"weights_grid.csv\"))\n",
    "        except Exception as ee: print(f\"[export] weights_grid.csv: {ee}\")\n",
    "        try: stats_df.to_csv(os.path.join(export_dir, \"portfolio_stats.csv\"), index=False)\n",
    "        except Exception as ee: print(f\"[export] portfolio_stats.csv: {ee}\")\n",
    "        try: tilt_df.to_csv(os.path.join(export_dir, \"tilts.csv\"))\n",
    "        except Exception as ee: print(f\"[export] tilts.csv: {ee}\")\n",
    "        try: df_melt.to_csv(os.path.join(export_dir, \"returns_long.csv\"), index=False)\n",
    "        except Exception as ee: print(f\"[export] returns_long.csv: {ee}\")\n",
    "else:\n",
    "    # ---------- Headless fallback: write key outputs as CSVs ----------\n",
    "    export_dir = os.path.join(os.path.dirname(filename), \"Exports\")\n",
    "    try: os.makedirs(export_dir, exist_ok=True)\n",
    "    except Exception: pass\n",
    "    try: exp_ret_df.to_csv(os.path.join(export_dir, \"expected_returns.csv\"))\n",
    "    except Exception as e: print(f\"[export] expected_returns.csv: {e}\")\n",
    "    try: cov_plus.to_csv(os.path.join(export_dir, \"covariance_plus.csv\"))\n",
    "    except Exception as e: print(f\"[export] covariance_plus.csv: {e}\")\n",
    "    try: W.to_csv(os.path.join(export_dir, \"weights_grid.csv\"))\n",
    "    except Exception as e: print(f\"[export] weights_grid.csv: {e}\")\n",
    "    try: stats_df.to_csv(os.path.join(export_dir, \"portfolio_stats.csv\"), index=False)\n",
    "    except Exception as e: print(f\"[export] portfolio_stats.csv: {e}\")\n",
    "    try: tilt_df.to_csv(os.path.join(export_dir, \"tilts.csv\"))\n",
    "    except Exception as e: print(f\"[export] tilts.csv: {e}\")\n",
    "    try: df_melt.to_csv(os.path.join(export_dir, \"returns_long.csv\"), index=False)\n",
    "    except Exception as e: print(f\"[export] returns_long.csv: {e}\")\n",
    "\n",
    "print(\"Workbook Successfully Updated\")\n",
    "\n",
    "# --- Create a Desktop shortcut (optional, safe in any context) ---\n",
    "try:\n",
    "    if HAS_WIN32COM:\n",
    "        shortcut_path = str(Path.home() / \"Desktop\" / \"Portfolio Optimiser.lnk\")\n",
    "\n",
    "        # Prefer the exe if it exists; otherwise point at the script we’re running.\n",
    "        # Works when frozen, when run as .py, and in Jupyter (falls back to .py name in APP_DIR).\n",
    "        if getattr(sys, \"frozen\", False):\n",
    "            target = Path(sys.executable)\n",
    "        else:\n",
    "            # Try the current file if available; else fall back to a known script name in this folder\n",
    "            if \"__file__\" in globals():\n",
    "                target = Path(__file__).resolve()\n",
    "            else:\n",
    "                # Adjust the name if your launcher script is 'Main.py' instead\n",
    "                # (You have both Main.py and Portfolio_Optimiser3110.py in your screenshot.)\n",
    "                candidate = APP_DIR / \"Portfolio_Optimiser1411.py\"\n",
    "                target = candidate if candidate.exists() else (APP_DIR / \"Main.py\")\n",
    "\n",
    "        shell = win32.Dispatch(\"WScript.Shell\")\n",
    "        sc = shell.CreateShortCut(shortcut_path)\n",
    "        sc.WindowStyle = 1  # normal window\n",
    "        sc.Arguments = \"\"   # no extra args      \n",
    "        sc.Targetpath = str(target)\n",
    "        sc.WorkingDirectory = str(target.parent)\n",
    "        # Use icon.ico if present; otherwise the target itself\n",
    "        icon_path = APP_DIR / \"icon.ico\"\n",
    "        sc.IconLocation = str(icon_path if icon_path.exists() else target)\n",
    "        sc.save()\n",
    "    else:\n",
    "        print(\"[shortcut] pywin32 not available; skipping Desktop shortcut.\")\n",
    "except Exception as e:\n",
    "    print(f\"[shortcut] skipped due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: auto-open the workbook in Excel (independent of xlwings) ---\n",
    "OPEN_AFTER_SAVE = bool(CFG.get(\"open_after_save\", True))\n",
    "\n",
    "def _os_open(path):\n",
    "    try:\n",
    "        # Windows\n",
    "        os.startfile(path)  # type: ignore[attr-defined]\n",
    "    except AttributeError:\n",
    "        # macOS / Linux fallback\n",
    "        import subprocess, sys\n",
    "        if sys.platform == \"darwin\":\n",
    "            subprocess.run([\"open\", path])\n",
    "        else:\n",
    "            subprocess.run([\"xdg-open\", path])\n",
    "\n",
    "if OPEN_AFTER_SAVE:\n",
    "    _os_open(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- BLOCK 8: PowerPoint Report Generator ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BLOCK 8: PowerPoint Report Generator ---\n",
    "def add_header_footer(slide, title_text: str, footer_text: str = \"\"):\n",
    "    \"\"\"Adds a consistent header and footer banner with text.\"\"\"\n",
    "    # Header banner\n",
    "    header = slide.shapes.add_shape(\n",
    "        1,  # mso_shape.rectangle\n",
    "        Inches(0), Inches(0),\n",
    "        Inches(10), Inches(1)\n",
    "    )\n",
    "    fill = header.fill\n",
    "    fill.solid()\n",
    "    fill.fore_color.rgb = RGBColor(0, 51, 102)  # dark navy\n",
    "    header.line.fill.background()  # no border\n",
    "\n",
    "    # Header text\n",
    "    tf = header.text_frame\n",
    "    tf.text = title_text\n",
    "    p = tf.paragraphs[0]\n",
    "    p.font.bold = True\n",
    "    p.font.size = Pt(32)\n",
    "    p.font.color.rgb = RGBColor(255, 255, 255)\n",
    "    p.alignment = 1  # centre\n",
    "\n",
    "    # Footer banner\n",
    "    footer = slide.shapes.add_shape(\n",
    "        1, Inches(0), Inches(7), Inches(10), Inches(0.4)\n",
    "    )\n",
    "    fill = footer.fill\n",
    "    fill.solid()\n",
    "    fill.fore_color.rgb = RGBColor(230, 230, 230)\n",
    "    footer.line.fill.background()\n",
    "\n",
    "    # Footer text\n",
    "    tf = footer.text_frame\n",
    "    tf.text = footer_text or \"Generated by Portfolio Optimiser\"\n",
    "    p = tf.paragraphs[0]\n",
    "    p.font.size = Pt(12)\n",
    "    p.font.color.rgb = RGBColor(80, 80, 80)\n",
    "    p.alignment = 1  # centre\n",
    "\n",
    "def export_to_ppt(results, trades, charts=None):\n",
    "    \"\"\"\n",
    "    Generates a professional PowerPoint summary based on your custom template.\n",
    "    \"\"\"\n",
    "\n",
    "    APP_DIR = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "\n",
    "    # Template file (design only, never edited)\n",
    "    template_path = os.path.join(APP_DIR, \"PowerPoint_Template.pptx\")\n",
    "\n",
    "    # Output path — always overwrite this file\n",
    "    ppt_path = os.path.join(APP_DIR, \"Portfolio_Report.pptx\")\n",
    "\n",
    "    # Load your custom template\n",
    "    prs = Presentation(template_path)\n",
    "   \n",
    "    # --- SLIDE 1: Title and TimeStamp ---\n",
    "    slide = prs.slides[0] \n",
    "    \n",
    "    # --- Title text box ---  \n",
    "    if slide.shapes.title:\n",
    "        slide.shapes.title.text = \"Portfolio Performance Overview\"\n",
    "    \n",
    "    # --- Timestamp text box ---\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"Last updated on the %d %B %Y at %I:%M %p\")\n",
    "    ts_box = slide.shapes.add_textbox(Inches(0.8), Inches(6.0), Inches(9), Inches(0.5))\n",
    "    tf2 = ts_box.text_frame\n",
    "    tf2.word_wrap = False\n",
    "    p2 = tf2.add_paragraph()\n",
    "    p2.text = timestamp\n",
    "    p2.font.size = Pt(16)\n",
    "    p2.alignment = PP_ALIGN.LEFT  # uses default colour/font\n",
    "\n",
    "    # --- SLIDE 2: Trade Plan + Brokerage ---\n",
    "    slide_layout = prs.slide_layouts[20]  # clean layout from your master\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    \n",
    "    # Title\n",
    "    if slide.shapes.title:\n",
    "        slide.shapes.title.text = \"Trade Plan and Brokerage Overview\"\n",
    "    \n",
    "    # --- Draw Trade Plan table ---\n",
    "    if trades is not None and not trades.empty:\n",
    "        # Map existing columns to your new desired display names\n",
    "        rename_map = {\n",
    "            \"Curr Units\": \"Current\",\n",
    "            \"Target Units\": \"Target\",\n",
    "            \"Δ Units\": \"Change\",\n",
    "            \"Last Px (AUD)\": \"Last Price\",\n",
    "            \"Cash Flow (AUD)\": \"Cash Flow\",\n",
    "            \"Brokerage (AUD)\": \"Brokerage\",\n",
    "        }\n",
    "    \n",
    "        # Select, copy, and rename columns\n",
    "        df = trades[[\"Security\"] + list(rename_map.keys())].copy()\n",
    "        df.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "        # Reorder columns\n",
    "        cols = [\"Security\", \"Current\", \"Target\", \"Change\", \"Last Price\", \"Brokerage\", \"Cash Flow\"]\n",
    "        df = df[cols]\n",
    "    \n",
    "        # --- Clean and format values ---\n",
    "        df[\"Security\"] = df[\"Security\"].astype(str).str.replace(\".AX\", \"\", regex=False)\n",
    "        for col in [\"Last Price\", \"Cash Flow\", \"Brokerage\"]:\n",
    "            df[col] = (\n",
    "                pd.to_numeric(df[col], errors=\"coerce\")\n",
    "                .round(2)\n",
    "                .apply(lambda x: f\"-${abs(x):,.2f}\" if x < 0 else f\"${x:,.2f}\")\n",
    "            )\n",
    "    \n",
    "        # --- Determine if we split into two tables ---\n",
    "        rows, cols = df.shape\n",
    "        split = rows > 15\n",
    "        half = math.ceil(rows / 2) if split else rows\n",
    "        table_sets = [df.iloc[:half]] if not split else [df.iloc[:half], df.iloc[half:]]\n",
    "        left_positions = [Inches(0.5), Inches(5.0)] if split else [Inches(0.5)]\n",
    "    \n",
    "        def autofit_table_width(table, df, total_width_in=4.7):\n",
    "            \"\"\"\n",
    "            True auto-fit for PowerPoint tables with a small minimum width for narrow headers\n",
    "            (prevents wrapping for 'Target' and 'Change').\n",
    "            \"\"\"\n",
    "            from pptx.util import Inches\n",
    "        \n",
    "            def est_width(text):\n",
    "                return len(str(text)) * 0.085  # empirical average for 9pt Calibri text\n",
    "        \n",
    "            est_widths = []\n",
    "            for col in df.columns:\n",
    "                header_w = est_width(col)\n",
    "                data_w = max(est_width(v) for v in df[col].astype(str))\n",
    "                width = max(header_w, data_w)\n",
    "        \n",
    "                # Minimum width safeguard for narrow headers\n",
    "                if col.lower() in (\"target\", \"change\"):\n",
    "                    width = max(width, 0.55)  # ensures ~0.55 inches minimum\n",
    "                elif col.lower() == \"security\":\n",
    "                    width = max(width, 0.7)   # ensures symbol names have room\n",
    "        \n",
    "                est_widths.append(width)\n",
    "        \n",
    "            total_est = sum(est_widths)\n",
    "            scale = total_width_in / total_est\n",
    "        \n",
    "            for j, est in enumerate(est_widths):\n",
    "                table.columns[j].width = Inches(est * scale)\n",
    "\n",
    "        \n",
    "        # --- Draw tables ---\n",
    "        for idx, subdf in enumerate(table_sets):\n",
    "            top = Inches(1.8)\n",
    "            left = Inches(0.25 + idx * 4.75)  # tighter to edge\n",
    "            width = Inches(4.75)\n",
    "            height = Inches(4.8)\n",
    "        \n",
    "            table = slide.shapes.add_table(\n",
    "                rows=subdf.shape[0] + 1,\n",
    "                cols=subdf.shape[1],\n",
    "                left=left,\n",
    "                top=top,\n",
    "                width=width,\n",
    "                height=height\n",
    "            ).table\n",
    "        \n",
    "            # Auto-fit widths based on text lengths\n",
    "            autofit_table_width(table, subdf, total_width_in=4.7)\n",
    "        \n",
    "            # **Disable word wrapping for all cells (keeps headers on one line)**\n",
    "            for cell in table.iter_cells():\n",
    "                cell.text_frame.word_wrap = False\n",
    "        \n",
    "            # Reduce row height\n",
    "            for r in range(len(table.rows)):\n",
    "                table.rows[r].height = Inches(0.23)\n",
    "        \n",
    "            # Header\n",
    "            for j, col_name in enumerate(subdf.columns):\n",
    "                cell = table.cell(0, j)\n",
    "                cell.text = col_name\n",
    "                tf = cell.text_frame\n",
    "                tf.word_wrap = False\n",
    "                tf.margin_left = 0\n",
    "                tf.margin_right = 0\n",
    "                tf.auto_size = MSO_AUTO_SIZE.TEXT_TO_FIT_SHAPE\n",
    "                p = tf.paragraphs[0]\n",
    "                p.font.bold = True\n",
    "                p.font.size = Pt(8)  \n",
    "                p.alignment = PP_ALIGN.CENTER\n",
    "        \n",
    "            # Data rows\n",
    "            for i, (_, row) in enumerate(subdf.iterrows(), start=1):\n",
    "                for j, val in enumerate(row):\n",
    "                    cell = table.cell(i, j)\n",
    "                    cell.text = str(val)\n",
    "                    p = cell.text_frame.paragraphs[0]\n",
    "                    p.font.size = Pt(9)\n",
    "                    if j == 0:  # security column bold\n",
    "                        p.font.bold = True\n",
    "                    p.alignment = PP_ALIGN.CENTER\n",
    "\n",
    "    \n",
    "        # --- Summary bar across top ---\n",
    "        left = Inches(0.5)\n",
    "        top = Inches(1.1)  # just below the title\n",
    "        width = Inches(9.0)\n",
    "        height = Inches(0.5)\n",
    "        textbox = slide.shapes.add_textbox(left, top, width, height)\n",
    "        tf = textbox.text_frame\n",
    "        tf.word_wrap = False\n",
    "        tf.clear()\n",
    "        \n",
    "        # --- Fetch values ---\n",
    "        total_portfolio = results.get(\"total_portfolio_value\", 0)\n",
    "        total_brokerage = results.get(\"total_brokerage\", 0)\n",
    "        net_invested = results.get(\"net_invested\", 0)\n",
    "        portfolio_change = results.get(\"portfolio_change\", 0)\n",
    "        net_invested_change = results.get(\"net_invested_change\", 0)\n",
    "        \n",
    "        # --- Helper to format change text ---\n",
    "        def add_change_run(paragraph, val):\n",
    "            run = paragraph.add_run()\n",
    "            if val == 0:\n",
    "                run.text = \"\"\n",
    "                return\n",
    "            sign = \"+\" if val > 0 else \"\"\n",
    "            run.text = f\" ({sign}{val:,.2f})\"\n",
    "            run.font.size = Pt(14)\n",
    "            if val > 0:\n",
    "                run.font.color.rgb = RGBColor(0, 128, 0)  # green\n",
    "            elif val < 0:\n",
    "                run.font.color.rgb = RGBColor(192, 0, 0)  # red\n",
    "            else:\n",
    "                run.font.color.rgb = RGBColor(80, 80, 80)\n",
    "        \n",
    "        # --- Main summary line ---\n",
    "        p = tf.add_paragraph()\n",
    "        p.font.size = Pt(14)\n",
    "        p.font.bold = True\n",
    "        p.alignment = PP_ALIGN.CENTER\n",
    "        \n",
    "        # Text with separate runs for coloured numbers\n",
    "        run1 = p.add_run()\n",
    "        run1.text = f\"Total Portfolio: ${total_portfolio:,.2f}\"\n",
    "        run1.font.size = Pt(14)\n",
    "        run1.font.bold = True\n",
    "        add_change_run(p, portfolio_change)\n",
    "        \n",
    "        run2 = p.add_run()\n",
    "        run2.text = f\"     Total Brokerage: ${total_brokerage:,.2f}     \"\n",
    "        run2.font.size = Pt(14)\n",
    "        run2.font.bold = True\n",
    "        run2.font.color.rgb = RGBColor(0, 0, 0)\n",
    "        \n",
    "        run3 = p.add_run()\n",
    "        run3.text = f\"Net Invested: ${net_invested:,.2f}\"\n",
    "        run3.font.size = Pt(14)\n",
    "        run3.font.bold = True\n",
    "        add_change_run(p, net_invested_change)\n",
    "\n",
    "        # --- Slide 2: Portfolio vs Indices ---\n",
    "        slide_layout = prs.slide_layouts[20]  # clean layout from your master\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        \n",
    "        # Title\n",
    "        if slide.shapes.title:\n",
    "            slide.shapes.title.text = \"Portfolio Performance\"\n",
    "        \n",
    "        # --- Get 3-month portfolio + benchmarks ---\n",
    "        lookback_days = 90\n",
    "        recent_prices = prices.iloc[-lookback_days:].copy()\n",
    "        \n",
    "        benchmarks = [\"^AORD\", \"^GSPC\", \"^IXIC\"]\n",
    "        benchmark_data = yf.download(\n",
    "            benchmarks,\n",
    "            start=recent_prices.index[0],\n",
    "            end=recent_prices.index[-1],\n",
    "            progress=False,\n",
    "            auto_adjust=True,\n",
    "            threads=False\n",
    "        )\n",
    "        \n",
    "        # Handle multi-index and fill missing values\n",
    "        if isinstance(benchmark_data.columns, pd.MultiIndex):\n",
    "            benchmark_data = benchmark_data[\"Close\"]\n",
    "            benchmark_data = benchmark_data.ffill().bfill()\n",
    "        \n",
    "        # --- Align and clean ---\n",
    "        common_index = recent_prices.index.intersection(benchmark_data.index)\n",
    "        recent_prices = recent_prices.reindex(common_index)\n",
    "        benchmark_data = benchmark_data.reindex(common_index)\n",
    "        \n",
    "        pval = portfolio_value_series.reindex(recent_prices.index).ffill().bfill()\n",
    "        \n",
    "        mask = pval.notna() & benchmark_data.notna().any(axis=1)\n",
    "        pval = pval[mask]\n",
    "        benchmark_data = benchmark_data.loc[mask]\n",
    "        \n",
    "        portfolio_returns = pval / pval.iloc[0] - 1\n",
    "        benchmark_returns = benchmark_data.div(benchmark_data.iloc[0]).subtract(1)\n",
    "        \n",
    "        # Friendly labels\n",
    "        benchmark_returns = benchmark_returns.rename(columns={\n",
    "            \"^AORD\": \"ASX\",\n",
    "            \"^GSPC\": \"S&P 500\",\n",
    "            \"^IXIC\": \"NASDAQ\"\n",
    "        })\n",
    "        \n",
    "        # --- Combine into one DataFrame ---\n",
    "        perf_df = pd.concat(\n",
    "            [portfolio_returns.rename(\"Portfolio\")] +\n",
    "            [benchmark_returns[c].rename(c) for c in benchmark_returns.columns],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Optional: clip extreme outliers (prevents visual spikes)\n",
    "        perf_df = perf_df.clip(lower=-0.2, upper=0.5)\n",
    "        \n",
    "        # --- Plot ---\n",
    "        fig, ax = plt.subplots(figsize=(7, 4.5))\n",
    "        perf_df.mul(100).plot(ax=ax, linewidth=1.8)\n",
    "        ax.set_title(\"Portfolio vs ASX, S&P 500, NASDAQ (3-Month Performance)\")\n",
    "        ax.set_ylabel(\"Return (%)\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "        \n",
    "        chart_path = os.path.join(APP_DIR, \"perf_vs_indices.png\")\n",
    "        fig.savefig(chart_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # --- Insert chart in PowerPoint ---\n",
    "        slide.shapes.add_picture(chart_path, Inches(0.8), Inches(1.3), width=Inches(8.2), height=Inches(4.4))\n",
    "\n",
    "\n",
    "\n",
    "        prs.save(ppt_path)\n",
    "        print(f\"[pptx] Report saved to: {ppt_path}\")\n",
    "        return ppt_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Block 9: Finishers / Launchers ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pptx] Report saved to: C:\\Users\\Fionn Guina\\Portfolio_Optimiser\\Portfolio_Report.pptx\n"
     ]
    }
   ],
   "source": [
    "# 1) Generate the report (optional)\n",
    "ppt_path = None\n",
    "if CFG.get(\"generate_report\", True):\n",
    "    ppt_path = export_to_ppt(results, trades, charts)  # your function returns the .pptx path\n",
    "\n",
    "# 2) Open the PowerPoint if requested (either via dialog or config)\n",
    "open_ppt = bool(user_opts.get(\"open_ppt\", CFG.get(\"open_ppt_after_save\", True)))\n",
    "if open_ppt and ppt_path and os.path.exists(ppt_path):\n",
    "    _os_open(ppt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
