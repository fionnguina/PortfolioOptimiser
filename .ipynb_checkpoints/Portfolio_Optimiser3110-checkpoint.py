{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Data From Yahoo Finance For Stock Build last updated 1/11/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install beautifulsoup4\n",
    "#!pip3 install curl_cffi\n",
    "#!pip3 install frozendict\n",
    "#!pip3 install multitasking\n",
    "#!pip3 install numpy\n",
    "#!pip3 install pandas\n",
    "#!pip3 install peewee\n",
    "#!pip3 install platformdirs\n",
    "#!pip3 install protobuf\n",
    "#!pip3 install pytz\n",
    "#!pip3 install requests\n",
    "#!pip3 install websockets\n",
    "#!pip3 install statsmodels\n",
    "#!pip3 install tkinter\n",
    "#!pip3 install xlwings\n",
    "#!pip3 install webdriver-manager\n",
    "#!pip3 install openpyxl\n",
    "#!pip3 install pyinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#This is only for when we require an upgrade to software package\n",
    "#!pip3 install --upgrade pandas\n",
    "#!pip3 install --upgrade openpyxl\n",
    "#!pip3 install --upgrade yfinance\n",
    "#!pip3 install --upgrade webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 1 imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import yfinance as yf\n",
    "import openpyxl\n",
    "import pathlib\n",
    "import hashlib\n",
    "import shutil\n",
    "import io\n",
    "import sys, os\n",
    "import json\n",
    "import xlwings as xw\n",
    "import statsmodels.api as sm\n",
    "import re, zipfile\n",
    "import tkinter as _tk\n",
    "import multiprocessing as mp\n",
    "from numpy.linalg import pinv\n",
    "from pathlib import Path\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from datetime import datetime\n",
    "from tkinter import ttk as _ttk, messagebox as _mb\n",
    "from scipy.optimize import minimize\n",
    "try:\n",
    "    import win32com.client as win32\n",
    "    HAS_WIN32COM = True\n",
    "except Exception:\n",
    "    HAS_WIN32COM = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### BLOCK 2 Global codes and Data Retrieval from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Central base directory\n",
    "# ---------------------------------------------------------------------\n",
    "def _app_dir() -> Path:\n",
    "    \"\"\"\n",
    "    Determine the application directory dynamically:\n",
    "      - When frozen (PyInstaller): use the exe folder\n",
    "      - When run as a script: use the script's folder\n",
    "      - When interactive (Jupyter/IPython): use cwd\n",
    "    \"\"\"\n",
    "    if getattr(sys, \"frozen\", False):\n",
    "        return Path(sys.executable).parent\n",
    "    if \"__file__\" in globals():\n",
    "        return Path(__file__).resolve().parent\n",
    "    return Path(os.getcwd())\n",
    "\n",
    "\n",
    "# Absolute path to your central config root (for dev use)\n",
    "_DEV_BASE = Path.home() / \"Portfolio_Optimiser\"\n",
    "\n",
    "# Use the dev folder if it exists, otherwise fall back to dynamic app dir\n",
    "APP_DIR = _DEV_BASE if _DEV_BASE.exists() else _app_dir()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config file and Excel workbook paths\n",
    "# ---------------------------------------------------------------------\n",
    "def _default_excel_path() -> str:\n",
    "    \"\"\"Return full path to the default Excel workbook.\"\"\"\n",
    "    return str((APP_DIR / \"Stock Analysis.xlsm\").resolve())\n",
    "\n",
    "CONFIG_PATH = APP_DIR / \"config.json\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Default configuration values\n",
    "# ---------------------------------------------------------------------\n",
    "_DEFAULTS = {\n",
    "    \"excel_path\": _default_excel_path(),\n",
    "    \"marginal_tax_rate\": 0.37,\n",
    "    \"carry_forward_losses\": 0.0,\n",
    "    \"lot_match_method\": \"HIFO\",\n",
    "    \"open_after_save\": True,\n",
    "    \"use_xlwings\": True,\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config loader\n",
    "# ---------------------------------------------------------------------\n",
    "def load_config() -> dict:\n",
    "    cfg = dict(_DEFAULTS)\n",
    "    try:\n",
    "        if CONFIG_PATH.exists():\n",
    "            with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                user_cfg = json.load(f)\n",
    "            for k, v in user_cfg.items():\n",
    "                if k in cfg:\n",
    "                    cfg[k] = v\n",
    "    except Exception as e:\n",
    "        print(f\"[config] using defaults (error reading config.json): {e}\")\n",
    "\n",
    "    # Ensure workbook directory exists\n",
    "    try:\n",
    "        os.makedirs(Path(cfg[\"excel_path\"]).parent, exist_ok=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "CFG = load_config()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Actual Code\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "TILT_FACTORS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "\n",
    "# Bind config into existing globals you already use\n",
    "filename               = CFG[\"excel_path\"]\n",
    "MARGINAL_TAX_RATE      = float(CFG[\"marginal_tax_rate\"])\n",
    "CAPITAL_LOSS_CARRY_FWD = float(CFG[\"carry_forward_losses\"])\n",
    "LOT_MATCH_METHOD       = str(CFG[\"lot_match_method\"]).upper()\n",
    "OPEN_AFTER_SAVE        = bool(CFG.get(\"open_after_save\", True))\n",
    "USE_XLWINGS            = bool(CFG.get(\"use_xlwings\", True))\n",
    "\n",
    "def evaluate_transaction_costs(trade_df, lots_df, sale_date, tax_rate):\n",
    "    # Temporary placeholder to prevent crash\n",
    "    return {\"brokerage\": 0.0, \"cgt_tax\": 0.0, \"total_cost\": 0.0}\n",
    "\n",
    "def _read_lots_from_path(xl_path, sheet_name=\"Lots\"):\n",
    "    try:\n",
    "        return pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception:\n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "# --- Brokerage & CGT config (edit these to suit) ---\n",
    "BROKERAGE = {\n",
    "    \"ASX\": {\"first_buy_free_threshold\": 1000.0, \"min_fee\": 11.0, \"rate\": 0.001},  # 0.10%\n",
    "    \"US\":  {\"min_fee\": 0.0, \"rate\": 0.0},  # CMC U.S. brokerage $0\n",
    "}\n",
    "MARGINAL_TAX_RATE = 0.37           # your personal marginal rate (decimal)\n",
    "CAPITAL_LOSS_CARRY_FWD = 0.0       # prior year carried-forward capital losses (AUD)\n",
    "LOT_MATCH_METHOD = \"HIFO\"          # or \"FIFO\" (parcel-matching when selling)\n",
    "\n",
    "def ensure_workbook(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    with xw.App(visible=False, add_book=True) as app:\n",
    "        wb = app.books.add()\n",
    "        for nm in [\"Holdings\",\"Tilts\",\"OPT\",\"Input\",\"Cov\",\"FF5F\",\"Lots\"]:\n",
    "            try: wb.sheets[nm]\n",
    "            except: wb.sheets.add(nm)\n",
    "        # Minimal headers\n",
    "        wb.sheets[\"Holdings\"].range(\"A1\").value = [[\"Security\",\"Units\",\"Last Price\",\"FX to AUD\",\"Market Value\",\"Weight\",\"Include?\"]]\n",
    "        wb.sheets[\"Tilts\"].range(\"A1\").value = [[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "        wb.sheets[\"Tilts\"].range(\"A2\").value = [[f, (1.0 if i==0 else 0.0), 0.20, (i==0)] for i,f in enumerate(TILT_FACTORS)]\n",
    "        wb.sheets[\"Lots\"].range(\"A1\").value = [[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"]]\n",
    "        wb.save(path); wb.close()\n",
    "\n",
    "# Call it right before Block 7 seed reads:\n",
    "ensure_workbook(filename)\n",
    "\n",
    "# -------- Risk-free (AU): current RBA cash rate target --------\n",
    "def get_rba_cash_rate_target_current(default=0.04):\n",
    "    \"\"\"\n",
    "    Returns the latest RBA cash rate target as a decimal, scraped from:\n",
    "    https://www.rba.gov.au/statistics/cash-rate/\n",
    "    Falls back to the monthly-average CSV if needed, else `default`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dfs = pd.read_html(\"https://www.rba.gov.au/statistics/cash-rate/\", match=\"Cash rate target %\")\n",
    "        if dfs:\n",
    "            tab = dfs[0]\n",
    "            val = pd.to_numeric(tab.iloc[0][\"Cash rate target %\"], errors=\"coerce\")\n",
    "            if pd.notna(val):\n",
    "                return float(val) / 100.0\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        csv = \"https://www.rba.gov.au/statistics/tables/csv/f1.1-data.csv\"\n",
    "        df = pd.read_csv(csv)\n",
    "        col = next(c for c in df.columns if c.lower().startswith(\"cash rate target\"))\n",
    "        last = pd.to_numeric(df[col], errors=\"coerce\").dropna().iloc[-1]\n",
    "        return float(last) / 100.0\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "# -------- Simple on-disk cache (7-day TTL) for FF5 + MOM --------\n",
    "_CACHE_DIR = pathlib.Path(os.path.expanduser(\"~\")) / \".portfolio_optimiser_cache\"\n",
    "_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _cache_path(url: str) -> pathlib.Path:\n",
    "    key = hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "    return _CACHE_DIR / f\"{key}.csv\"\n",
    "\n",
    "def _cached_read(url: str, build_df_fn, ttl_days: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If we have a cached CSV newer than ttl_days, load it.\n",
    "    Otherwise call build_df_fn() to construct the DataFrame, then store it.\n",
    "    Assumes the DF has a DatetimeIndex.\n",
    "    \"\"\"\n",
    "    p = _cache_path(url)\n",
    "    try:\n",
    "        if p.exists():\n",
    "            age_sec = time.time() - p.stat().st_mtime\n",
    "            if age_sec <= ttl_days * 86400:\n",
    "                df = pd.read_csv(p, index_col=0, parse_dates=[0])\n",
    "                # ensure sorted Date index\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                return df.sort_index()\n",
    "    except Exception as e:\n",
    "        print(f\"[cache] read miss due to: {e}\")\n",
    "\n",
    "    df = build_df_fn()\n",
    "    try:\n",
    "        df.to_csv(p)\n",
    "    except Exception as e:\n",
    "        print(f\"[cache] write skipped due to: {e}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------- FF5F + Momentum loaders (Dartmouth) --------\n",
    "FF5_DAILY_ZIP = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip\"\n",
    "MOM_DAILY_ZIP = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_daily_CSV.zip\"\n",
    "\n",
    "def get_mom_daily():\n",
    "    def _builder():\n",
    "        r = requests.get(MOM_DAILY_ZIP, timeout=60); r.raise_for_status()\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        csv = next(n for n in z.namelist() if n.lower().endswith(\".csv\"))\n",
    "        raw = z.read(csv).decode(\"latin1\", errors=\"ignore\").splitlines()\n",
    "        num_rx = re.compile(r\"^\\s*\\d{6,8}\\s*[,\\s]\")\n",
    "        first = next(i for i, ln in enumerate(raw) if num_rx.match(ln))\n",
    "        header = \"Date,MOM\"\n",
    "        data = [header] + [ln.strip() for ln in raw[first:] if num_rx.match(ln)]\n",
    "        df = pd.read_csv(io.StringIO(\"\\n\".join(data)), engine=\"python\", sep=r\"\\s*,\\s*\")\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "        df[\"MOM\"] = pd.to_numeric(df[\"MOM\"], errors=\"coerce\") / 100.0  # decimal\n",
    "        return df[[\"MOM\"]]\n",
    "    df = _cached_read(MOM_DAILY_ZIP, _builder, ttl_days=7)\n",
    "    # ensure schema exactly as expected\n",
    "    df = df.copy()\n",
    "    if \"MOM\" not in df.columns:\n",
    "        df[\"MOM\"] = pd.to_numeric(df.iloc[:, 0], errors=\"coerce\")\n",
    "        df = df[[\"MOM\"]]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def get_ff5_daily(cache_csv_path=None):\n",
    "    \"\"\"\n",
    "    Fama–French 5 Factors (2x3) [Daily].\n",
    "    Returns columns (decimals): ['Mkt-RF','SMB','HML','RMW','CMA','RF'] indexed by Date.\n",
    "    Uses 7-day cached CSV in %USERPROFILE%\\\\.portfolio_optimiser_cache\n",
    "    \"\"\"\n",
    "    def _builder():\n",
    "        resp = requests.get(FF5_DAILY_ZIP, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "        csv_name = next(n for n in zf.namelist() if n.lower().endswith(\".csv\"))\n",
    "\n",
    "        raw = zf.read(csv_name).decode(\"latin1\", errors=\"ignore\")\n",
    "        lines = raw.splitlines()\n",
    "\n",
    "        num_rx = re.compile(r\"^\\s*\\d{6,8}\\s*[,\\s]\")\n",
    "        first_data_idx = next(i for i, ln in enumerate(lines) if num_rx.match(ln))\n",
    "\n",
    "        header_idx = None\n",
    "        for i in range(max(0, first_data_idx-5), first_data_idx+1):\n",
    "            if re.search(r\"\\bdate\\b\", lines[i], flags=re.I) and (\"mkt\" in lines[i].lower()):\n",
    "                header_idx = i\n",
    "                break\n",
    "\n",
    "        header = lines[header_idx].strip() if header_idx is not None else \"Date,Mkt-RF,SMB,HML,RMW,CMA,RF\"\n",
    "        data_lines = [header]\n",
    "        for ln in lines[first_data_idx:]:\n",
    "            if not num_rx.match(ln):\n",
    "                break\n",
    "            data_lines.append(ln.strip())\n",
    "\n",
    "        df = pd.read_csv(io.StringIO(\"\\n\".join(data_lines)), engine=\"python\", sep=r\"\\s*,\\s*\")\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        col_map = {c.lower().replace(\" \", \"\"): c for c in df.columns}\n",
    "        ren = {}\n",
    "        for want in [\"Date\",\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"RF\"]:\n",
    "            key = want.lower().replace(\" \", \"\")\n",
    "            if key in col_map:\n",
    "                ren[col_map[key]] = want\n",
    "        df = df.rename(columns=ren)\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "        factor_cols = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"RF\"]\n",
    "        df[factor_cols] = df[factor_cols].apply(pd.to_numeric, errors=\"coerce\") / 100.0\n",
    "        df = df.dropna(subset=factor_cols)\n",
    "        return df\n",
    "\n",
    "    df = _cached_read(FF5_DAILY_ZIP, _builder, ttl_days=7)\n",
    "\n",
    "    # Optional external cache file output for your own debugging\n",
    "    if cache_csv_path:\n",
    "        try:\n",
    "            df.to_csv(cache_csv_path, index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[ff5] could not write cache_csv_path: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ff5_mom_daily():\n",
    "    \"\"\"\n",
    "    Return daily factors as decimals with columns:\n",
    "    ['Mkt-RF','SMB','HML','RMW','CMA','MOM','RF'] on a common date index.\n",
    "    \"\"\"\n",
    "    ff5_only = get_ff5_daily()   # <-- was wrongly calling get_ff5_mom_daily()\n",
    "    mom = get_mom_daily()\n",
    "\n",
    "    out = ff5_only.join(mom, how=\"inner\").sort_index()\n",
    "    # reorder defensively (only keep columns that exist)\n",
    "    cols = [c for c in [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\",\"RF\"] if c in out.columns]\n",
    "    return out[cols]\n",
    "\n",
    "\n",
    "# -------- Foreign Exchange from Yahoo Finance --------\n",
    "def _last_numeric(x):\n",
    "    v = x.iloc[-1]\n",
    "    if isinstance(v, pd.Series):\n",
    "        v = v.iloc[0]\n",
    "    return float(v)\n",
    "\n",
    "def get_usd_aud_fx(default=1.50):\n",
    "    try:\n",
    "        px = yf.download(\"AUDUSD=X\", period=\"5d\", interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)[\"Close\"].dropna()\n",
    "        last = _last_numeric(px)\n",
    "        if last > 0:\n",
    "            return 1.0 / last                  # AUD per 1 USD\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        px = yf.download(\"USDAUD=X\", period=\"5d\", interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)[\"Close\"].dropna()\n",
    "        last = _last_numeric(px)\n",
    "        if last > 0:\n",
    "            return last                        # AUD per 1 USD\n",
    "    except Exception:\n",
    "        pass\n",
    "    return float(default)\n",
    "\n",
    "def fx_to_aud_for_tickers(tickers, usd_aud_rate):\n",
    "    \"\"\"1.0 for AUS tickers (*.AX) & indices (^...), usd_aud_rate for others (assume USD).\"\"\"\n",
    "    out = {}\n",
    "    for t in map(str, tickers):\n",
    "        out[t] = 1.0 if (t.startswith(\"^\") or t.endswith(\".AX\")) else float(usd_aud_rate)\n",
    "    return pd.Series(out, name=\"FX to AUD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 3 Downloading Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) DOWNLOAD PRICES  — universe comes from Holdings sheet + static starters\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# If Block 7 defines `filename`, we’ll reuse it. Otherwise set your path here.\n",
    "_XL_PATH = globals().get(\"filename\", _default_excel_path())\n",
    "\n",
    "# Your static “starter” universe (kept as a safety net / defaults)\n",
    "STATIC_STARTERS = ['^AORD']\n",
    "\n",
    "EXCLUDE_FROM_OPT = {'^AORD'}\n",
    "rf_annual = get_rba_cash_rate_target_current()\n",
    "\n",
    "def _tickers_from_holdings(xl_path, sheet='Holdings'):\n",
    "    \"\"\"Extract 'Security' values using pandas (no COM).\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet)\n",
    "    except Exception:\n",
    "        return []\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty or \"Security\" not in df.columns:\n",
    "        return []\n",
    "    sec = (df[\"Security\"].dropna().astype(str).str.strip())\n",
    "    return list(dict.fromkeys([t for t in sec if t]))\n",
    "\n",
    "# 0) Build the universe\n",
    "tickers_from_sheet = _tickers_from_holdings(_XL_PATH, sheet='Holdings')  # dynamic\n",
    "tickers = list(dict.fromkeys((tickers_from_sheet or []) + STATIC_STARTERS))\n",
    "if '^AORD' not in tickers:\n",
    "    tickers.insert(0, '^AORD')  # always include benchmark\n",
    "\n",
    "# 1) Download prices (robust to single/ multiple tickers)\n",
    "PRICE_PERIOD = '2y'  # set '1y'/'3y' as you like\n",
    "dl = yf.download(tickers, period=PRICE_PERIOD, auto_adjust=True, threads=False, progress=False)\n",
    "\n",
    "if isinstance(dl, pd.DataFrame) and 'Close' in dl.columns:\n",
    "    prices = dl['Close']\n",
    "else:\n",
    "    # yfinance can return a Series for a single ticker\n",
    "    prices = dl if isinstance(dl, pd.Series) else pd.DataFrame()\n",
    "    if isinstance(prices, pd.Series):\n",
    "        prices = prices.to_frame(name=tickers[0])\n",
    "prices.index = pd.to_datetime(prices.index)\n",
    "prices = prices.sort_index()\n",
    "prices = prices.loc[:, ~prices.columns.duplicated()]  # de-dup any duplicate tickers defensively\n",
    "\n",
    "# ------------- FX conversion for US stocks (to AUD for returns) ------------------\n",
    "\n",
    "# 1) AUD per 1 USD (ensure we end up with a Series)\n",
    "fx_raw = yf.download(\"USDAUD=X\", period=\"5y\", interval=\"1d\",\n",
    "                     auto_adjust=True, threads=False, progress=False)\n",
    "fx = fx_raw[\"Close\"] if isinstance(fx_raw, pd.DataFrame) else fx_raw\n",
    "if isinstance(fx, pd.DataFrame):\n",
    "    fx = fx.iloc[:, 0]\n",
    "fx = pd.to_numeric(fx, errors=\"coerce\").reindex(prices.index).ffill()\n",
    "\n",
    "# identify USD-priced tickers\n",
    "usd_cols = [str(c) for c in prices.columns if not str(c).endswith(\".AX\") and not str(c).startswith(\"^\")]\n",
    "\n",
    "# build an AUD-converted copy safely\n",
    "prices_aud_for_returns = prices.copy()\n",
    "usd_part = prices.loc[:, usd_cols].mul(fx, axis=0)  # align by date\n",
    "prices_aud_for_returns.update(usd_part)\n",
    "\n",
    "# 4) Compute returns *from AUD-converted prices*\n",
    "df = prices_aud_for_returns.reset_index()\n",
    "df_melt = (\n",
    "    prices_aud_for_returns.reset_index()\n",
    "      .melt(id_vars='Date', var_name='Security', value_name='Close')\n",
    "      .sort_values(['Security','Date'])\n",
    ")\n",
    "df_melt['Return'] = df_melt.groupby('Security', sort=False)['Close'].pct_change(fill_method=None)\n",
    "df_melt = df_melt.dropna()\n",
    "\n",
    "# 5) FX map for holdings (last-price conversion in the sheet)\n",
    "usd_aud = get_usd_aud_fx()\n",
    "fx_map_all = fx_to_aud_for_tickers(prices.columns, usd_aud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 4 Creating the Stock Holdings Dialog Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2) GUI portfolio editor (Tkinter) + helpers — CLEAN VERSION\n",
    "# -------------------------------\n",
    "\n",
    "def _fetch_prices_for_new_tickers(tickers_new, base_prices, period='5y'):\n",
    "    add = [t for t in map(str, tickers_new) if t not in base_prices.columns]\n",
    "    if not add:\n",
    "        return base_prices\n",
    "    try:\n",
    "        dl = yf.download(add, period=period, auto_adjust=True, threads=False, progress=False)\n",
    "        if isinstance(dl, pd.DataFrame) and 'Close' in dl.columns:\n",
    "            dl = dl['Close']          # wide DataFrame if multiple tickers\n",
    "        if isinstance(dl, pd.Series):  # single ticker case → rename to that ticker\n",
    "            name = add[0]\n",
    "            dl = dl.rename(name).to_frame()\n",
    "        dl.index = pd.to_datetime(dl.index)\n",
    "        out = base_prices.join(dl, how='outer').sort_index()\n",
    "        out = out.loc[:, ~out.columns.duplicated()]\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not fetch some tickers {add}: {e}\")\n",
    "        return base_prices\n",
    "\n",
    "# -------- File-based seed readers (no COM, reliable) --------\n",
    "def _read_holdings_seed_from_path(xl_path, sheet_name=\"Holdings\"):\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed-path] holdings: {e} -> EMPTY\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty or \"Security\" not in df.columns:\n",
    "        print(\"[seed-path] holdings: empty/malformed -> EMPTY\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "\n",
    "    units = pd.to_numeric(df.get(\"Units\", 0.0), errors=\"coerce\").fillna(0.0)\n",
    "    if \"Include?\" in df.columns:\n",
    "        inc = df[\"Include?\"].astype(str).str.strip().str.upper().isin({\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"})\n",
    "    else:\n",
    "        inc = pd.Series(True, index=df.index)\n",
    "\n",
    "    units = pd.Series(units.values, index=df[\"Security\"])\n",
    "    include = dict(zip(df[\"Security\"], inc.astype(bool)))\n",
    "    print(f\"[seed-path] holdings: rows={len(units)}, nonzero={int((units!=0).sum())}\")\n",
    "    return units, include\n",
    "\n",
    "\n",
    "def _read_tilts_seed_from_path(xl_path, sheet_name=\"Tilts\"):\n",
    "    # respect global factor list if you defined MOM in Block 2:\n",
    "    # e.g. TILT_FACTORS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "    factors = list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
    "    default = pd.DataFrame(\n",
    "        {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "         \"Band\":   [0.05]*len(factors),\n",
    "         \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "        index=factors\n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed-path] tilts: {e} -> DEFAULTS\"); return default\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        print(\"[seed-path] tilts: empty -> DEFAULTS\"); return default\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    need = {\"Factor\",\"Target\",\"Band\",\"Use?\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        print(\"[seed-path] tilts: malformed -> DEFAULTS\"); return default\n",
    "\n",
    "    df[\"Factor\"] = df[\"Factor\"].astype(str).str.strip()\n",
    "    df = df.set_index(\"Factor\").reindex(factors)\n",
    "    out = default.copy()\n",
    "    out.loc[df.index, \"Target\"] = pd.to_numeric(df[\"Target\"], errors=\"coerce\")\n",
    "    out.loc[df.index, \"Band\"]   = pd.to_numeric(df[\"Band\"],   errors=\"coerce\")\n",
    "    out.loc[df.index, \"Use?\"]   = df[\"Use?\"].astype(str).str.upper().isin([\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"])\n",
    "    out[\"Target\"] = out[\"Target\"].fillna(default[\"Target\"]).astype(float)\n",
    "    out[\"Band\"]   = out[\"Band\"].fillna(default[\"Band\"]).astype(float)\n",
    "    return out.reindex(factors)\n",
    "\n",
    "# -------------------------------\n",
    "# SAFE seeds I/O used by Block 7 (readers only)\n",
    "# -------------------------------\n",
    "def _read_holdings_seed_from_sheet(wb, sheet_name=\"Holdings\"):\n",
    "    if wb is None:\n",
    "        print(\"[seed] holdings: wb is None -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        print(f\"[seed] holdings: sheet '{sheet_name}' not found -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "    try:\n",
    "        ur = sht.used_range\n",
    "        if ur is None:\n",
    "            print(\"[seed] holdings: used_range is None -> EMPTY seeds\")\n",
    "            return pd.Series(dtype=float), {}\n",
    "        vals = ur.options(ndim=2).value\n",
    "        if not vals or not vals[0] or all(h is None for h in vals[0]):\n",
    "            print(\"[seed] holdings: used_range has no headers -> EMPTY seeds\")\n",
    "            return pd.Series(dtype=float), {}\n",
    "        headers = [str(c).strip() if c is not None else \"\" for c in vals[0]]\n",
    "        rows = vals[1:] if len(vals) > 1 else []\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed] holdings: failed to read table: {e}\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    if df.empty or \"Security\" not in df.columns:\n",
    "        print(\"[seed] holdings: empty/malformed -> EMPTY seeds\")\n",
    "        return pd.Series(dtype=float), {}\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "    units = pd.to_numeric(df.get(\"Units\", 0.0), errors=\"coerce\").fillna(0.0)\n",
    "    if \"Include?\" in df.columns:\n",
    "        inc = df[\"Include?\"].astype(str).str.strip().str.upper().isin({\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"})\n",
    "    else:\n",
    "        inc = pd.Series(True, index=df.index)\n",
    "    units = pd.Series(units.values, index=df[\"Security\"])\n",
    "    include = dict(zip(df[\"Security\"], inc.astype(bool)))\n",
    "    print(f\"[seed] holdings: loaded {int((units!=0).sum())} non-zero unit rows (of {len(units)})\")\n",
    "    return units, include\n",
    "\n",
    "\n",
    "def _read_tilts_seed_from_sheet(wb, sheet_name=\"Tilts\"):\n",
    "    factors = list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
    "    default = pd.DataFrame(\n",
    "        {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "         \"Band\":   [0.05]*len(factors),\n",
    "         \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "        index=factors\n",
    "    )\n",
    "\n",
    "    if wb is None:\n",
    "        print(\"[seed] tilts: wb is None -> DEFAULTS\"); return default\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        print(f\"[seed] tilts: sheet '{sheet_name}' not found -> DEFAULTS\"); return default\n",
    "\n",
    "    try:\n",
    "        ur = sht.used_range\n",
    "        if ur is None:\n",
    "            print(\"[seed] tilts: used_range is None -> DEFAULTS\"); return default\n",
    "        vals = ur.options(ndim=2).value\n",
    "        if not vals or not vals[0] or all(h is None for h in vals[0]):\n",
    "            print(\"[seed] tilts: no data -> DEFAULTS\"); return default\n",
    "        headers = [str(c).strip() if c is not None else \"\" for c in vals[0]]\n",
    "        rows = vals[1:] if len(vals) > 1 else []\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "    except Exception as e:\n",
    "        print(f\"[seed] tilts: failed to read table: {e} -> DEFAULTS\"); return default\n",
    "\n",
    "    need = {\"Factor\",\"Target\",\"Band\",\"Use?\"}\n",
    "    if df.empty or not need.issubset(df.columns):\n",
    "        print(\"[seed] tilts: malformed -> DEFAULTS\"); return default\n",
    "\n",
    "    df[\"Factor\"] = df[\"Factor\"].astype(str).str.strip()\n",
    "    df = df.set_index(\"Factor\").reindex(factors)\n",
    "\n",
    "    out = default.copy()\n",
    "    out.loc[df.index, \"Target\"] = pd.to_numeric(df[\"Target\"], errors=\"coerce\")\n",
    "    out.loc[df.index, \"Band\"]   = pd.to_numeric(df[\"Band\"],   errors=\"coerce\")\n",
    "    out.loc[df.index, \"Use?\"]   = df[\"Use?\"].astype(str).str.upper().isin([\"TRUE\",\"1\",\"Y\",\"YES\",\"T\"])\n",
    "    out[\"Target\"] = out[\"Target\"].fillna(default[\"Target\"]).astype(float)\n",
    "    out[\"Band\"]   = out[\"Band\"].fillna(default[\"Band\"]).astype(float)\n",
    "    return out.reindex(factors)\n",
    "\n",
    "# -------------------------------\n",
    "# Writers (used by Block 7)\n",
    "# -------------------------------\n",
    "def _write_tilts_sheet(wb, tilts_df, sheet_name=\"Tilts\"):\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        sht = wb.sheets.add(sheet_name, after=wb.sheets[-1])\n",
    "    try:\n",
    "        sht.used_range.clear_contents()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    out = tilts_df.reset_index().rename(columns={\"index\": \"Factor\"})\n",
    "    out = out[[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "    sht.range(\"A1\").value = [[\"Factor\",\"Target\",\"Band\",\"Use?\"]]\n",
    "    sht.range(\"A2\").options(index=False, header=False).value = out\n",
    "    last_row = 1 + len(out)\n",
    "    try:\n",
    "        sht.range(f\"B2:B{last_row}\").api.NumberFormat = \"0.000\"\n",
    "        sht.range(f\"C2:C{last_row}\").api.NumberFormat = \"0.000\"\n",
    "        val_rng = sht.range(f\"D2:D{last_row}\").api\n",
    "        val_rng.Validation.Delete()\n",
    "        val_rng.Validation.Add(3, 1, 1, \"TRUE,FALSE\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    sht.autofit()\n",
    "\n",
    "\n",
    "def _write_holdings_sheet(wb, prices, units, include_flags,\n",
    "                          sheet_name=\"Holdings\", fx_to_aud_map=None):\n",
    "    if fx_to_aud_map is None:\n",
    "        usd_aud = get_usd_aud_fx()\n",
    "        fx_to_aud_map = fx_to_aud_for_tickers(prices.columns, usd_aud)\n",
    "\n",
    "    tickers_all = list(dict.fromkeys(list(prices.columns)))\n",
    "    last_px = prices.ffill().iloc[-1]\n",
    "\n",
    "    rows = []\n",
    "    units_s = pd.Series(units)\n",
    "    include_s = pd.Series(include_flags)\n",
    "    for t in tickers_all:\n",
    "        inc = bool(include_s.get(t, True))\n",
    "        rows.append({\n",
    "            \"Security\": t,\n",
    "            \"Units\": float(units_s.get(t, 0.0)),\n",
    "            \"Last Price\": float(pd.Series(last_px).get(t, np.nan)),\n",
    "            \"FX to AUD\": float(pd.Series(fx_to_aud_map).get(t, 1.0)),\n",
    "            \"Market Value\": 0.0,\n",
    "            \"Weight\": 0.0,\n",
    "            \"Include?\": inc\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    try:\n",
    "        sht = wb.sheets[sheet_name]\n",
    "    except Exception:\n",
    "        sht = wb.sheets.add(sheet_name, after=wb.sheets[-1])\n",
    "    try:\n",
    "        sht.used_range.clear_contents()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    sht.range('A1').value = [[\"Security\",\"Units\",\"Last Price\",\"FX to AUD\",\"Market Value\",\"Weight\",\"Include?\"]]\n",
    "    sht.range('A2').options(index=False, header=False).value = df\n",
    "    n = len(df); last_row = 1 + n\n",
    "\n",
    "    if n >= 1:\n",
    "        sht.range('E2').formula = \"=B2*C2*D2\"\n",
    "        if n > 1:\n",
    "            sht.range(f\"E2:E{last_row}\").api.FillDown()\n",
    "        sumif_den = f\"SUMIF($G$2:$G${last_row},TRUE,$E$2:$E${last_row})\"\n",
    "        sht.range('F2').formula = f\"=IF({sumif_den}=0,0,IF($G2,E2/{sumif_den},0))\"\n",
    "        if n > 1:\n",
    "            sht.range(f\"F2:F{last_row}\").api.FillDown()\n",
    "        try:\n",
    "            val_rng = sht.range(f\"G2:G{last_row}\").api\n",
    "            val_rng.Validation.Delete()\n",
    "            val_rng.Validation.Add(3, 1, 1, \"TRUE,FALSE\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            sht.range(f\"C2:C{last_row}\").api.NumberFormat = \"0.0000\"\n",
    "            sht.range(f\"D2:D{last_row}\").api.NumberFormat = \"0.0000\"\n",
    "            sht.range(f\"E2:E{last_row}\").api.NumberFormat = \"0.00\"\n",
    "            sht.range(f\"F2:F{last_row}\").api.NumberFormat = \"0.00%\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    sht.autofit()\n",
    "\n",
    "# -------------------------------\n",
    "# Dialog shims (no windows here)\n",
    "# -------------------------------\n",
    "def edit_holdings_dialog(prices, exclude, seed_units, seed_include, title=\"Edit Portfolio Holdings\"):\n",
    "    units_ser = seed_units.copy()\n",
    "    include_flags = dict(seed_include)\n",
    "    last_price_ser = prices.ffill().iloc[-1].reindex(units_ser.index)\n",
    "    return units_ser, last_price_ser, prices, include_flags\n",
    "\n",
    "def edit_tilts_dialog(seed_df):\n",
    "    return seed_df.copy()\n",
    "\n",
    "# -------------------------------\n",
    "# Combined dialog (one window)\n",
    "# -------------------------------\n",
    "def edit_holdings_and_tilts_dialog(prices, exclude, seed_units, seed_include, seed_tilts,\n",
    "                                   title=\"Edit Holdings & Factor Tilts\"):\n",
    "    \"\"\"\n",
    "    Returns: (units_series, last_price_series, prices_df, include_flags_dict, tilts_df)\n",
    "    \"\"\"\n",
    "    tickers_all = [t for t in prices.columns]\n",
    "    exclude = set(exclude or [])\n",
    "    last_px = prices.ffill().iloc[-1]\n",
    "\n",
    "    # factor list (use global TILT_FACTORS if set, so MOM shows up)\n",
    "    factors = list(seed_tilts.index) if isinstance(seed_tilts, pd.DataFrame) and not seed_tilts.empty \\\n",
    "              else (list(TILT_FACTORS) if 'TILT_FACTORS' in globals() else [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"])\n",
    "    if not isinstance(seed_tilts, pd.DataFrame) or seed_tilts.empty:\n",
    "        seed_tilts = pd.DataFrame(\n",
    "            {\"Target\": [1.0] + [0.0]*(len(factors)-1),\n",
    "             \"Band\":   [0.05]*len(factors),\n",
    "             \"Use?\":   [True] + [False]*(len(factors)-1)},\n",
    "            index=factors\n",
    "        )\n",
    "\n",
    "    root = _tk.Tk()\n",
    "    root.title(title)\n",
    "    root.geometry(\"980x640\")\n",
    "    root.minsize(920, 560)\n",
    "\n",
    "    # === Main layout ===\n",
    "    frm_main = _ttk.Frame(root, padding=10); frm_main.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # Left: holdings\n",
    "    frm_left = _ttk.LabelFrame(frm_main, text=\"Holdings\", padding=10)\n",
    "    frm_left.pack(side=\"left\", fill=\"both\", expand=True, padx=(0, 6))\n",
    "    for i in range(3):\n",
    "        frm_left.rowconfigure(i, weight=(1 if i == 1 else 0))\n",
    "    frm_left.columnconfigure(0, weight=1)\n",
    "\n",
    "    # Header\n",
    "    header = _ttk.Frame(frm_left); header.grid(row=0, column=0, sticky=\"ew\")\n",
    "    _ttk.Label(header, text=\"Inc?\", width=5).grid(row=0, column=0, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Del?\", width=5).grid(row=0, column=1, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Security\", width=20).grid(row=0, column=2, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Units\", width=14).grid(row=0, column=3, sticky=\"w\")\n",
    "    _ttk.Label(header, text=\"Last Price\", width=12).grid(row=0, column=4, sticky=\"w\")\n",
    "\n",
    "    # Scrollable list\n",
    "    list_container = _ttk.Frame(frm_left); list_container.grid(row=1, column=0, sticky=\"nsew\", pady=(4, 6))\n",
    "    list_container.rowconfigure(0, weight=1); list_container.columnconfigure(0, weight=1)\n",
    "    canvas = _tk.Canvas(list_container, highlightthickness=0)\n",
    "    scroll_y = _ttk.Scrollbar(list_container, orient=\"vertical\", command=canvas.yview)\n",
    "    body = _ttk.Frame(canvas)\n",
    "    body.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "    canvas.create_window((0, 0), window=body, anchor=\"nw\")\n",
    "    canvas.configure(yscrollcommand=scroll_y.set)\n",
    "    canvas.grid(row=0, column=0, sticky=\"nsew\"); scroll_y.grid(row=0, column=1, sticky=\"ns\")\n",
    "\n",
    "    def _on_mousewheel(event):\n",
    "        if event.delta:\n",
    "            canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
    "        elif getattr(event, \"num\", None) in (4, 5):\n",
    "            canvas.yview_scroll(-1 if event.num == 4 else 1, \"units\")\n",
    "    body.bind(\"<Enter>\", lambda e: canvas.bind_all(\"<MouseWheel>\", _on_mousewheel))\n",
    "    body.bind(\"<Leave>\", lambda e: canvas.unbind_all(\"<MouseWheel>\"))\n",
    "    canvas.bind_all(\"<Button-4>\", _on_mousewheel); canvas.bind_all(\"<Button-5>\", _on_mousewheel)\n",
    "\n",
    "    row_vars = {}\n",
    "    def _add_row(ticker, units_default=0.0, include_default=True, disabled=False):\n",
    "        r = len(row_vars) + 1\n",
    "        v_inc = _tk.BooleanVar(value=(False if disabled else bool(include_default)))\n",
    "        v_del = _tk.BooleanVar(value=False)\n",
    "        v_units = _tk.StringVar(value=(\"0\" if disabled else str(float(units_default))))\n",
    "        chk_inc = _ttk.Checkbutton(body, variable=v_inc)\n",
    "        chk_del = _ttk.Checkbutton(body, variable=v_del)\n",
    "        ent = _ttk.Entry(body, textvariable=v_units, width=16)\n",
    "        lbl_t = _ttk.Label(body, text=str(ticker), width=20)\n",
    "        last_px_str = f\"{float(last_px.get(ticker, float('nan'))):.4f}\"\n",
    "        lbl_px = _ttk.Label(body, text=last_px_str, width=12)\n",
    "        if disabled:\n",
    "            chk_inc.state([\"disabled\"]); ent.state([\"disabled\"]); lbl_t.configure(foreground=\"#888\")\n",
    "        chk_inc.grid(row=r, column=0, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        chk_del.grid(row=r, column=1, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        lbl_t.grid(row=r, column=2, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        ent.grid(row=r, column=3, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        lbl_px.grid(row=r, column=4, sticky=\"w\", padx=(0, 6), pady=2)\n",
    "        row_vars[ticker] = {\"inc\": v_inc, \"del\": v_del, \"units\": v_units, \"disabled\": disabled, \"lbl_px\": lbl_px}\n",
    "\n",
    "    # Prefill rows\n",
    "    for t in tickers_all:\n",
    "        disabled = (t in exclude)\n",
    "        inc_default = bool(pd.Series(seed_include).get(t, True)) and not disabled\n",
    "        units_default = float(pd.Series(seed_units).get(t, 0.0))\n",
    "        _add_row(t, units_default=units_default, include_default=inc_default, disabled=disabled)\n",
    "\n",
    "    # Add-holding box\n",
    "    add_box = _ttk.LabelFrame(frm_left, text=\"Add holding\", padding=10)\n",
    "    add_box.grid(row=2, column=0, sticky=\"ew\")\n",
    "    _ttk.Label(add_box, text=\"Ticker\").grid(row=0, column=0, sticky=\"w\")\n",
    "    ent_new_ticker = _ttk.Entry(add_box, width=18); ent_new_ticker.grid(row=0, column=1, sticky=\"w\", padx=(4, 12))\n",
    "    _ttk.Label(add_box, text=\"Units\").grid(row=0, column=2, sticky=\"w\")\n",
    "    ent_new_units = _ttk.Entry(add_box, width=14); ent_new_units.grid(row=0, column=3, sticky=\"w\", padx=(4, 12))\n",
    "    _btn_add = _ttk.Button(add_box, text=\"Add\"); _btn_add.grid(row=0, column=4, sticky=\"w\")\n",
    "    added_tickers = []\n",
    "    def _do_add():\n",
    "        t = ent_new_ticker.get().strip()\n",
    "        if not t:\n",
    "            _mb.showwarning(\"Add holding\", \"Please enter a ticker.\"); return\n",
    "        t = t.upper()\n",
    "        if t in row_vars:\n",
    "            _mb.showinfo(\"Add holding\", f\"{t} already listed.\"); return\n",
    "        try:\n",
    "            u = float(ent_new_units.get().strip()) if ent_new_units.get().strip() else 0.0\n",
    "        except ValueError:\n",
    "            _mb.showwarning(\"Add holding\", \"Units must be numeric.\"); return\n",
    "        _add_row(t, units_default=u, include_default=True, disabled=(t in exclude))\n",
    "        added_tickers.append(t)\n",
    "        ent_new_ticker.delete(0, _tk.END); ent_new_units.delete(0, _tk.END)\n",
    "    _btn_add.configure(command=_do_add)\n",
    "\n",
    "    # Right panel — Factor Tilts\n",
    "    frm_right = _ttk.LabelFrame(frm_main, text=\"Factor Tilts\", padding=10)\n",
    "    frm_right.pack(side=\"right\", fill=\"y\", padx=(6, 0))\n",
    "    _ttk.Label(frm_right, text=\"Use?\",    width=5 ).grid(row=0, column=0, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Factor\",  width=12).grid(row=0, column=1, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Target β\",width=10).grid(row=0, column=2, sticky=\"w\")\n",
    "    _ttk.Label(frm_right, text=\"Band\",    width=10).grid(row=0, column=3, sticky=\"w\")\n",
    "\n",
    "    tilt_vars = {}\n",
    "    for i, f in enumerate(factors, start=1):\n",
    "        use_default  = bool(seed_tilts.loc[f, \"Use?\"])   if f in seed_tilts.index else False\n",
    "        tgt_default  = float(seed_tilts.loc[f, \"Target\"]) if f in seed_tilts.index else 0.0\n",
    "        band_default = float(seed_tilts.loc[f, \"Band\"])   if f in seed_tilts.index else 0.05\n",
    "        v_use = _tk.BooleanVar(value=use_default)\n",
    "        v_tgt = _tk.StringVar(value=f\"{tgt_default:.3f}\")\n",
    "        v_bnd = _tk.StringVar(value=f\"{band_default:.3f}\")\n",
    "        _ttk.Checkbutton(frm_right, variable=v_use).grid(row=i, column=0, sticky=\"w\", pady=2)\n",
    "        _ttk.Label(frm_right, text=f, width=12).grid(row=i, column=1, sticky=\"w\", pady=2)\n",
    "        _ttk.Entry(frm_right, textvariable=v_tgt, width=10).grid(row=i, column=2, sticky=\"w\", pady=2)\n",
    "        _ttk.Entry(frm_right, textvariable=v_bnd, width=10).grid(row=i, column=3, sticky=\"w\", pady=2)\n",
    "        tilt_vars[f] = (v_use, v_tgt, v_bnd)\n",
    "\n",
    "    # after fac_cols/f_mean_ann are available (you have them earlier), pass them in or recompute locally.\n",
    "    def _compute_recommended_tilts():\n",
    "        try:\n",
    "            ff = get_ff5_mom_daily().tail(FF5_LOOKBACK_DAYS)\n",
    "            fac_cols = [c for c in ff.columns if c != \"RF\"]\n",
    "            Fcov_daily = ff[fac_cols].cov()\n",
    "            f_mean_ann = ff[fac_cols].mean() * 252.0\n",
    "            # use the betas you already computed for the current prices window\n",
    "            reco, _wtilt = recommend_factor_tilts_achievable(B, f_mean_ann, Fcov_daily)\n",
    "            # ensure we return values for all factors in the dialog order\n",
    "            return reco.reindex(list(seed_tilts.index)).fillna(0.0)\n",
    "        except Exception:\n",
    "            return pd.Series(0.0, index=list(seed_tilts.index))\n",
    "    \n",
    "    def _apply_recommended_tilts():\n",
    "        rec = _compute_recommended_tilts()\n",
    "        for f in factors:\n",
    "            v_use, v_tgt, v_bnd = tilt_vars[f]\n",
    "            v_use.set(True)\n",
    "            v_tgt.set(f\"{float(rec.get(f,0.0)):.3f}\")\n",
    "            # keep user band or set to a gentle default:\n",
    "            if not v_bnd.get():\n",
    "                v_bnd.set(\"0.200\")\n",
    "        _mb.showinfo(\"Tilts\", \"Recommended tilts applied.\\n(You can still edit before Save.)\")\n",
    "    \n",
    "    btn_reco = _ttk.Button(frm_right, text=\"Auto-recommend tilts\", command=_apply_recommended_tilts)\n",
    "    btn_reco.grid(row=len(factors)+2, column=0, columnspan=4, sticky=\"ew\", pady=(12,0))\n",
    "\n",
    "    # Buttons\n",
    "    def _reset_to_seed_units():\n",
    "        su = pd.Series(seed_units).astype(float)  # seed_units is already a parameter to this function\n",
    "        for t, vs in row_vars.items():\n",
    "            if vs.get(\"disabled\"):\n",
    "                continue\n",
    "            vs[\"units\"].set(str(int(round(su.get(t, 0.0)))))\n",
    "        _mb.showinfo(\"Holdings\", \"Units reset to the values loaded from Excel at the start of this run.\")\n",
    "\n",
    "    \n",
    "    frm_btns = _ttk.Frame(root, padding=(10, 0, 10, 10)); frm_btns.pack(fill=\"x\")\n",
    "    _ttk.Button(frm_btns, text=\"Reset to Seed\", command=_reset_to_seed_units).pack(side=\"left\", padx=6)\n",
    "    _ttk.Button(frm_btns, text=\"Cancel\", command=root.destroy).pack(side=\"right\", padx=6)\n",
    "\n",
    "    def _on_save():\n",
    "        nonlocal prices\n",
    "        if added_tickers:\n",
    "            prices = _fetch_prices_for_new_tickers(added_tickers, prices)\n",
    "\n",
    "        to_delete = []\n",
    "        units_out, include_flags = {}, {}\n",
    "        for t, vs in row_vars.items():\n",
    "            mark_delete = bool(vs[\"del\"].get())\n",
    "            disabled = vs[\"disabled\"]\n",
    "            inc = bool(vs[\"inc\"].get()) and not disabled and not mark_delete\n",
    "            include_flags[t] = inc\n",
    "            if mark_delete:\n",
    "                to_delete.append(t)\n",
    "                continue\n",
    "            if not disabled:\n",
    "                txt = vs[\"units\"].get().strip()\n",
    "                try:\n",
    "                    val = float(txt) if txt else 0.0\n",
    "                except ValueError:\n",
    "                    val = 0.0\n",
    "                units_out[t] = val\n",
    "            # refresh last px label\n",
    "            if t in prices.columns:\n",
    "                try:\n",
    "                    lp = float(prices.ffill().iloc[-1].get(t, float('nan')))\n",
    "                    vs[\"lbl_px\"].configure(text=f\"{lp:.4f}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # remove deleted names from the price panel so they don’t enter μ/Σ\n",
    "        if to_delete:\n",
    "            keep = [c for c in prices.columns if c not in set(to_delete)]\n",
    "            prices = prices.reindex(columns=keep)\n",
    "\n",
    "        units_ser = pd.Series(units_out, dtype=float)\n",
    "        last_price_ser = prices.ffill().iloc[-1].reindex(units_ser.index)\n",
    "\n",
    "        out_rows = []\n",
    "        for f, (v_use, v_tgt, v_bnd) in tilt_vars.items():\n",
    "            try:  tgt = float(v_tgt.get())\n",
    "            except ValueError: tgt = 0.0\n",
    "            try:  bnd = float(v_bnd.get())\n",
    "            except ValueError: bnd = 0.05\n",
    "            out_rows.append({\"Factor\": f, \"Target\": tgt, \"Band\": bnd, \"Use?\": bool(v_use.get())})\n",
    "        tilts_df = pd.DataFrame(out_rows).set_index(\"Factor\").reindex(factors)\n",
    "\n",
    "        edit_holdings_and_tilts_dialog.result = (units_ser, last_price_ser, prices, include_flags, tilts_df)\n",
    "        root.destroy()\n",
    "\n",
    "    _ttk.Button(frm_btns, text=\"Save\", command=_on_save).pack(side=\"right\", padx=6)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", root.destroy)\n",
    "    root.mainloop()\n",
    "    return getattr(edit_holdings_and_tilts_dialog, \"result\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 5 Creating the Covariance Matrix and the Rest of the OPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FX-adjusted returns for Sigma?: True (max |diff|=0.00e+00)\n",
      "\n",
      "Recommended factor tilts (based on current factor premia):\n",
      "Mkt-RF    1.000\n",
      "SMB      -1.293\n",
      "HML       1.525\n",
      "RMW      -0.681\n",
      "CMA      -0.829\n",
      "MOM       0.425\n",
      "Name: Recommended β, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === Analytics helpers (moved from Block 4) ===================================\n",
    "def holdings_portfolio_returns(prices: pd.DataFrame, units: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build a value-weighted portfolio from 'prices' and 'units', and return daily pct-change.\n",
    "    - prices: wide DataFrame of Close in AUD (or AUD-converted) with Date index.\n",
    "    - units:  Series of current units held per ticker (can include zeros/missing).\n",
    "    Returns a daily return Series aligned to prices' index.\n",
    "    \"\"\"\n",
    "    units = pd.Series(units).reindex(prices.columns).fillna(0.0)\n",
    "    if units.abs().sum() == 0:\n",
    "        return pd.Series(dtype=float)\n",
    "    px = prices.reindex(columns=units.index).ffill()\n",
    "    port_val = (px * units.values).sum(axis=1)\n",
    "    ret = port_val.pct_change(fill_method=None)\n",
    "    return ret.dropna()\n",
    "\n",
    "def current_holdings_weights(units: pd.Series,\n",
    "                             last_prices: pd.Series,\n",
    "                             investable: list[str],\n",
    "                             fx_to_aud: pd.Series | float | None = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute FX-aware weights of current holdings over the investable set (long-only, renormalised).\n",
    "    - units:         Series of unit counts indexed by Security\n",
    "    - last_prices:   Series of last Close (native currency)\n",
    "    - investable:    list of tickers included in optimisation (order matters)\n",
    "    - fx_to_aud:     Series of FX-to-AUD per Security (or scalar 1.0); if None, assume 1.0\n",
    "    Returns a Series of weights indexed by investable tickers (sums to 1 if MV>0).\n",
    "    \"\"\"\n",
    "    # FX handling\n",
    "    if isinstance(fx_to_aud, pd.Series):\n",
    "        fx = fx_to_aud.reindex(units.index).fillna(1.0)\n",
    "    else:\n",
    "        fx = 1.0\n",
    "\n",
    "    mv = (pd.Series(units, dtype=float) * pd.Series(last_prices, dtype=float) * fx)\n",
    "    mv = mv.reindex(investable).fillna(0.0)\n",
    "    den = mv.sum()\n",
    "    return (mv / den) if den > 0 else mv\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) COVARIANCE MATRIX (daily)\n",
    "# ------------------------------------------------------------\n",
    "df_cov_wide = (\n",
    "    df_melt[['Date','Security','Return']]\n",
    "    .pivot(index='Date', columns='Security', values='Return')\n",
    ")\n",
    "\n",
    "Sigma_daily = df_cov_wide.cov()  # DAILY cov (AUD returns)\n",
    "\n",
    "# (Optional) sanity that Sigma came from AUD-converted prices\n",
    "Sigma_from_aud = (\n",
    "    pd.melt(prices_aud_for_returns.reset_index(), id_vars=\"Date\",\n",
    "            var_name=\"Security\", value_name=\"Close\")\n",
    "      .sort_values([\"Security\",\"Date\"])\n",
    "      .assign(Return=lambda d: d.groupby(\"Security\")[\"Close\"].pct_change(fill_method=None))\n",
    "      .pivot(index=\"Date\", columns=\"Security\", values=\"Return\")\n",
    "      .cov()\n",
    ").reindex(index=Sigma_daily.index, columns=Sigma_daily.columns)\n",
    "max_abs_diff = (Sigma_daily - Sigma_from_aud).abs().to_numpy().max()\n",
    "using_fx = np.allclose(Sigma_daily.to_numpy(), Sigma_from_aud.to_numpy(), rtol=0, atol=1e-12)\n",
    "print(f\"Using FX-adjusted returns for Sigma?: {using_fx} (max |diff|={max_abs_diff:.2e})\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) GEOMETRIC (LOG-BASED) EXPECTED RETURNS (annual) — sample μ\n",
    "# ------------------------------------------------------------\n",
    "df_melt['LogRet'] = np.log1p(df_melt['Return'])\n",
    "mu_log_ann = df_melt.groupby('Security')['LogRet'].mean() * 252.0\n",
    "mu_ann_geo = np.expm1(mu_log_ann)  # ANNUAL (geom)\n",
    "\n",
    "# Align\n",
    "securities_all = list(Sigma_daily.columns)\n",
    "Sigma_daily = Sigma_daily.loc[securities_all, securities_all]\n",
    "mu_vec_all = mu_ann_geo.reindex(securities_all)\n",
    "\n",
    "valid_all = [s for s in securities_all\n",
    "             if pd.notna(mu_vec_all.get(s, np.nan)) and pd.notna(Sigma_daily.loc[s, s])]\n",
    "Sigma_daily = Sigma_daily.loc[valid_all, valid_all]\n",
    "mu_vec_all = mu_vec_all.reindex(valid_all)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Build FF5 betas ONCE (so tilts are always available)\n",
    "# ------------------------------------------------------------\n",
    "# --- Configurable lookback (shared) ---\n",
    "FF5_LOOKBACK_DAYS = globals().get(\"FF5_LOOKBACK_DAYS\", 252*2)  # ~2 years\n",
    "\n",
    "def compute_ff5_betas(df_cov_wide, ff, min_obs=200):\n",
    "    fac = [c for c in ff.columns if c != \"RF\"]    # <— key change (auto includes MOM)\n",
    "    B_rows, alpha, resid = [], {}, {}\n",
    "    for t in df_cov_wide.columns:\n",
    "        r = df_cov_wide[t].dropna()\n",
    "        idx = r.index.intersection(ff.index)\n",
    "        if len(idx) < min_obs:\n",
    "            continue\n",
    "        y = (r.loc[idx] - ff.loc[idx, \"RF\"]).astype(float)\n",
    "        X = sm.add_constant(ff.loc[idx, fac].astype(float))\n",
    "        res = sm.OLS(y, X, missing=\"drop\").fit()\n",
    "        alpha[t] = float(res.params.get(\"const\", 0.0))\n",
    "        B_rows.append((t, res.params.reindex(fac).fillna(0.0).values))\n",
    "        resid[t] = float(res.resid.var(ddof=1))\n",
    "    if not B_rows:\n",
    "        return None, None, None\n",
    "    B = pd.DataFrame([b for _, b in B_rows], index=[t for t,_ in B_rows], columns=fac)\n",
    "    return B, pd.Series(alpha), pd.Series(resid)\n",
    "\n",
    "\n",
    "ff5 = get_ff5_mom_daily()                     # DAILY, decimals\n",
    "ff5_win = ff5.tail(FF5_LOOKBACK_DAYS)     # use same window everywhere\n",
    "B, alpha_daily, resid_var = compute_ff5_betas(df_cov_wide, ff5_win, min_obs=120)\n",
    "\n",
    "def recommend_factor_tilts_achievable(B: pd.DataFrame,\n",
    "                                      f_mean_ann: pd.Series,\n",
    "                                      Fcov_daily: pd.DataFrame,\n",
    "                                      normalise_to_mkt: bool = True,\n",
    "                                      lam_w: float = 0.0,\n",
    "                                      w0: pd.Series | None = None) -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Project the unconstrained factor target t* = Σ_f^{-1} μ_f onto the long-only simplex:\n",
    "        min_w  0.5 || B^T w - t* ||^2  + 0.5 * lam_w * ||w||^2\n",
    "        s.t.   w >= 0, 1'w = 1\n",
    "    Returns (tilt_reco_achievable, w_tilt).\n",
    "    \"\"\"\n",
    "    fac = [c for c in B.columns]          # factor order\n",
    "    mu = f_mean_ann.reindex(fac).astype(float).values\n",
    "    Sig = Fcov_daily.loc[fac, fac].astype(float).values\n",
    "\n",
    "    # unconstrained \"ideal\" target in factor space\n",
    "    t_star = pinv(Sig) @ mu\n",
    "    if normalise_to_mkt and \"Mkt-RF\" in fac:\n",
    "        m_idx = fac.index(\"Mkt-RF\")\n",
    "        if abs(t_star[m_idx]) > 1e-12:\n",
    "            t_star = t_star / t_star[m_idx]\n",
    "\n",
    "    # optimise over portfolio weights\n",
    "    tick = list(B.index)\n",
    "    n = len(tick)\n",
    "    Bt = B[fac].T.values  # shape (F, n)\n",
    "\n",
    "    # start from current holdings weights if provided, else uniform\n",
    "    if isinstance(w0, pd.Series):\n",
    "        w0v = w0.reindex(tick).fillna(0.0).values\n",
    "        s = w0v.sum(); w0v = (w0v / s) if s > 0 else np.full(n, 1.0/n)\n",
    "    else:\n",
    "        w0v = np.full(n, 1.0/n)\n",
    "\n",
    "    def obj(w):\n",
    "        diff = Bt @ w - t_star\n",
    "        return 0.5 * (diff @ diff) + 0.5 * lam_w * (w @ w)\n",
    "\n",
    "    def grad(w):\n",
    "        diff = Bt @ w - t_star\n",
    "        return Bt.T @ diff + lam_w * w\n",
    "\n",
    "    cons = (\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0, 'jac': lambda w: np.ones_like(w)},\n",
    "    )\n",
    "    bounds = [(0.0, 1.0)] * n\n",
    "\n",
    "    res = minimize(obj, w0v, method='SLSQP', jac=grad, bounds=bounds, constraints=cons,\n",
    "                   options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False})\n",
    "    w_hat = (res.x if res.success else w0v)\n",
    "    w_hat = np.clip(w_hat, 0, 1); w_hat = w_hat / max(1e-12, w_hat.sum())\n",
    "\n",
    "    t_ach = (Bt @ w_hat)\n",
    "    tilt_reco = pd.Series(t_ach, index=fac, name=\"Achievable β\")\n",
    "    w_tilt = pd.Series(w_hat, index=tick, name=\"w_tilt\")\n",
    "    return tilt_reco, w_tilt\n",
    "\n",
    "def compute_factor_feasible_ranges(B: pd.DataFrame,\n",
    "                                   include_flags: dict[str, bool] | None = None,\n",
    "                                   factor_order: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each factor f in B.columns, solve:\n",
    "        min/max   B[:, f]^T w\n",
    "        s.t.      w >= 0, 1'w = 1, and (optionally) w_i = 0 if include_flags[ticker] is False.\n",
    "    Returns a DataFrame with columns: ['Min β','Max β'] indexed by factor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.optimize import linprog\n",
    "    except Exception as e:\n",
    "        # Graceful fallback if SciPy isn't available\n",
    "        facs = list(B.columns) if factor_order is None else list(factor_order)\n",
    "        return pd.DataFrame({\"Min β\": np.nan, \"Max β\": np.nan}, index=facs)\n",
    "\n",
    "    tickers = list(B.index)\n",
    "    n = len(tickers)\n",
    "    if factor_order is None:\n",
    "        factor_order = list(B.columns)\n",
    "    factor_order = [f for f in factor_order if f in B.columns]\n",
    "\n",
    "    # equality: sum w = 1\n",
    "    A_eq = np.ones((1, n))\n",
    "    b_eq = np.array([1.0])\n",
    "\n",
    "    # bounds: 0 <= w_i <= 1, and optionally force 0 for excluded tickers\n",
    "    if include_flags:\n",
    "        bounds = [(0.0, 1.0 if bool(include_flags.get(t, True)) else 0.0) for t in tickers]\n",
    "    else:\n",
    "        bounds = [(0.0, 1.0)] * n\n",
    "\n",
    "    mins, maxs = [], []\n",
    "    for f in factor_order:\n",
    "        c = B[f].astype(float).values  # objective coefficients\n",
    "\n",
    "        # minimise c^T w\n",
    "        res_min = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "        beta_min = float(res_min.fun) if res_min.success else np.nan\n",
    "\n",
    "        # maximise c^T w  <=> minimise (-c)^T w\n",
    "        res_max = linprog(-c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "        beta_max = (-float(res_max.fun)) if res_max.success else np.nan\n",
    "\n",
    "        mins.append(beta_min); maxs.append(beta_max)\n",
    "\n",
    "    out = pd.DataFrame({\"Min β\": mins, \"Max β\": maxs}, index=factor_order)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Choose μ and Σ source for the optimiser\n",
    "#       - Sample: Sigma_daily (DAILY), mu_ann_geo (ANNUAL)\n",
    "#       - FF5:    Sigma_ff (DAILY),   mu_ff_ann (ANNUAL)\n",
    "# ------------------------------------------------------------\n",
    "USE_FF5 = True  # flip to False to use sample moments\n",
    "\n",
    "if USE_FF5 and (B is not None) and not B.empty:\n",
    "    fac_cols = [c for c in ff5_win.columns if c != \"RF\"]  # auto-includes MOM if present\n",
    "    Fcov_daily = ff5_win[fac_cols].cov()\n",
    "    S_diag = resid_var.reindex(B.index).clip(lower=0.0).fillna(0.0)\n",
    "\n",
    "    Sigma_ff_daily = B @ Fcov_daily @ B.T + np.diag(S_diag)\n",
    "    Sigma_ff_daily = pd.DataFrame(Sigma_ff_daily, index=B.index, columns=B.index)\n",
    "\n",
    "    f_mean_ann = ff5_win[fac_cols].mean() * 252.0        # ANNUAL premia\n",
    "    \n",
    "    # === RECOMMENDED FACTOR TILTS ================================================\n",
    "    # Compute an achievable recommendation based on your current investable set\n",
    "    tilt_reco_achievable, w_tilt = recommend_factor_tilts_achievable(B, f_mean_ann, Fcov_daily,\n",
    "                                                                 normalise_to_mkt=True,\n",
    "                                                                 lam_w=0.0,\n",
    "                                                                 w0=None)  # or pass current weights if you prefer\n",
    "    \n",
    "    def recommend_factor_tilts(f_mean_ann, Fcov_daily, normalise=True):\n",
    "        \"\"\"\n",
    "        Recommend optimal factor tilts given estimated factor premia and covariance.\n",
    "        Returns a Series of recommended beta targets for each factor.\n",
    "        \"\"\"\n",
    "        fac = f_mean_ann.index\n",
    "        mu = f_mean_ann.values\n",
    "        Sigma = Fcov_daily.loc[fac, fac].values\n",
    "    \n",
    "        # Mean–variance optimal factor exposure vector: Σ⁻¹ μ\n",
    "        Sigma_inv = np.linalg.pinv(Sigma)\n",
    "        t_opt = Sigma_inv @ mu\n",
    "    \n",
    "        # Normalise so that Market β = 1 (interpretable scaling)\n",
    "        if normalise and \"Mkt-RF\" in fac:\n",
    "            t_opt = t_opt / t_opt[list(fac).index(\"Mkt-RF\")]\n",
    "    \n",
    "        return pd.Series(t_opt, index=fac, name=\"Recommended β\")\n",
    "    \n",
    "    # Compute and display recommended tilts\n",
    "    tilt_reco = recommend_factor_tilts(f_mean_ann, Fcov_daily)\n",
    "    print(\"\\nRecommended factor tilts (based on current factor premia):\")\n",
    "    print(tilt_reco.round(3))\n",
    "    # ==============================================================================\n",
    "    \n",
    "    alpha_ann  = alpha_daily * 252.0                     # ANNUAL alpha\n",
    "    mu_ff_ann  = alpha_ann.reindex(B.index).fillna(0.0) + (B @ f_mean_ann).rename(None) + rf_annual\n",
    "  \n",
    "    securities_opt = [t for t in Sigma_ff_daily.index if t not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_ff_daily.loc[securities_opt, securities_opt]   # DAILY\n",
    "    mu_vec_opt = mu_ff_ann.reindex(securities_opt)                   # ANNUAL\n",
    "    exp_ret_label = \"Expected Return (annual, FF5)\"\n",
    "else:\n",
    "    \n",
    "    securities_opt = [s for s in valid_all if s not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_daily.loc[securities_opt, securities_opt]      # DAILY\n",
    "    mu_vec_opt = mu_vec_all.reindex(securities_opt)                  # ANNUAL\n",
    "    exp_ret_label = \"Expected Return (ann., geom)\"\n",
    "\n",
    "# Display tables (once μ/Σ are final)\n",
    "n_opt = len(securities_opt)\n",
    "cov_plus = pd.DataFrame(0.0, index=securities_opt + ['w'], columns=securities_opt + ['w'])\n",
    "cov_plus.iloc[:n_opt, :n_opt] = Sigma_opt.values\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) OPTIMISATION UTILITIES (unconstrained + tilt-constrained)\n",
    "# ------------------------------------------------------------\n",
    "def optimise_long_only(mu, Sigma, target_return):\n",
    "    try:\n",
    "        from scipy.optimize import minimize\n",
    "        n = len(mu)\n",
    "        mu = np.asarray(mu, dtype=float)\n",
    "        Sigma = np.asarray(Sigma, dtype=float)\n",
    "        if not (mu.min() - 1e-12 <= target_return <= mu.max() + 1e-12):\n",
    "            return np.full(n, np.nan), False, \"Target outside long-only feasible range.\"\n",
    "        def obj(w): return float(w @ Sigma @ w)\n",
    "        cons = (\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "            {'type': 'eq', 'fun': lambda w: float(mu @ w) - float(target_return)},\n",
    "        )\n",
    "        bounds = [(0.0, 1.0)] * n\n",
    "        w0 = np.full(n, 1.0/n)\n",
    "        res = minimize(obj, w0, method='SLSQP', bounds=bounds, constraints=cons,\n",
    "                       options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False})\n",
    "        if res.success and np.isfinite(res.fun):\n",
    "            return res.x, True, \"SLSQP success.\"\n",
    "        return np.full(n, np.nan), False, \"SLSQP failed.\"\n",
    "    except Exception as e:\n",
    "        return np.full(len(mu), np.nan), False, f\"SLSQP unavailable or error: {e}\"\n",
    "\n",
    "def optimise_unconstrained_analytic(mu, Sigma, target_return):\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    Sigma = np.asarray(Sigma, dtype=float)\n",
    "    n = len(mu); ones = np.ones(n)\n",
    "    Sigma_inv = np.linalg.pinv(Sigma)\n",
    "    A = ones @ Sigma_inv @ ones\n",
    "    Bv = ones @ Sigma_inv @ mu\n",
    "    C = mu @ Sigma_inv @ mu\n",
    "    M = np.array([[A, Bv], [Bv, C]]); rhs = np.array([1.0, float(target_return)])\n",
    "    try:\n",
    "        alpha, beta = np.linalg.solve(M, rhs)\n",
    "        w = Sigma_inv @ (alpha * ones + beta * mu)\n",
    "        return w, \"Analytic solution.\"\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.full(n, np.nan), \"Analytic solver failed (singular).\"\n",
    "\n",
    "def optimise_long_only_with_tilts(mu, Sigma, target_return, B, tilt_targets, tilt_bands, use_mask):\n",
    "    from scipy.optimize import minimize\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    Sigma = np.asarray(Sigma, dtype=float)\n",
    "    n = len(mu)\n",
    "    def obj(w): return float(w @ Sigma @ w)\n",
    "    cons = [\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "        {'type': 'eq', 'fun': lambda w: float(mu @ w) - float(target_return)},\n",
    "    ]\n",
    "    for f in [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]:\n",
    "        if not use_mask.get(f, True): \n",
    "            continue\n",
    "        t = float(tilt_targets.get(f, 0.0))\n",
    "        b = float(tilt_bands.get(f, 0.05))\n",
    "        v = B[f].values\n",
    "        cons.append({'type':'ineq', 'fun': (lambda v=v, t=t, b=b: lambda w: (t + b) - float(v @ w))()})\n",
    "        cons.append({'type':'ineq', 'fun': (lambda v=v, t=t, b=b: lambda w:  float(v @ w) - (t - b))()})\n",
    "    bounds = [(0.0, 1.0)] * n\n",
    "    w0 = np.full(n, 1.0/n)\n",
    "    res = minimize(obj, w0, method='SLSQP', bounds=bounds, constraints=cons,\n",
    "                   options={'maxiter': 1000, 'ftol': 1e-12, 'disp': False})\n",
    "    if res.success and np.isfinite(res.fun):\n",
    "        return res.x, \"tilt SLSQP success\"\n",
    "    return np.full(n, np.nan), f\"tilt SLSQP failed ({getattr(res,'message','unknown')})\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) FRONTIERS: unconstrained and tilt-constrained\n",
    "# ------------------------------------------------------------\n",
    "target_returns = [0.01, 0.02, 0.03, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.225, 0.25, 0.275, 0.30, 0.325, 0.35, 0.375, 0.40]\n",
    "\n",
    "# Unconstrained (your current behaviour)\n",
    "weights_dict, stats_rows = {}, []\n",
    "for R in target_returns:\n",
    "    w, ok, note = optimise_long_only(mu_vec_opt.values, Sigma_opt.values, R)\n",
    "    weights_dict[R] = w\n",
    "    vol_ann = (np.sqrt(w @ Sigma_opt.values @ w) * np.sqrt(252.0)) if np.all(np.isfinite(w)) else np.nan\n",
    "    achieved = float(mu_vec_opt.values @ w) if np.all(np.isfinite(w)) else np.nan\n",
    "    sharpe = (achieved - rf_annual) / vol_ann if (pd.notna(vol_ann) and vol_ann > 0) else np.nan\n",
    "    stats_rows.append({\"Target Return\": R, \"Achieved Return\": achieved, \"Volatility (ann.)\": vol_ann,\n",
    "                       \"Sharpe\": sharpe, \"Method\": \"Long-only SLSQP\", \"Note\": note})\n",
    "weights_cols = [f\"{int(r*1000)/10:.1f}%\" if (r*100)%1!=0 else f\"{int(r*100):d}%\" for r in target_returns]\n",
    "W = pd.DataFrame({col: weights_dict[R] for col, R in zip(weights_cols, target_returns)}, index=securities_opt)\n",
    "stats_df = pd.DataFrame(stats_rows)\n",
    "stats_df.insert(0, \"Target (%)\", [f\"{int(r*1000)/10:.1f}%\" if (r*100)%1!=0 else f\"{int(r*100):d}%\"\n",
    "                                   for r in target_returns])\n",
    "stats_df = stats_df.drop(columns=[\"Target Return\"])\n",
    "# Robust tangency selection (handles all-NaN Sharpe)\n",
    "sh = pd.to_numeric(stats_df['Sharpe'], errors='coerce')\n",
    "if sh.notna().any():\n",
    "    best_idx = int(sh.idxmax())\n",
    "else:\n",
    "    vol_series = pd.to_numeric(stats_df['Volatility (ann.)'], errors='coerce')\n",
    "    best_idx = int(vol_series.idxmin()) if vol_series.notna().any() else 0\n",
    "\n",
    "tan_ret = float(pd.to_numeric(stats_df.loc[best_idx, 'Achieved Return'], errors='coerce'))\n",
    "tan_vol = float(pd.to_numeric(stats_df.loc[best_idx, 'Volatility (ann.)'], errors='coerce'))\n",
    "if not np.isfinite(tan_ret) or not np.isfinite(tan_vol):\n",
    "    tan_ret, tan_vol = float('nan'), float('nan')\n",
    "\n",
    "cal_df = pd.DataFrame({\"Volatility (ann.)\": [0.0, tan_vol], \"Return\": [rf_annual, tan_ret]})\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) PREPARE A Trade Plan\n",
    "# ------------------------------------------------------------\n",
    "cov_plus = cov_plus.fillna(0.0)\n",
    "\n",
    "# investable assets only (matches weights grid)\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "# or, if you prefer to show all (incl. ^AORD), use mu_vec_all instead.\n",
    "\n",
    "def make_trade_plan(units_cur, last_px, fx_map, w_target, include_flags, include_zero_lines=False):\n",
    "    \"\"\"Return (trade_df, residual_cash) to move from current units to target weights (AUD).\n",
    "       If include_zero_lines=True, keep rows with Δ Units = 0 in the output table.\"\"\"\n",
    "    tickers = list(w_target.index)\n",
    "    inc = pd.Series(include_flags).reindex(tickers).fillna(True).astype(bool)\n",
    "    tickers = [t for t in tickers if inc.get(t, True)]\n",
    "\n",
    "    lp_aud = (pd.Series(last_px).reindex(tickers).astype(float) *\n",
    "              pd.Series(fx_map).reindex(tickers).fillna(1.0).astype(float))\n",
    "    cur_units = pd.Series(units_cur).reindex(tickers).fillna(0.0).astype(float)\n",
    "    cur_val = (cur_units * lp_aud).sum()\n",
    "    cur_val = float(cur_val)\n",
    "\n",
    "    if cur_val <= 0:\n",
    "        out = pd.DataFrame(columns=[\"Security\",\"Curr Units\",\"Target Units\",\"Δ Units\",\"Last Px (AUD)\",\"Cash Flow (AUD)\"])\n",
    "        return out, 0.0\n",
    "\n",
    "    tgt_val = pd.Series(w_target).reindex(tickers).fillna(0.0) * cur_val\n",
    "    tgt_units_float = (tgt_val / lp_aud).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    tgt_units_int = tgt_units_float.round().astype(int)\n",
    "\n",
    "    delta_units = (tgt_units_int - cur_units).round().astype(int)\n",
    "    cash_impact = (-delta_units * lp_aud).astype(float)\n",
    "    residual = float((tgt_val - tgt_units_int * lp_aud).sum())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"Security\": tickers,\n",
    "        \"Curr Units\": cur_units.astype(int).values,\n",
    "        \"Target Units\": tgt_units_int.values,\n",
    "        \"Δ Units\": delta_units.values,\n",
    "        \"Last Px (AUD)\": lp_aud.values,\n",
    "        \"Cash Flow (AUD)\": cash_impact.values\n",
    "    })\n",
    "    if not include_zero_lines:\n",
    "        out = out.loc[out[\"Δ Units\"] != 0]\n",
    "    return out.reset_index(drop=True), residual\n",
    "\n",
    "\n",
    "def compute_target_units_for_holdings(units_cur, last_px, fx_map, w_target, include_flags):\n",
    "    tickers = list(pd.Index(w_target.index))\n",
    "    inc = pd.Series(include_flags).reindex(tickers).fillna(True).astype(bool)\n",
    "    tickers = [t for t in tickers if inc.get(t, True)]\n",
    "\n",
    "    lp_aud = (pd.Series(last_px).reindex(tickers).astype(float) *\n",
    "              pd.Series(fx_map).reindex(tickers).fillna(1.0).astype(float))\n",
    "    cur_units = pd.Series(units_cur).reindex(tickers).fillna(0.0).astype(float)\n",
    "    cur_val = float((cur_units * lp_aud).sum())\n",
    "    if cur_val <= 0:\n",
    "        return pd.Series(0, index=w_target.index, dtype=int)\n",
    "\n",
    "    tgt_val = pd.Series(w_target).reindex(tickers).fillna(0.0) * cur_val\n",
    "    tgt_units_float = (tgt_val / lp_aud).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    tgt_units_int = tgt_units_float.round().astype(int)\n",
    "    return tgt_units_int.reindex(w_target.index).fillna(0).astype(int)\n",
    "\n",
    "def compute_achieved_tilts(B: pd.DataFrame, w: pd.Series, factors=None, renormalise_missing=True) -> pd.Series:\n",
    "    if B is None or B.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    w_all = pd.Series(w).reindex(B.index).fillna(0.0)\n",
    "    if renormalise_missing and w_all.sum() > 0:\n",
    "        w_use = w_all / w_all.sum()\n",
    "    else:\n",
    "        w_use = w_all\n",
    "    t = (B.T @ w_use).rename(\"Achieved β\")\n",
    "    if factors is not None:\n",
    "        t = t.reindex(factors)\n",
    "    return t\n",
    "\n",
    "def _build_frontier(mu_vec_opt, Sigma_opt, target_returns=None):\n",
    "    if target_returns is None:\n",
    "        target_returns = [0.01, 0.02, 0.03, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.225, 0.25, 0.275, 0.30, 0.325, 0.35, 0.375, 0.40]\n",
    "    weights_dict, stats_rows = {}, []\n",
    "    mu = mu_vec_opt.values; S = Sigma_opt.values\n",
    "    for R in target_returns:\n",
    "        w, ok, note = optimise_long_only(mu, S, R)\n",
    "        weights_dict[R] = w\n",
    "        vol_ann = (np.sqrt(w @ S @ w) * np.sqrt(252.0)) if np.all(np.isfinite(w)) else np.nan\n",
    "        achieved = float(mu @ w) if np.all(np.isfinite(w)) else np.nan\n",
    "        sharpe = (achieved - rf_annual) / vol_ann if (pd.notna(vol_ann) and vol_ann > 0) else np.nan\n",
    "        stats_rows.append({\"Target Return\": R, \"Achieved Return\": achieved, \"Volatility (ann.)\": vol_ann,\n",
    "                           \"Sharpe\": sharpe, \"Method\": \"Long-only SLSQP\", \"Note\": note})\n",
    "    cols = [f\"{int(r*1000)/10:.1f}%\" if (r*100)%1!=0 else f\"{int(r*100):d}%\" for r in target_returns]\n",
    "    W = pd.DataFrame({c: weights_dict[R] for c, R in zip(cols, target_returns)}, index=Sigma_opt.index)\n",
    "    stats_df = pd.DataFrame(stats_rows)\n",
    "    stats_df.insert(0, \"Target (%)\", cols)\n",
    "    stats_df = stats_df.drop(columns=[\"Target Return\"])\n",
    "    # Robust tangency selection (handles all-NaN Sharpe)\n",
    "    sh = pd.to_numeric(stats_df['Sharpe'], errors='coerce')\n",
    "    if sh.notna().any():\n",
    "        best_idx = int(sh.idxmax())\n",
    "    else:\n",
    "        vol_series = pd.to_numeric(stats_df['Volatility (ann.)'], errors='coerce')\n",
    "        best_idx = int(vol_series.idxmin()) if vol_series.notna().any() else 0\n",
    "    \n",
    "    tan_ret = float(pd.to_numeric(stats_df.loc[best_idx, 'Achieved Return'], errors='coerce'))\n",
    "    tan_vol = float(pd.to_numeric(stats_df.loc[best_idx, 'Volatility (ann.)'], errors='coerce'))\n",
    "    if not np.isfinite(tan_ret) or not np.isfinite(tan_vol):\n",
    "        tan_ret, tan_vol = float('nan'), float('nan')\n",
    "    return W, stats_df, tan_ret, tan_vol\n",
    "\n",
    "W, stats_df, tan_ret, tan_vol = _build_frontier(mu_vec_opt, Sigma_opt)\n",
    "\n",
    "# Load parcels once (if the sheet is missing, you just get an empty table)\n",
    "lots_df = _read_lots_from_path(filename, \"Lots\")\n",
    "\n",
    "def _cost_adjust_stats(W, stats_df, units, last_px, fx_map, include_flags):\n",
    "    mv_aud = float((pd.Series(units, dtype=float).reindex(W.index).fillna(0.0) *\n",
    "                   last_px.reindex(W.index).astype(float) *\n",
    "                   pd.Series(fx_map).reindex(W.index).fillna(1.0)).sum())\n",
    "    sale_date = pd.Timestamp(prices.index[-1])\n",
    "\n",
    "    costs = []\n",
    "    for col in W.columns:\n",
    "        w = W[col].reindex(W.index).fillna(0.0)\n",
    "        trade, _resid = make_trade_plan(units, last_px, fx_map, w, include_flags)\n",
    "        c = evaluate_transaction_costs(trade, lots_df, sale_date, MARGINAL_TAX_RATE)\n",
    "        # Achieved (model) return already in stats_df, but compute directly to be safe:\n",
    "        ach = float(mu_vec_opt.reindex(W.index).fillna(0.0).values @ w.values)\n",
    "        net_ret = ach - (c[\"total_cost\"] / mv_aud if mv_aud > 0 else 0.0)\n",
    "        costs.append({\"Target (%)\": col,\n",
    "                      \"Txn Costs (AUD)\": c[\"total_cost\"],\n",
    "                      \"Net Achieved Return\": net_ret})\n",
    "    extra = pd.DataFrame(costs)\n",
    "    out = stats_df.merge(extra, on=\"Target (%)\", how=\"left\")\n",
    "    out[\"Net Sharpe\"] = (out[\"Net Achieved Return\"] - rf_annual) / out[\"Volatility (ann.)\"]\n",
    "    return out\n",
    "\n",
    "    units = pd.Series(0, index=mu_vec_opt.index)\n",
    "    last_px_hold = prices.ffill().iloc[-1].reindex(units.index)\n",
    "    include_flags = {t: True for t in units.index}\n",
    "    \n",
    "    stats_df = _cost_adjust_stats(W, stats_df, units, last_px_hold, fx_map_all, include_flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOCK 6 Transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _market_of(ticker: str) -> str:\n",
    "    t = str(ticker)\n",
    "    if t.startswith(\"^\"): return \"INDEX\"\n",
    "    if t.endswith(\".AX\"): return \"ASX\"\n",
    "    return \"US\"\n",
    "\n",
    "def compute_brokerage(trade_df: pd.DataFrame) -> tuple[float, pd.Series]:\n",
    "    \"\"\"Return (total_brokerage_AUD, per_row_series).\"\"\"\n",
    "    if trade_df.empty:\n",
    "        return 0.0, pd.Series(dtype=float)\n",
    "\n",
    "    fees = []\n",
    "    asx_buy_candidates = []  # (row_idx, trade_value) eligible for $0\n",
    "\n",
    "    for i, r in trade_df.iterrows():\n",
    "        # Skip rows with no actual trade\n",
    "        units = float(r.get(\"Δ Units\", 0.0))\n",
    "        if abs(units) < 1e-12:\n",
    "            fees.append(0.0)\n",
    "            continue\n",
    "\n",
    "        mkt = _market_of(r[\"Security\"])\n",
    "        px  = float(r.get(\"Last Px (AUD)\", 0.0))\n",
    "        trade_val = abs(units) * px\n",
    "\n",
    "        if mkt == \"US\":\n",
    "            fee = 0.0\n",
    "        elif mkt == \"ASX\":\n",
    "            fee = max(BROKERAGE[\"ASX\"][\"min_fee\"], BROKERAGE[\"ASX\"][\"rate\"] * trade_val)\n",
    "            # Track eligible “first buy ≤ $1k”\n",
    "            if units > 0 and trade_val <= BROKERAGE[\"ASX\"][\"first_buy_free_threshold\"] + 1e-9:\n",
    "                asx_buy_candidates.append((i, trade_val))\n",
    "        else:\n",
    "            fee = 0.0\n",
    "\n",
    "        fees.append(fee)\n",
    "\n",
    "    fees = pd.Series(fees, index=trade_df.index, name=\"Brokerage (AUD)\")\n",
    "\n",
    "    # Apply “first ASX buy ≤ $1k is $0” to ONE eligible row\n",
    "    if asx_buy_candidates:\n",
    "        # (Leave as smallest-eligible; change to reverse=True to pick the largest-eligible instead.)\n",
    "        idx0 = sorted(asx_buy_candidates, key=lambda x: x[1])[0][0]\n",
    "        fees.loc[idx0] = 0.0\n",
    "\n",
    "    return float(fees.sum()), fees\n",
    "\n",
    "\n",
    "def _read_lots_from_path(xl_path, sheet=\"Lots\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lots sheet schema:\n",
    "      Security | AcqDate | Units | CostBaseAUD\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xl_path, sheet_name=sheet)\n",
    "    except Exception:\n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "    if df.empty: \n",
    "        return pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "\n",
    "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "    if \"AcqDate\" in df.columns:\n",
    "        df[\"AcqDate\"] = pd.to_datetime(df[\"AcqDate\"], errors=\"coerce\")\n",
    "    for col in [\"Units\",\"CostBaseAUD\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])\n",
    "    df[\"Security\"] = df[\"Security\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def _is_long_term_au(acq_date: pd.Timestamp, sale_date: pd.Timestamp) -> bool:\n",
    "    \"\"\"\n",
    "    Australian CGT 50% discount rule:\n",
    "    asset must be held for at least 12 months between acquisition and sale.\n",
    "    Uses relativedelta to handle leap years correctly.\n",
    "    \"\"\"\n",
    "    if pd.isna(acq_date) or pd.isna(sale_date):\n",
    "        return False\n",
    "    return sale_date >= (pd.Timestamp(acq_date) + relativedelta(years=1))\n",
    "\n",
    "def _allocate_sale_to_lots(lots: pd.DataFrame, sell_units: float, sale_price_aud: float,\n",
    "                           sale_date: pd.Timestamp, method: str = \"HIFO\"):\n",
    "    \"\"\"\n",
    "    Consume lot units to satisfy a sale. Returns list of dicts with:\n",
    "      qty, acq_date, proceed, cost_base, gain, long_term\n",
    "    \"\"\"\n",
    "    if lots.empty or sell_units <= 0:\n",
    "        return []\n",
    "\n",
    "    lots = lots.copy()\n",
    "    if \"AcqDate\" in lots.columns:\n",
    "        lots[\"AcqDate\"] = pd.to_datetime(lots[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    # Sort by matching method\n",
    "    if method.upper() == \"HIFO\":\n",
    "        lots = lots.sort_values(by=[\"CostBaseAUD\", \"AcqDate\"], ascending=[False, True])\n",
    "    else:  # FIFO\n",
    "        lots = lots.sort_values(by=[\"AcqDate\"], ascending=True)\n",
    "\n",
    "    out = []\n",
    "    remaining = float(sell_units)\n",
    "    for _, L in lots.iterrows():\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        have = float(L[\"Units\"])\n",
    "        if have <= 0:\n",
    "            continue\n",
    "\n",
    "        qty = min(remaining, have)\n",
    "        cb_unit = float(L[\"CostBaseAUD\"])\n",
    "        acq = pd.Timestamp(L[\"AcqDate\"])\n",
    "\n",
    "        proceed = float(sale_price_aud) * qty\n",
    "        cost_base = cb_unit * qty\n",
    "        gain = proceed - cost_base\n",
    "        long_term = _is_long_term_au(acq, sale_date)\n",
    "\n",
    "        out.append({\n",
    "            \"qty\": qty,\n",
    "            \"acq_date\": acq,\n",
    "            \"proceed\": proceed,\n",
    "            \"cost_base\": cost_base,\n",
    "            \"gain\": gain,\n",
    "            \"long_term\": bool(long_term),\n",
    "        })\n",
    "        remaining -= qty\n",
    "\n",
    "    return out\n",
    "\n",
    "def compute_cgt_tax(trade_df: pd.DataFrame, lots_df: pd.DataFrame, sale_date: pd.Timestamp,\n",
    "                    marginal_rate: float, carry_forward_loss: float = 0.0,\n",
    "                    method: str = \"HIFO\") -> tuple[float, dict]:\n",
    "    \"\"\"\n",
    "    Returns (tax_AUD, breakdown_dict) with an 'audit' DataFrame so users can see exactly\n",
    "    how CGT was computed (per-lot).\n",
    "    \"\"\"\n",
    "    if trade_df.empty:\n",
    "        return 0.0, {\"st_gain\":0.0, \"lt_gain\":0.0, \"losses\":0.0,\n",
    "                     \"discounted_lt_after_losses\":0.0, \"taxable\":0.0, \"audit\": pd.DataFrame()}\n",
    "\n",
    "    lots_df = lots_df.copy()\n",
    "    if \"AcqDate\" in lots_df.columns:\n",
    "        lots_df[\"AcqDate\"] = pd.to_datetime(lots_df[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    # group lots by security for fast lookup\n",
    "    lots_by_sec = {s: g.copy() for s, g in lots_df.groupby(\"Security\")} if not lots_df.empty else {}\n",
    "\n",
    "    audit_rows = []\n",
    "    st_gain = 0.0; lt_gain = 0.0; losses = 0.0\n",
    "\n",
    "    for _, r in trade_df.iterrows():\n",
    "        dU = int(r.get(\"Δ Units\", 0))\n",
    "        if dU >= 0:  # only sells trigger CGT\n",
    "            continue\n",
    "        sec  = str(r[\"Security\"])\n",
    "        px_aud = float(r[\"Last Px (AUD)\"])\n",
    "        sell_qty = abs(dU)\n",
    "\n",
    "        ledger = _allocate_sale_to_lots(\n",
    "            lots_by_sec.get(sec, pd.DataFrame(columns=[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"])),\n",
    "            sell_qty, px_aud, sale_date, method=method\n",
    "        )\n",
    "        sold = 0.0\n",
    "        for row in ledger:\n",
    "            sold += row[\"qty\"]\n",
    "            g = row[\"gain\"]\n",
    "            audit_rows.append({\n",
    "                \"Security\": sec,\n",
    "                \"Qty\": row[\"qty\"],\n",
    "                \"AcqDate\": row[\"acq_date\"],\n",
    "                \"SaleDate\": pd.Timestamp(sale_date),\n",
    "                \"Proceeds\": row[\"proceed\"],\n",
    "                \"CostBase\": row[\"cost_base\"],\n",
    "                \"Gain\": row[\"gain\"],\n",
    "                \"LongTermEligible\": bool(row[\"long_term\"])\n",
    "            })\n",
    "            if g >= 0:\n",
    "                if row[\"long_term\"]:\n",
    "                    lt_gain += g\n",
    "                else:\n",
    "                    st_gain += g\n",
    "            else:\n",
    "                losses += -g  # store as positive\n",
    "\n",
    "        # excess sells beyond recorded lots → treat as zero-gain (conservative)\n",
    "        _unused = max(0.0, sell_qty - sold)\n",
    "\n",
    "    # Apply losses (including carry-forward) first, optimally vs ST then LT\n",
    "    rem_losses = float(carry_forward_loss) + float(losses)\n",
    "    st_off = min(rem_losses, st_gain);  st_gain -= st_off;  rem_losses -= st_off\n",
    "    lt_off = min(rem_losses, lt_gain);  lt_gain -= lt_off;  rem_losses -= lt_off\n",
    "\n",
    "    # 50% discount on remaining long-term gains (AU individual rule)\n",
    "    discounted_lt = 0.5 * max(0.0, lt_gain)\n",
    "    taxable = max(0.0, st_gain + discounted_lt)\n",
    "\n",
    "    tax = float(marginal_rate) * float(taxable)\n",
    "    audit_df = pd.DataFrame(audit_rows)\n",
    "\n",
    "    bkd = {\n",
    "        \"st_gain\": float(st_gain),\n",
    "        \"lt_gain\": float(lt_gain),\n",
    "        \"losses\": float(losses + carry_forward_loss),\n",
    "        \"discounted_lt_after_losses\": float(discounted_lt),\n",
    "        \"taxable\": float(taxable),\n",
    "        \"audit\": audit_df\n",
    "    }\n",
    "    return float(tax), bkd\n",
    "\n",
    "\n",
    "def evaluate_transaction_costs(trade_df: pd.DataFrame, lots_df: pd.DataFrame,\n",
    "                               sale_date: pd.Timestamp, marginal_rate: float) -> dict:\n",
    "    brok_total, brok_series = compute_brokerage(trade_df)\n",
    "    tax_total, tax_bkd = compute_cgt_tax(trade_df, lots_df, sale_date,\n",
    "                                         marginal_rate=MARGINAL_TAX_RATE,\n",
    "                                         carry_forward_loss=CAPITAL_LOSS_CARRY_FWD,\n",
    "                                         method=LOT_MATCH_METHOD)\n",
    "    return {\"brokerage\": brok_total, \"cgt_tax\": tax_total,\n",
    "            \"total_cost\": brok_total + tax_total, \"breakdown\": tax_bkd,\n",
    "            \"per_row_brokerage\": brok_series}\n",
    "\n",
    "def _update_lots_after_trades(lots_df: pd.DataFrame, trade_df: pd.DataFrame,\n",
    "                              sale_date: pd.Timestamp, fx_map: pd.Series | dict):\n",
    "    \"\"\"\n",
    "    Apply executed trades to the Lots table:\n",
    "      - Sells: decrement matched lots using the current LOT_MATCH_METHOD (HIFO/FIFO).\n",
    "      - Buys:  append a new lot with AcqDate = sale_date and CostBaseAUD = Last Px (AUD).\n",
    "    Returns a NEW lots DataFrame (original not mutated).\n",
    "    \"\"\"\n",
    "    out = lots_df.copy()\n",
    "    if \"AcqDate\" in out.columns:\n",
    "        out[\"AcqDate\"] = pd.to_datetime(out[\"AcqDate\"], errors=\"coerce\")\n",
    "\n",
    "    for _, tr in trade_df.iterrows():\n",
    "        sec = str(tr[\"Security\"])\n",
    "        dU = int(tr.get(\"Δ Units\", 0))\n",
    "        px_aud = float(tr.get(\"Last Px (AUD)\", 0.0))\n",
    "\n",
    "        if dU < 0:\n",
    "            # Sells: consume existing lots in the same order used for CGT allocation\n",
    "            lot_block = out[out[\"Security\"] == sec].copy()\n",
    "            if LOT_MATCH_METHOD.upper() == \"HIFO\":\n",
    "                lot_block = lot_block.sort_values(by=[\"CostBaseAUD\",\"AcqDate\"], ascending=[False, True])\n",
    "            else:\n",
    "                lot_block = lot_block.sort_values(by=[\"AcqDate\"], ascending=True)\n",
    "\n",
    "            remaining = abs(dU)\n",
    "            for i in lot_block.index:\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                have = float(out.at[i, \"Units\"])\n",
    "                take = min(remaining, have)\n",
    "                out.at[i, \"Units\"] = have - take\n",
    "                remaining -= take\n",
    "\n",
    "            # remove fully consumed lots\n",
    "            out = out[out[\"Units\"] > 0.0].copy()\n",
    "\n",
    "        elif dU > 0:\n",
    "            # Buys: create a new lot at today's AUD price\n",
    "            out = pd.concat([out, pd.DataFrame([{\n",
    "                \"Security\": sec,\n",
    "                \"AcqDate\": pd.Timestamp(sale_date),\n",
    "                \"Units\": int(dU),\n",
    "                \"CostBaseAUD\": px_aud\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        # dU == 0 → no action for this row\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block 7 Writing into the excel (i.e. formatting and building the actual sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed-path] holdings: rows=25, nonzero=21\n",
      "1 name: Efficient_Frontier | title: Efficient Frontier & CAL (rf=4.00%)\n",
      "Workbook Successfully Updated\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 10) WRITE TO EXCEL \n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ---- 10A) Read seeds (no COM; avoids UsedRange issues) ----\n",
    "seed_units, seed_include = _read_holdings_seed_from_path(filename, \"Holdings\")\n",
    "tilt_seed = _read_tilts_seed_from_path(filename, \"Tilts\")\n",
    "\n",
    "# Ensure MOM exists in the seed and rows are in the canonical order\n",
    "if not isinstance(tilt_seed, pd.DataFrame) or tilt_seed.empty:\n",
    "    tilt_seed = pd.DataFrame(\n",
    "        {\"Target\":[1.0] + [0.0]*(len(TILT_FACTORS)-1),\n",
    "         \"Band\":[0.20]*len(TILT_FACTORS),\n",
    "         \"Use?\":[True] + [False]*(len(TILT_FACTORS)-1)},\n",
    "        index=TILT_FACTORS\n",
    "    )\n",
    "else:\n",
    "    for f in TILT_FACTORS:\n",
    "        if f not in tilt_seed.index:\n",
    "            tilt_seed.loc[f] = {\"Target\":0.0, \"Band\":0.20, \"Use?\":False}\n",
    "    tilt_seed = tilt_seed.reindex(TILT_FACTORS)\n",
    "\n",
    "# ---- 10B) Combined dialog (holdings + tilts) ----\n",
    "res = edit_holdings_and_tilts_dialog(\n",
    "    prices=prices,\n",
    "    exclude=EXCLUDE_FROM_OPT,\n",
    "    seed_units=seed_units,\n",
    "    seed_include=seed_include,\n",
    "    seed_tilts=tilt_seed\n",
    ")\n",
    "if res is None:\n",
    "    units = seed_units.copy()\n",
    "    include_flags = seed_include.copy()\n",
    "    last_px_hold = prices.ffill().iloc[-1].reindex(units.index)\n",
    "    tilt_df = tilt_seed.copy()\n",
    "else:\n",
    "    units, last_px_hold, prices, include_flags, tilt_df = res\n",
    "\n",
    "# --- helper: rebuild analytics from (possibly updated) prices ---\n",
    "def _rebuild_core_from_prices(prices, fx_ticker=\"USDAUD=X\", period=\"5y\"):\n",
    "    fx_raw = yf.download(fx_ticker, period=period, interval=\"1d\",\n",
    "                         auto_adjust=True, threads=False, progress=False)\n",
    "    fx = fx_raw[\"Close\"] if isinstance(fx_raw, pd.DataFrame) else fx_raw\n",
    "    if isinstance(fx, pd.DataFrame):\n",
    "        fx = fx.iloc[:, 0]\n",
    "    fx = pd.to_numeric(fx, errors=\"coerce\").reindex(prices.index).ffill()\n",
    "\n",
    "    usd_cols = [c for c in prices.columns\n",
    "                if not str(c).endswith(\".AX\") and not str(c).startswith(\"^\")]\n",
    "    prices_aud = prices.copy()\n",
    "    if usd_cols:\n",
    "        prices_aud.update(prices.loc[:, usd_cols].mul(fx, axis=0))\n",
    "\n",
    "    d = (prices_aud.reset_index()\n",
    "         .melt(id_vars=\"Date\", var_name=\"Security\", value_name=\"Close\")\n",
    "         .sort_values([\"Security\", \"Date\"]))\n",
    "    d[\"Return\"] = d.groupby(\"Security\", sort=False)[\"Close\"].pct_change(fill_method=None)\n",
    "    d = d.dropna()\n",
    "\n",
    "    df_cov_wide = d.pivot(index=\"Date\", columns=\"Security\", values=\"Return\").sort_index()\n",
    "    Sigma_daily = df_cov_wide.cov()\n",
    "\n",
    "    d[\"LogRet\"] = np.log1p(d[\"Return\"])\n",
    "    mu_log_ann = d.groupby(\"Security\")[\"LogRet\"].mean() * 252.0\n",
    "    mu_ann_geo = np.expm1(mu_log_ann)\n",
    "\n",
    "    return prices_aud, d, df_cov_wide, Sigma_daily, mu_ann_geo\n",
    "\n",
    "# === Rebuild core analytics ===\n",
    "prices_aud_for_returns, df_melt, df_cov_wide, Sigma_daily, mu_ann_geo = _rebuild_core_from_prices(prices)\n",
    "\n",
    "# ---- Factors (FF5 + MOM) & betas ----\n",
    "FF5_LOOKBACK_DAYS = globals().get(\"FF5_LOOKBACK_DAYS\", 252*2)\n",
    "ff = get_ff5_mom_daily()\n",
    "ff_win = ff.tail(FF5_LOOKBACK_DAYS)\n",
    "fac_cols = [c for c in ff_win.columns if c != \"RF\"]\n",
    "B, alpha_daily, resid_var = compute_ff5_betas(df_cov_wide, ff_win, min_obs=120)\n",
    "\n",
    "# ---- Choose μ and Σ source ----\n",
    "USE_FF5 = True\n",
    "if USE_FF5 and (B is not None) and not B.empty:\n",
    "    Fcov_daily = ff_win[fac_cols].cov()\n",
    "    S_diag = resid_var.reindex(B.index).clip(lower=0.0).fillna(0.0)\n",
    "    Sigma_ff_daily = B @ Fcov_daily @ B.T + np.diag(S_diag)\n",
    "    Sigma_ff_daily = pd.DataFrame(Sigma_ff_daily, index=B.index, columns=B.index)\n",
    "\n",
    "    f_mean_ann = ff_win[fac_cols].mean() * 252.0\n",
    "    mu_ff_ann  = (alpha_daily * 252.0).reindex(B.index).fillna(0.0) + (B @ f_mean_ann).rename(None) + rf_annual\n",
    "\n",
    "    securities_opt = [t for t in Sigma_ff_daily.index if t not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_ff_daily.loc[securities_opt, securities_opt]\n",
    "    mu_vec_opt = mu_ff_ann.reindex(securities_opt)\n",
    "    exp_ret_label = \"Expected Return (annual, FF5+MOM)\"\n",
    "else:\n",
    "    securities_all = list(Sigma_daily.columns)\n",
    "    mu_vec_all = mu_ann_geo.reindex(securities_all)\n",
    "    valid_all = [s for s in securities_all\n",
    "                 if pd.notna(mu_vec_all.get(s)) and pd.notna(Sigma_daily.loc[s, s])]\n",
    "    securities_opt = [s for s in valid_all if s not in EXCLUDE_FROM_OPT]\n",
    "    Sigma_opt = Sigma_daily.loc[securities_opt, securities_opt]\n",
    "    mu_vec_opt = mu_vec_all.reindex(securities_opt)\n",
    "    exp_ret_label = \"Expected Return (ann., geom)\"\n",
    "\n",
    "# Tables used later\n",
    "n_opt = len(securities_opt)\n",
    "cov_plus = pd.DataFrame(0.0, index=securities_opt + ['w'], columns=securities_opt + ['w'])\n",
    "cov_plus.iloc[:n_opt, :n_opt] = Sigma_opt.values\n",
    "exp_ret_df = mu_vec_opt.rename(exp_ret_label).to_frame()\n",
    "\n",
    "# FX map used by Holdings + trade plan\n",
    "usd_aud    = get_usd_aud_fx()\n",
    "fx_map_all = fx_to_aud_for_tickers(prices.columns, usd_aud)\n",
    "\n",
    "# ---- 10D) Reopen Excel and WRITE everything, then close ----\n",
    "if USE_XLWINGS:\n",
    "    try:\n",
    "        with xw.App(visible=False, add_book=False) as app:\n",
    "            wb = app.books.open(filename, update_links=False, read_only=False)\n",
    "            if bool(wb.api.ReadOnly):\n",
    "                raise RuntimeError(\"Workbook opened read-only; close it in Excel and try again.\")\n",
    "            wb.activate()\n",
    "            app.display_alerts = False\n",
    "            app.screen_updating = False\n",
    "            try: app.api.EnableEvents = False\n",
    "            except Exception: pass\n",
    "            time.sleep(0.2)\n",
    "\n",
    "            # Pick the max-Sharpe portfolio column once for reuse\n",
    "            sh = pd.to_numeric(stats_df['Sharpe'], errors='coerce').fillna(-1)\n",
    "            best_idx = int(sh.values.argmax()) if len(sh) else 0\n",
    "            w_star = W.iloc[:, best_idx].reindex(W.index).fillna(0.0)\n",
    "\n",
    "            # 1) Cov sheet\n",
    "            try:\n",
    "                cov = wb.sheets['Cov']; cov.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                cov = wb.sheets.add('Cov', after=wb.sheets[-1])\n",
    "            cov.range('A1').options(pd.DataFrame, index=True, header=True).value = Sigma_opt\n",
    "\n",
    "            # 2) Input sheet\n",
    "            try:\n",
    "                inp = wb.sheets['Input']; inp.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                inp = wb.sheets.add('Input', after=wb.sheets[-1])\n",
    "            inp.range('A1').options(pd.DataFrame, index=False, header=True).value = df_melt\n",
    "\n",
    "            # 3) OPT sheet\n",
    "            try:\n",
    "                opt = wb.sheets['OPT']; opt.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                opt = wb.sheets.add('OPT', after=wb.sheets[-1])\n",
    "\n",
    "            # Header\n",
    "            opt.range('A1').value = 'Optimal Portfolio Theory (long-only where possible)'\n",
    "            opt.range('A2').value = f\"Generated: {datetime.now():%Y-%m-%d %H:%M:%S}\"\n",
    "            opt.range('A3').value = 'Expected returns use geometric (log-based) annualisation.'\n",
    "            opt.range('A4').value = 'Variance is daily; annual vol = sqrt(252) * stdev.'\n",
    "            try:\n",
    "                opt.range('A1').api.Font.Bold = True; opt.range('A1').api.Font.Size = 14\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Expected returns\n",
    "            opt.range('A6').value = exp_ret_label\n",
    "            opt.range('A7').options(pd.DataFrame, index=True, header=True).value = exp_ret_df\n",
    "            n_rows = exp_ret_df.shape[0] + 1\n",
    "            try:\n",
    "                opt.range(f\"B8:B{7+n_rows}\").api.NumberFormat = \"0.00%\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Covariance (+ weight row/col)\n",
    "            start_cov_row = 9 + n_rows\n",
    "            opt.range(f\"A{start_cov_row}\").value = 'Covariance Matrix (daily, model) with weight row/column'\n",
    "            opt.range(f\"A{start_cov_row+1}\").options(pd.DataFrame, index=True, header=True).value = cov_plus.fillna(0.0)\n",
    "\n",
    "            # Weights grid\n",
    "            start_w_row = start_cov_row + cov_plus.shape[0] + 4\n",
    "            opt.range(f\"A{start_w_row}\").value = 'Optimised Weights by Target Return'\n",
    "            opt.range(f\"A{start_w_row+1}\").options(pd.DataFrame, index=True, header=True).value = W\n",
    "\n",
    "            # Portfolio Statistics\n",
    "            start_s_row = start_w_row + W.shape[0] + 4\n",
    "            opt.range(f\"A{start_s_row}\").value = 'Portfolio Statistics'\n",
    "            opt.range(f\"A{start_s_row+1}\").options(pd.DataFrame, index=False, header=True).value = stats_df\n",
    "\n",
    "            # ================= Efficient Frontier chart updater =================\n",
    "            def _col_letter(idx0: int) -> str:\n",
    "                n = idx0 + 1  # A=1\n",
    "                letters = \"\"\n",
    "                while n:\n",
    "                    n, rem = divmod(n - 1, 26)\n",
    "                    letters = chr(65 + rem) + letters\n",
    "                return letters\n",
    "            \n",
    "            def _get_chart_by_title(opt_sheet, title_text: str):\n",
    "                \"\"\"Return the COM Chart object whose Title text equals title_text (case/space-insensitive).\"\"\"\n",
    "                def _norm(s): return \" \".join(str(s).split()).casefold()\n",
    "                co = opt_sheet.api.ChartObjects()\n",
    "                want = _norm(title_text)\n",
    "                for i in range(1, co.Count + 1):\n",
    "                    o = co.Item(i)\n",
    "                    try:\n",
    "                        ch = o.Chart\n",
    "                        if ch.HasTitle and _norm(ch.ChartTitle.Text) == want:\n",
    "                            return ch\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                raise RuntimeError(f\"Chart with title '{title_text}' not found on sheet '{opt_sheet.name}'\")\n",
    "            \n",
    "            def update_efficient_frontier_chart(\n",
    "                opt_sheet,\n",
    "                stats_df: pd.DataFrame,\n",
    "                start_s_row: int,\n",
    "                *,\n",
    "                rf_annual: float,\n",
    "                tan_ret: float,\n",
    "                tan_vol: float,\n",
    "                current_point: tuple | None = None,\n",
    "                title_text: str = \"Efficient Frontier & CAL (rf=4.00%)\"\n",
    "            ):\n",
    "                \n",
    "                # ---- Validate columns in stats_df ----\n",
    "                cols = list(stats_df.columns)\n",
    "                try:\n",
    "                    j_ret = cols.index(\"Achieved Return\")\n",
    "                    j_vol = cols.index(\"Volatility (ann.)\")\n",
    "                except ValueError:\n",
    "                    raise RuntimeError(\"stats_df must have columns 'Achieved Return' and 'Volatility (ann.)'.\")\n",
    "            \n",
    "                nrows = int(stats_df.shape[0])\n",
    "                if nrows <= 0:\n",
    "                    raise RuntimeError(\"stats_df has no rows; nothing to plot.\")\n",
    "            \n",
    "                # ---- Build Excel range references for X (Vol) and Y (Return) from the table you wrote ----\n",
    "                header_row = start_s_row + 1      # header row in Excel where you wrote stats_df header\n",
    "                first_row  = header_row + 1       # first data row\n",
    "                col_vol = _col_letter(j_vol)      # zero-based -> Excel column letters relative to column A\n",
    "                col_ret = _col_letter(j_ret)\n",
    "                x_rng = opt_sheet.range(f\"{col_vol}{first_row}:{col_vol}{first_row + nrows - 1}\").api\n",
    "                y_rng = opt_sheet.range(f\"{col_ret}{first_row}:{col_ret}{first_row + nrows - 1}\").api\n",
    "            \n",
    "                # ---- Grab the chart ----\n",
    "                rf = rf_annual\n",
    "                ch = _get_chart_by_title(opt_sheet, title_text)\n",
    "            \n",
    "                # ---- Clear existing series (keep object & styling) ----\n",
    "                try:\n",
    "                    while ch.SeriesCollection().Count > 0:\n",
    "                        ch.SeriesCollection(1).Delete()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "                # Excel ChartType constants (avoid win32com constants; use literals)\n",
    "                XL_XY_SCATTER              = -4169  # points only\n",
    "                XL_XY_SCATTER_LINES        = 74     # scatter with lines (markers on)\n",
    "                XL_MARKERSTYLE_NONE        = -4142\n",
    "                XL_MARKERSTYLE_CIRCLE      = 8\n",
    "                XL_MARKERSTYLE_PLUS        = 2\n",
    "                XL_AXIS_CATEGORY           = 1      # for XY charts Excel still treats X as a value axis, but this works for formatting\n",
    "                XL_AXIS_VALUE              = 2\n",
    "            \n",
    "                # ---- Efficient Frontier (smooth line, no markers) ----\n",
    "                s_front = ch.SeriesCollection().NewSeries()\n",
    "                s_front.Name = '=\"Efficient Frontier\"'\n",
    "                s_front.XValues = x_rng\n",
    "                s_front.Values  = y_rng\n",
    "                s_front.ChartType = XL_XY_SCATTER_LINES\n",
    "                try:\n",
    "                    s_front.MarkerStyle = XL_MARKERSTYLE_NONE\n",
    "                    s_front.Smooth = True\n",
    "                    # optional line weight for visibility\n",
    "                    s_front.Format.Line.Weight = 1.5\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "                # ---- CAL (smooth line from (0, rf) to (tan_vol, tan_ret)) ----\n",
    "                if np.all(np.isfinite([rf_annual, tan_ret, tan_vol])):\n",
    "                    s_cal = ch.SeriesCollection().NewSeries()\n",
    "                    s_cal.Name = '=\"CAL\"'\n",
    "                    s_cal.XValues = (0.0, float(tan_vol))\n",
    "                    s_cal.Values  = (float(rf_annual), float(tan_ret))\n",
    "                    s_cal.ChartType = XL_XY_SCATTER_LINES\n",
    "                    try:\n",
    "                        s_cal.MarkerStyle = XL_MARKERSTYLE_NONE\n",
    "                        s_cal.Smooth = True\n",
    "                        s_cal.Format.Line.Weight = 1.25\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            \n",
    "                # ---- MVP (single point at min volatility) ----\n",
    "                try:\n",
    "                    vol_series = pd.to_numeric(stats_df[\"Volatility (ann.)\"], errors=\"coerce\")\n",
    "                    ret_series = pd.to_numeric(stats_df[\"Achieved Return\"], errors=\"coerce\")\n",
    "                    mask = vol_series.notna() & ret_series.notna()\n",
    "                    if mask.any():\n",
    "                        idx_mvp = vol_series[mask].idxmin()\n",
    "                        mvp_x = float(vol_series.loc[idx_mvp])\n",
    "                        mvp_y = float(ret_series.loc[idx_mvp])\n",
    "                        s_mvp = ch.SeriesCollection().NewSeries()\n",
    "                        s_mvp.Name    = '=\"MVP\"'\n",
    "                        s_mvp.XValues = (mvp_x,)   # tuples, not lists, play nicer with COM\n",
    "                        s_mvp.Values  = (mvp_y,)\n",
    "                        s_mvp.ChartType = XL_XY_SCATTER\n",
    "                        try:\n",
    "                            s_mvp.MarkerStyle = XL_MARKERSTYLE_CIRCLE\n",
    "                            s_mvp.MarkerSize  = 8\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                except Exception as e:\n",
    "                    print(f\"[chart] MVP error: {e}\")\n",
    "            \n",
    "                # ---- Current portfolio (single point) ----\n",
    "                if current_point is not None:\n",
    "                    try:\n",
    "                        curr_vol, curr_ret = map(float, current_point)\n",
    "                        if np.isfinite(curr_vol) and np.isfinite(curr_ret):\n",
    "                            s_cur = ch.SeriesCollection().NewSeries()\n",
    "                            s_cur.Name    = '=\"Current\"'\n",
    "                            s_cur.XValues = (curr_vol,)\n",
    "                            s_cur.Values  = (curr_ret,)\n",
    "                            s_cur.ChartType = XL_XY_SCATTER\n",
    "                            try:\n",
    "                                s_cur.MarkerStyle = XL_MARKERSTYLE_PLUS\n",
    "                                s_cur.MarkerSize  = 10\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                    except Exception as e:\n",
    "                        print(f\"[chart] Current point error: {e}\")\n",
    "            \n",
    "                # ---- Axis number formats to percentages (best-effort) ----\n",
    "                for ax_type in (XL_AXIS_CATEGORY, XL_AXIS_VALUE):\n",
    "                    try:\n",
    "                        ch.Axes(ax_type).TickLabels.NumberFormat = \"0.0%\"\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            \n",
    "                # Keep legend; if chart had one it stays. Optionally ensure it exists:\n",
    "                try:\n",
    "                    ch.HasLegend = True\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # ================= End chart updater =================            \n",
    "            # -------- Example usage (fits your existing variables) --------\n",
    "            # Compute current portfolio point if you want it plotted; otherwise pass current_point=None.\n",
    "            current_point = None\n",
    "            try:\n",
    "                curr_w = current_holdings_weights(\n",
    "                    units=units,\n",
    "                    last_prices=last_px_hold,\n",
    "                    investable=list(Sigma_opt.index),\n",
    "                    fx_to_aud=fx_map_all\n",
    "                ).reindex(Sigma_opt.index).fillna(0.0)\n",
    "            \n",
    "                mu_use = mu_vec_opt.reindex(Sigma_opt.index).fillna(0.0).values\n",
    "                S_use  = Sigma_opt.values\n",
    "                wv     = curr_w.values\n",
    "            \n",
    "                curr_ret = float(mu_use @ wv)\n",
    "                curr_vol = float(np.sqrt(wv @ S_use @ wv) * np.sqrt(252.0))\n",
    "                current_point = (curr_vol, curr_ret)\n",
    "            except Exception as e:\n",
    "                print(f\"[chart] Current point compute error: {e}\")\n",
    "                current_point = None\n",
    "            \n",
    "            # Finally, update the existing chart on 'OPT'\n",
    "            # --- Efficient Frontier Chart Update (safe version) ---\n",
    "            try:\n",
    "                update_efficient_frontier_chart(\n",
    "                    opt_sheet=opt,\n",
    "                    stats_df=stats_df,\n",
    "                    start_s_row=start_s_row,\n",
    "                    rf_annual=float(rf_annual),\n",
    "                    tan_ret=float(tan_ret),\n",
    "                    tan_vol=float(tan_vol),\n",
    "                    current_point=current_point,\n",
    "                    title_text=\"Efficient Frontier & CAL (rf=4.00%)\",\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[chart] Skipping chart update: {e}\")\n",
    " \n",
    "            co = opt.api.ChartObjects()\n",
    "            for i in range(1, co.Count + 1):\n",
    "                o = co.Item(i)\n",
    "                title = \"\"\n",
    "                try:\n",
    "                    if o.Chart.HasTitle:\n",
    "                        title = o.Chart.ChartTitle.Text\n",
    "                except Exception:\n",
    "                    pass\n",
    "                print(i, \"name:\", o.Name, \"| title:\", title)\n",
    "\n",
    "          \n",
    "            # ---- Build trade plan & costs BEFORE writing Trade Plan/Costs/Tilts ----\n",
    "            trade_rec, resid_rec = make_trade_plan(\n",
    "                units, last_px_hold, fx_map_all, w_star, include_zero_lines=True, include_flags=include_flags\n",
    "            )\n",
    "            costs_rec = evaluate_transaction_costs(\n",
    "                trade_rec, lots_df, pd.Timestamp(prices.index[-1]), MARGINAL_TAX_RATE\n",
    "            )\n",
    "\n",
    "            trade_rec = trade_rec.copy()\n",
    "            trade_rec[\"Brokerage (AUD)\"] = costs_rec[\"per_row_brokerage\"].reindex(trade_rec.index).fillna(0.0).round(2)\n",
    "            # drop any legacy promo cols\n",
    "            trade_rec.drop(columns=[c for c in trade_rec.columns if c.lower().startswith(\"promo\")],\n",
    "                           errors=\"ignore\", inplace=True)\n",
    "\n",
    "            # ---- Achieved factor tilts table (from B and w_star) ----\n",
    "            tilts_out = None\n",
    "            if (B is not None) and (not B.empty):\n",
    "                factor_order = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "                w_use = w_star.reindex(B.index).fillna(0.0)\n",
    "                if float(w_use.sum()) > 0:\n",
    "                    w_use = w_use / float(w_use.sum())\n",
    "                achieved_series = (B.T @ w_use).rename(\"Achieved β\").reindex(factor_order)\n",
    "\n",
    "                if isinstance(tilt_df, pd.DataFrame) and not tilt_df.empty:\n",
    "                    tgt = tilt_df.reindex(factor_order)\n",
    "                    tilts_out = pd.DataFrame({\n",
    "                        \"Use?\":      tgt[\"Use?\"].astype(bool).map({True: \"Yes\", False: \"No\"}),\n",
    "                        \"Target β\":  pd.to_numeric(tgt[\"Target\"], errors=\"coerce\"),\n",
    "                        \"Band\":      pd.to_numeric(tgt[\"Band\"],   errors=\"coerce\"),\n",
    "                        \"Achieved β\": achieved_series,\n",
    "                    })\n",
    "                    tilts_out[\"Diff\"] = tilts_out[\"Achieved β\"] - tilts_out[\"Target β\"]\n",
    "                    tilts_out[\"Within Band?\"] = (tilts_out[\"Diff\"].abs() <= tilts_out[\"Band\"]).map({True: \"Yes\", False: \"No\"})\n",
    "                else:\n",
    "                    tilts_out = achieved_series.to_frame()\n",
    "\n",
    "            # ---------- Layout anchors (avoid overlaps) ----------\n",
    "            anchor_row = start_s_row + stats_df.shape[0] + 4\n",
    "            TP_COL, COST_COL, TILT_COL = \"A\", \"J\", \"M\"\n",
    "\n",
    "            # ---------- LEFT: Trade Plan ----------\n",
    "            opt.range(f\"{TP_COL}{anchor_row}\").value = \"Trade Plan (rounded units)\"\n",
    "            opt.range(f\"{TP_COL}{anchor_row+1}\").options(pd.DataFrame, index=False, header=True).value = trade_rec\n",
    "\n",
    "            # basic formatting\n",
    "            tp_rows = trade_rec.shape[0] + 1\n",
    "            tp_first = anchor_row + 1\n",
    "            tp_data_first = tp_first + 1\n",
    "            # ---------- Format Trade Plan numbers ----------\n",
    "            try:\n",
    "                for col_name, fmt in {\n",
    "                    \"Security\": \"@\",\n",
    "                    \"Current Units\": \"0\",\n",
    "                    \"Target Units\": \"0\",\n",
    "                    \"Last Px (AUD)\": \"0.0000\",\n",
    "                    \"Cash Flow (AUD)\": \"$0.00\",\n",
    "                    \"Brokerage (AUD)\": \"$0.00\",\n",
    "                }.items():\n",
    "                    if col_name in trade_rec.columns:\n",
    "                        col_idx = list(trade_rec.columns).index(col_name)\n",
    "                        col_letter = chr(ord(\"A\") + col_idx)\n",
    "                        opt.range(f\"{col_letter}{tp_data_first}:{col_letter}{tp_first+tp_rows}\").api.NumberFormat = fmt\n",
    "            except Exception as e:\n",
    "                print(f\"[format] Trade Plan formatting skipped: {e}\")\n",
    "                if \"Brokerage (AUD)\" in trade_rec.columns:\n",
    "                    bidx = list(trade_rec.columns).index(\"Brokerage (AUD)\")\n",
    "                    bcol = chr(ord(\"A\") + bidx)\n",
    "                    opt.range(f\"{bcol}{tp_data_first}:{bcol}{tp_first+tp_rows}\").api.NumberFormat = \"0.00\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # ---------- MIDDLE: Transaction Costs summary ----------\n",
    "            opt.range(f\"{COST_COL}{anchor_row}\").value = \"Transaction Costs (AUD)\"\n",
    "            opt.range(f\"{COST_COL}{anchor_row+1}\").value = [\n",
    "                [\"Brokerage\", \"CGT Tax\", \"Total\"],\n",
    "                [costs_rec[\"brokerage\"], costs_rec[\"cgt_tax\"], costs_rec[\"total_cost\"]],\n",
    "            ]\n",
    "            try:\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").api.NumberFormat = \"0.00\"\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").offset(0,1).api.NumberFormat = \"0.00\"\n",
    "                opt.range(f\"{COST_COL}{anchor_row+2}\").offset(0,2).api.NumberFormat = \"0.00\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # ---------- RIGHT: Achieved Factor Tilts ----------\n",
    "            if tilts_out is not None:\n",
    "                opt.range(f\"{TILT_COL}{anchor_row}\").value = \"Achieved Factor Tilts vs Targets\"\n",
    "                opt.range(f\"{TILT_COL}{anchor_row+1}\").options(pd.DataFrame, index=True, header=True).value = tilts_out\n",
    "                t_rows = tilts_out.shape[0] + 1\n",
    "                t_first = anchor_row + 1\n",
    "                t_data_first = t_first + 1\n",
    "                try:\n",
    "                    for col_name in [\"Target β\",\"Band\",\"Achieved β\",\"Diff\"]:\n",
    "                        if col_name in tilts_out.columns:\n",
    "                            idx = list(tilts_out.columns).index(col_name)\n",
    "                            col_letter = chr(ord(TILT_COL) + 1 + idx)  # after index column\n",
    "                            opt.range(f\"{col_letter}{t_data_first}:{col_letter}{t_first+t_rows}\").api.NumberFormat = \"0.000\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # ---------- BELOW RIGHT: Factor Feasible Ranges (long-only, sum=1) ----------\n",
    "            if (B is not None) and (not B.empty):\n",
    "                factor_order = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"MOM\"]\n",
    "                rng_df = compute_factor_feasible_ranges(B, include_flags=include_flags, factor_order=factor_order)\n",
    "            \n",
    "                # Optional: show your target & achieved alongside the ranges\n",
    "                if isinstance(tilts_out, pd.DataFrame):\n",
    "                    # pull Target and Achieved columns safely\n",
    "                    tgt = pd.to_numeric(tilts_out.get(\"Target β\", np.nan), errors=\"coerce\")\n",
    "                    ach = pd.to_numeric(tilts_out.get(\"Achieved β\", np.nan), errors=\"coerce\")\n",
    "                    rng_df = rng_df.join(tgt.rename(\"Target β\")).join(ach.rename(\"Achieved β\"))\n",
    "                    rng_df[\"Within Range?\"] = (rng_df[\"Target β\"] >= rng_df[\"Min β\"]) & (rng_df[\"Target β\"] <= rng_df[\"Max β\"])\n",
    "            \n",
    "                # place a few rows *below* the achieved-tilts table to avoid overlap\n",
    "                tilt_rows = (tilts_out.shape[0] + 2) if isinstance(tilts_out, pd.DataFrame) else 3\n",
    "                ranges_anchor = anchor_row + tilt_rows + 2\n",
    "            \n",
    "                opt.range(f\"{TILT_COL}{ranges_anchor}\").value = \"Factor Feasible Ranges (long-only, sum=1)\"\n",
    "                opt.range(f\"{TILT_COL}{ranges_anchor+1}\").options(pd.DataFrame, index=True, header=True).value = rng_df\n",
    "            \n",
    "                # number formats\n",
    "                rr = ranges_anchor + 1\n",
    "                rr_rows = rng_df.shape[0] + 1\n",
    "                try:\n",
    "                    # format numeric columns to 3 decimals if present\n",
    "                    for col_name in [\"Min β\",\"Max β\",\"Target β\",\"Achieved β\"]:\n",
    "                        if col_name in rng_df.columns:\n",
    "                            idx = list(rng_df.columns).index(col_name)\n",
    "                            # first data column is one to the right of TILT_COL\n",
    "                            col_letter = chr(ord(TILT_COL) + 1 + idx)\n",
    "                            opt.range(f\"{col_letter}{rr+1}:{col_letter}{rr+rr_rows}\").api.NumberFormat = \"0.000\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Final tidy\n",
    "            try: opt.autofit()\n",
    "            except Exception: pass\n",
    "\n",
    "            # 4) FF5F sheet (optional transparency)\n",
    "            try:\n",
    "                ff5s = wb.sheets['FF5F']; ff5s.used_range.clear_contents()\n",
    "            except Exception:\n",
    "                ff5s = wb.sheets.add('FF5F', after=wb.sheets[-1])\n",
    "            ff5s.range('A1').options(pd.DataFrame, index=True, header=True).value = ff\n",
    "\n",
    "            # ---- Update Lots and overwrite Holdings with target units (for next run) ----\n",
    "            UPDATED_LOTS = _update_lots_after_trades(lots_df, trade_rec, pd.Timestamp(prices.index[-1]), fx_map_all)\n",
    "            try:\n",
    "                sht_lots = wb.sheets['Lots']\n",
    "            except Exception:\n",
    "                sht_lots = wb.sheets.add('Lots', after=wb.sheets[-1])\n",
    "            sht_lots.used_range.clear_contents()\n",
    "            sht_lots.range(\"A1\").value = [[\"Security\",\"AcqDate\",\"Units\",\"CostBaseAUD\"]]\n",
    "            sht_lots.range(\"A2\").options(index=False, header=False).value = UPDATED_LOTS\n",
    "\n",
    "            tgt_units_full = compute_target_units_for_holdings(\n",
    "                units, last_px_hold, fx_map_all, w_star, include_flags\n",
    "            )\n",
    "            _write_holdings_sheet(wb, prices, tgt_units_full, include_flags,\n",
    "                                  sheet_name=\"Holdings\", fx_to_aud_map=fx_map_all)\n",
    "\n",
    "            wb.save()\n",
    "            wb.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Excel fallback] xlwings/COM error → exporting CSVs instead: {e}\")\n",
    "        export_dir = os.path.join(os.path.dirname(filename), \"Exports\")\n",
    "        try: os.makedirs(export_dir, exist_ok=True)\n",
    "        except Exception: pass\n",
    "        try: exp_ret_df.to_csv(os.path.join(export_dir, \"expected_returns.csv\"))\n",
    "        except Exception as ee: print(f\"[export] expected_returns.csv: {ee}\")\n",
    "        try: cov_plus.to_csv(os.path.join(export_dir, \"covariance_plus.csv\"))\n",
    "        except Exception as ee: print(f\"[export] covariance_plus.csv: {ee}\")\n",
    "        try: W.to_csv(os.path.join(export_dir, \"weights_grid.csv\"))\n",
    "        except Exception as ee: print(f\"[export] weights_grid.csv: {ee}\")\n",
    "        try: stats_df.to_csv(os.path.join(export_dir, \"portfolio_stats.csv\"), index=False)\n",
    "        except Exception as ee: print(f\"[export] portfolio_stats.csv: {ee}\")\n",
    "        try: tilt_df.to_csv(os.path.join(export_dir, \"tilts.csv\"))\n",
    "        except Exception as ee: print(f\"[export] tilts.csv: {ee}\")\n",
    "        try: df_melt.to_csv(os.path.join(export_dir, \"returns_long.csv\"), index=False)\n",
    "        except Exception as ee: print(f\"[export] returns_long.csv: {ee}\")\n",
    "else:\n",
    "    # ---------- Headless fallback: write key outputs as CSVs ----------\n",
    "    export_dir = os.path.join(os.path.dirname(filename), \"Exports\")\n",
    "    try: os.makedirs(export_dir, exist_ok=True)\n",
    "    except Exception: pass\n",
    "    try: exp_ret_df.to_csv(os.path.join(export_dir, \"expected_returns.csv\"))\n",
    "    except Exception as e: print(f\"[export] expected_returns.csv: {e}\")\n",
    "    try: cov_plus.to_csv(os.path.join(export_dir, \"covariance_plus.csv\"))\n",
    "    except Exception as e: print(f\"[export] covariance_plus.csv: {e}\")\n",
    "    try: W.to_csv(os.path.join(export_dir, \"weights_grid.csv\"))\n",
    "    except Exception as e: print(f\"[export] weights_grid.csv: {e}\")\n",
    "    try: stats_df.to_csv(os.path.join(export_dir, \"portfolio_stats.csv\"), index=False)\n",
    "    except Exception as e: print(f\"[export] portfolio_stats.csv: {e}\")\n",
    "    try: tilt_df.to_csv(os.path.join(export_dir, \"tilts.csv\"))\n",
    "    except Exception as e: print(f\"[export] tilts.csv: {e}\")\n",
    "    try: df_melt.to_csv(os.path.join(export_dir, \"returns_long.csv\"), index=False)\n",
    "    except Exception as e: print(f\"[export] returns_long.csv: {e}\")\n",
    "\n",
    "print(\"Workbook Successfully Updated\")\n",
    "\n",
    "# --- Optional: auto-open the workbook in Excel (independent of xlwings) ---\n",
    "OPEN_AFTER_SAVE = bool(CFG.get(\"open_after_save\", True))\n",
    "\n",
    "def _os_open(path):\n",
    "    try:\n",
    "        # Windows\n",
    "        os.startfile(path)  # type: ignore[attr-defined]\n",
    "    except AttributeError:\n",
    "        # macOS / Linux fallback\n",
    "        import subprocess, sys\n",
    "        if sys.platform == \"darwin\":\n",
    "            subprocess.run([\"open\", path])\n",
    "        else:\n",
    "            subprocess.run([\"xdg-open\", path])\n",
    "\n",
    "if OPEN_AFTER_SAVE:\n",
    "    _os_open(filename)\n",
    "\n",
    "# --- Create a Desktop shortcut (optional, safe in any context) ---\n",
    "try:\n",
    "    if HAS_WIN32COM:\n",
    "        shortcut_path = str(Path.home() / \"Desktop\" / \"Portfolio Optimiser.lnk\")\n",
    "\n",
    "        # Prefer the exe if it exists; otherwise point at the script we’re running.\n",
    "        # Works when frozen, when run as .py, and in Jupyter (falls back to .py name in APP_DIR).\n",
    "        if getattr(sys, \"frozen\", False):\n",
    "            target = Path(sys.executable)\n",
    "        else:\n",
    "            # Try the current file if available; else fall back to a known script name in this folder\n",
    "            if \"__file__\" in globals():\n",
    "                target = Path(__file__).resolve()\n",
    "            else:\n",
    "                # Adjust the name if your launcher script is 'Main.py' instead\n",
    "                # (You have both Main.py and Portfolio_Optimiser3110.py in your screenshot.)\n",
    "                candidate = APP_DIR / \"Portfolio_Optimiser3110.py\"\n",
    "                target = candidate if candidate.exists() else (APP_DIR / \"Main.py\")\n",
    "\n",
    "        shell = win32.Dispatch(\"WScript.Shell\")\n",
    "        sc = shell.CreateShortCut(shortcut_path)\n",
    "        sc.WindowStyle = 1  # normal window\n",
    "        sc.Arguments = \"\"   # no extra args      \n",
    "        sc.Targetpath = str(target)\n",
    "        sc.WorkingDirectory = str(target.parent)\n",
    "        # Use icon.ico if present; otherwise the target itself\n",
    "        icon_path = APP_DIR / \"icon.ico\"\n",
    "        sc.IconLocation = str(icon_path if icon_path.exists() else target)\n",
    "        sc.save()\n",
    "    else:\n",
    "        print(\"[shortcut] pywin32 not available; skipping Desktop shortcut.\")\n",
    "except Exception as e:\n",
    "    print(f\"[shortcut] skipped due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
